<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Geony Data World</title><meta description="Data Analyst&amp;#39;s blog"><meta property="og:type" content="blog"><meta property="og:title" content="Geony Data World"><meta property="og:url" content="http://wglee87.github.io/"><meta property="og:site_name" content="Geony Data World"><meta property="og:description" content="Data Analyst&amp;#39;s blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://wglee87.github.io/img/og_image.png"><meta property="article:author" content="WGLee87"><meta property="article:tag" content="data_analysis"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://wglee87.github.io"},"headline":"Geony Data World","image":["http://wglee87.github.io/img/og_image.png"],"author":{"@type":"Person","name":"WGLee87"},"description":"Data Analyst&#39;s blog"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Geony Data World" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-14T11:01:27.000Z" title="2020-05-14T11:01:27.000Z">2020-05-14</time><span class="level-item">30 minutes read (About 4483 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/14/leverage-outliar-cooks-distance-anova/">leverage-outliar-cooks_distance_anova</a></h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br></pre></td></tr></table></figure>

<h4 id="레버리지-leverage"><a href="#레버리지-leverage" class="headerlink" title="레버리지 (leverage)"></a>레버리지 (leverage)</h4><pre><code>독립변수의 전체 데이터가 아닌 개별적인 데이터 표본 하나하나가 회귀분석 결과에 미치는 영향력은 레버리지 분석이나 아웃라이어 분석을 통해 알 수 있다.
레버리지(leverage)는 실제 종속변수값  𝑦 가 예측치(predicted target)  𝑦̂  에 미치는 영향을 나타낸 값이다. self-influence, self-sensitivity 라고도 한다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 14 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">df0 = pd.concat([dfX, dfy],axis=<span class="number">1</span>)</span><br><span class="line">df0</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>const</th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>1.0</td>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>1.0</td>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>1.0</td>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>1.0</td>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>1.0</td>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 15 columns</p>
</div>



<h5 id="statsmodels를-이용한-레버리지-계산"><a href="#statsmodels를-이용한-레버리지-계산" class="headerlink" title="statsmodels를 이용한 레버리지 계산"></a>statsmodels를 이용한 레버리지 계산</h5><pre><code>레버리지 값은 RegressionResults 클래스의 get_influence 메서드로 다음과 같이 구할 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 100개의 데이터 생성</span></span><br><span class="line">X0, y, coef = make_regression(n_samples=<span class="number">100</span>, n_features=<span class="number">1</span>, noise=<span class="number">20</span>,</span><br><span class="line">                             coef=<span class="literal">True</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 레버리지가 높은 가상의 데이터를 추가</span></span><br><span class="line">data_100 = (<span class="number">4</span>, <span class="number">300</span>)</span><br><span class="line">data_101 = (<span class="number">3</span>, <span class="number">150</span>)</span><br><span class="line">X0 = np.vstack([X0, np.array([data_100[:<span class="number">1</span>], data_101[:<span class="number">1</span>]])])</span><br><span class="line">X = sm.add_constant(X0) <span class="comment">#상수항 추가</span></span><br><span class="line">y = np.hstack([y, [data_100[<span class="number">1</span>], data_101[<span class="number">1</span>]]])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt.scatter(X0, y, s=<span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>)</span><br><span class="line">plt.title(<span class="string">"가상의 회귀분석용 데이터"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="849" alt="output_6_0" src="https://user-images.githubusercontent.com/59719711/81926194-91f19200-961c-11ea-9b3f-3acaa0daccab.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS(pd.DataFrame(y), pd.DataFrame(X))</span><br><span class="line">result = model.fit()</span><br><span class="line">print(result.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      0   R-squared:                       0.936
Model:                            OLS   Adj. R-squared:                  0.935
Method:                 Least Squares   F-statistic:                     1464.
Date:                Thu, 14 May 2020   Prob (F-statistic):           1.61e-61
Time:                        14:22:53   Log-Likelihood:                -452.71
No. Observations:                 102   AIC:                             909.4
Df Residuals:                     100   BIC:                             914.7
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
0              3.2565      2.065      1.577      0.118      -0.840       7.353
1             78.3379      2.048     38.260      0.000      74.276      82.400
==============================================================================
Omnibus:                       16.191   Durbin-Watson:                   1.885
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.807
Skew:                          -0.534   Prob(JB):                     1.02e-08
Kurtosis:                       5.742   Cond. No.                         1.14
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


선형회귀 결과에서 get_influence 메서드를 호출하면 영향도 정보 객체를 구할 수 있고, 이 객체는 hat_matrix_diag 속성으로 레버리지 벡터의 값을 가지고도 있어</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">influence = result.get_influence()</span><br><span class="line">hat = influence.hat_matrix_diag</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt. stem(hat)</span><br><span class="line">plt.axhline(<span class="number">0.02</span>, c = <span class="string">'g'</span>, ls = <span class="string">'--'</span>) <span class="comment"># c = color , ls = linestyle</span></span><br><span class="line">plt.title(<span class="string">'각 데이터의 레버리지 값'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.
  &quot;&quot;&quot;</code></pre><img width="831" alt="output_9_1" src="https://user-images.githubusercontent.com/59719711/81926258-a6ce2580-961c-11ea-9442-38672fbc831a.png">


<pre><code>그래프를 그리는 코드에서 0.02의 값은 레버리지 평균값을 구하는 공식 독립변수의 갯수 / 데이터의 갯수 로 구하면 된다</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![스크린샷 <span class="number">2020</span><span class="number">-05</span><span class="number">-14</span> 오후 <span class="number">2</span> <span class="number">31</span> <span class="number">46</span>](https://user-images.githubusercontent.com/<span class="number">59719711</span>/<span class="number">81926278</span>-b2215100<span class="number">-961</span>c<span class="number">-11</span>ea<span class="number">-9613</span>-c5ba582d5de0.png)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(X0, y,s=<span class="number">30</span>)</span><br><span class="line">sm.graphics.abline_plot(model_results=result, ax=ax)</span><br><span class="line"></span><br><span class="line">idx = hat &gt; <span class="number">0.05</span></span><br><span class="line">plt.scatter(X0[idx], y[idx], s=<span class="number">300</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.title(<span class="string">"회귀분석 결과와 레버리지 포인트"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="833" alt="output_12_0" src="https://user-images.githubusercontent.com/59719711/81926328-bc434f80-961c-11ea-89ef-927b80f666c7.png">


<pre><code>그래프를 토대로 해석을 하자면, 데이터가 혼자만 너무 작거나 너무 크게 단독으로 존재할수록 레버리지가 커짐을 알 수 있어. 이 말은 저런 데이터은 전체 회귀분석 결과값에 큰 영향을 미친다는 말이야</code></pre><h4 id="아웃라이어-outlier"><a href="#아웃라이어-outlier" class="headerlink" title="아웃라이어(outlier)"></a>아웃라이어(outlier)</h4><pre><code>데이터와 동떨어진 값을 가지는 데이터, 즉 잔차가 큰 데이터를 아웃라이어(outlier)라고 하는데, 잔차의 크기는 독립 변수의 영향을 받으므로 아웃라이어를 찾으려면 이 영향을 제거한 표준화된 잔차를 계산해야 한다고 해. 무슨말인지 잘 모르겠지만 그래

statsmodels를 이용한 표준화 잔차 계산

잔차는 RegressionResult 객체의 resid 속성에 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line">plt.stem(result.resid)</span><br><span class="line">plt.title(<span class="string">"각 데이터의 잔차"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.</code></pre><img width="826" alt="output_16_1" src="https://user-images.githubusercontent.com/59719711/81926368-c8c7a800-961c-11ea-9826-24478a19b3b4.png">


<pre><code>표준화 잔차는 resid_pearson 속성에 있고, 보통 표준화 잔차가 2~4보다 크면 아웃라이어로 보는게 일반적이야</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt. stem(result.resid_pearson)</span><br><span class="line">plt.axhline(<span class="number">3</span>, c=<span class="string">'g'</span>, ls=<span class="string">'--'</span>)</span><br><span class="line">plt.axhline(<span class="number">-3</span>, c=<span class="string">'g'</span>, ls=<span class="string">'--'</span>)</span><br><span class="line">plt.title(<span class="string">'각 데이터의 표준화 잔차'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.</code></pre><img width="818" alt="output_18_1" src="https://user-images.githubusercontent.com/59719711/81926392-d41ad380-961c-11ea-852b-985bce5ea681.png">


<h4 id="Cook’s-Distance"><a href="#Cook’s-Distance" class="headerlink" title="Cook’s Distance"></a>Cook’s Distance</h4><pre><code>회귀 분석에는 레버리지 따로, 잔차의 크기가 큰 데이터가 아웃라이어가 되고 그것을 보는 따로따로의 기능도 있지만  이 두개를 동시에 보는 방법이 바로 Cook&apos;s Distance야. 아마도 Cook이라는 사람이 만들었을 가능성이..

넘어가자

동시에 보는 기준이라고 생각하면 되고, 둘중 하나만 커지더라도 이 Cook&apos;s distance 값은 커지게 돼

모든 데이터의 레버리지와 잔차를 동시에 보려면 plot_leverage_resid2 명령을 사용하는데, 이 명령은 x축으로 표준화 잔차의 제곱을 표시하고 y축으로 레버리지값을 표시한다. 

그리고 데이터 아이디가 표시된 데이터들이 레버리지가 큰 아웃라이어 야</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sm.graphics.plot_leverage_resid2(result)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">sm.graphics.influence_plot(result)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<pre><code>&lt;Figure size 1008x432 with 0 Axes&gt;</code></pre><img width="401" alt="output_21_1" src="https://user-images.githubusercontent.com/59719711/81926442-e563e000-961c-11ea-9511-4128f90f70c5.png">




<img width="392" alt="output_21_2" src="https://user-images.githubusercontent.com/59719711/81926462-ed238480-961c-11ea-827c-5e2360d26f75.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> statsmodels.graphics <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line">cooks_d2, pvals = influence.cooks_distance</span><br><span class="line">K = influence.k_vars</span><br><span class="line">fox_cr = <span class="number">4</span> / (len(y) - K - <span class="number">1</span>)</span><br><span class="line">idx = np.where(cooks_d2 &gt; fox_cr)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(X0, y)</span><br><span class="line">plt.scatter(X0[idx], y[idx], s=<span class="number">300</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">utils.annotate_axes(range(len(idx)), idx,</span><br><span class="line">                    list(zip(X0[idx], y[idx])), [(<span class="number">-20</span>, <span class="number">15</span>)] * len(idx), size=<span class="string">"small"</span>, ax=ax)</span><br><span class="line">plt.title(<span class="string">"Fox Recommendaion으로 선택한 아웃라이어"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="387" alt="output_22_0" src="https://user-images.githubusercontent.com/59719711/81926491-fb71a080-961c-11ea-815d-7cab11d016fd.png">


<h5 id="보스턴-집값-예측-문제¶"><a href="#보스턴-집값-예측-문제¶" class="headerlink" title="보스턴 집값 예측 문제¶"></a>보스턴 집값 예측 문제¶</h5><pre><code>보스턴 집값 문제에 아웃라이어를 적용해 보자. MEDV가 50인 데이터는 상식적으로 생각해도 이상한 데이터이므로 아웃라이어라고 판단할 수 있다. 나머지 데이터 중에서 폭스 추천공식을 사용하여 아웃라이어를 제외한 결과는 다음과 같다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br><span class="line"></span><br><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">df0 = pd.concat([dfX, dfy],axis=<span class="number">1</span>)</span><br><span class="line">df0</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">pred = result_boston.predict(dfX)</span><br><span class="line"></span><br><span class="line">influence_boston = result_boston.get_influence()</span><br><span class="line">cooks_d2, pvals = influence_boston.cooks_distance</span><br><span class="line">K = influence.k_vars</span><br><span class="line">fox_cr = <span class="number">4</span> / (len(y) - K - <span class="number">1</span>)</span><br><span class="line">idx = np.where(cooks_d2 &gt; fox_cr)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># MEDV = 50 제거</span></span><br><span class="line">idx = np.hstack([idx, np.where(boston.target == <span class="number">50</span>)[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(dfy, pred)</span><br><span class="line">plt.scatter(dfy.MEDV[idx], pred[idx], s=<span class="number">200</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">utils.annotate_axes(range(len(idx)), idx,</span><br><span class="line">                    list(zip(dfy.MEDV[idx], pred[idx])), [(<span class="number">-20</span>, <span class="number">15</span>)] * len(idx), size=<span class="string">"small"</span>, ax=ax)</span><br><span class="line">plt.title(<span class="string">"보스턴 집값 데이터에서 아웃라이어"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="374" alt="output_25_0" src="https://user-images.githubusercontent.com/59719711/81926518-04fb0880-961d-11ea-8ec0-70154b06352f.png">


<pre><code>다음은 이렇게 아웃라이어를 제외한 후에 다시 회귀분석을 한 결과이다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">idx2 = list(set(range(len(dfX))).difference(idx))</span><br><span class="line">dfX = dfX.iloc[idx2, :].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">dfy = dfy.iloc[idx2, :].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">model_boston2 = sm.OLS(dfy, dfX)</span><br><span class="line">result_boston2 = model_boston2.fit()</span><br><span class="line">print(result_boston2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.812
Model:                            OLS   Adj. R-squared:                  0.806
Method:                 Least Squares   F-statistic:                     156.1
Date:                Thu, 14 May 2020   Prob (F-statistic):          2.41e-161
Time:                        15:14:52   Log-Likelihood:                -1285.2
No. Observations:                 485   AIC:                             2598.
Df Residuals:                     471   BIC:                             2657.
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         18.8999      4.107      4.602      0.000      10.830      26.969
CRIM          -0.0973      0.024     -4.025      0.000      -0.145      -0.050
ZN             0.0278      0.010      2.651      0.008       0.007       0.048
INDUS         -0.0274      0.046     -0.595      0.552      -0.118       0.063
CHAS           0.9228      0.697      1.324      0.186      -0.447       2.292
NOX           -9.4922      2.856     -3.323      0.001     -15.105      -3.879
RM             5.0921      0.371     13.735      0.000       4.364       5.821
AGE           -0.0305      0.010     -2.986      0.003      -0.051      -0.010
DIS           -1.0562      0.150     -7.057      0.000      -1.350      -0.762
RAD            0.1990      0.049      4.022      0.000       0.102       0.296
TAX           -0.0125      0.003     -4.511      0.000      -0.018      -0.007
PTRATIO       -0.7777      0.098     -7.955      0.000      -0.970      -0.586
B              0.0107      0.002      5.348      0.000       0.007       0.015
LSTAT         -0.2846      0.043     -6.639      0.000      -0.369      -0.200
==============================================================================
Omnibus:                       45.944   Durbin-Watson:                   1.184
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.791
Skew:                           0.679   Prob(JB):                     5.17e-15
Kurtosis:                       4.188   Cond. No.                     1.59e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.59e+04. This might indicate that there are
strong multicollinearity or other numerical problems.


R-squared 의 성능점수가 올라간 것을 볼 수 있어.

이렇게 어떤 특정 데이터를 가지고 회귀분석 모델링을 할 때에는 하기 전에 레버리지가 큰 데이터와 아웃라이어의 값을 이러한 절차에 의해 뽑아서 제거하고 모델링을 한다면 더욱 성능이 좋은 회귀분석 모델링을 할 수 있는거야</code></pre><h4 id="분산-분석"><a href="#분산-분석" class="headerlink" title="분산 분석"></a>분산 분석</h4><pre><code>선형회귀분석의 결과가 얼마나 좋은지는 단순히 잔차제곱합(RSS: Residula Sum of Square)으로 평가할 수 없다. 변수의 단위 즉, 스케일이 달라지면 회귀분석과 상관없이 잔차제곱합도 달라지기 때문이야 ( ex.1km와 1000m)

분산 분석(ANOVA: Analysis of Variance)은 종속변수의 분산과 독립변수의 분산간의 관계를 사용하여 선형회귀분석의 성능을 평가하고자 하는 방법이다. 분산 분석은 서로 다른 두 개의 선형회귀분석의 성능 비교에 응용할 수 있으며 독립변수가 카테고리 변수인 경우 각 카테고리 값에 따른 영향을 정량적으로 분석하는데도 사용할 수 있게 돼

여러 수식들이 존재하지만 내가 이해를 못하겠고 결론은 다음과 같아.

모형 예측치의 움직임의 크기(분산,ESS)은 종속변수의 움직임의 크기(분산,TSS)보다 클 수 없어 그리고 모형의 성능이 좋을수록 모형 예측치의 움직임의 크기는 종속변수의 움직임의 크기와 비슷해진다는 점이야</code></pre><h5 id="F-검정을-사용한-변수-중요도-비교"><a href="#F-검정을-사용한-변수-중요도-비교" class="headerlink" title="F 검정을 사용한 변수 중요도 비교"></a>F 검정을 사용한 변수 중요도 비교</h5><pre><code>F검정은 각 독립변수의 중요도를 비교하기 위해 사용할 수 있다. 방법은 전체 모형과 각 변수 하나만을 뺀 모형들의 성능을 비교하는 것인데, 이는 간접적으로 각 독립 변수의 영향력을 측정하는 것이라고 할 수 있다. 예를 들어 보스턴 집값 데이터에서 CRIM이란 변수를 뺀 모델과 전체 모델의 비교하는 검정을 하면 이 검정 결과는 CRIM변수의 중요도를 나타낸다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_full = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ CRIM + ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line">model_reduced = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line"></span><br><span class="line">sm.stats.anova_lm(model_reduced.fit(), model_full.fit())</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater
  return (a &lt; x) &amp; (x &lt; b)
/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less
  return (a &lt; x) &amp; (x &lt; b)
/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 &amp; (x &lt;= _a)</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df_resid</th>
      <th>ssr</th>
      <th>df_diff</th>
      <th>ss_diff</th>
      <th>F</th>
      <th>Pr(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>493.0</td>
      <td>11322.004277</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>492.0</td>
      <td>11078.784578</td>
      <td>1.0</td>
      <td>243.219699</td>
      <td>10.801193</td>
      <td>0.001087</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>anova_lm 명령에서는 typ 인수를 2로 지정하면 하나 하나의 변수를 뺀 축소 모형에서의 F 검정값을 한꺼번에 계산할 수 있다.</code></pre><h5 id="아노바-분석-F검정"><a href="#아노바-분석-F검정" class="headerlink" title="아노바 분석 - F검정"></a>아노바 분석 - F검정</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ CRIM + ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line">result = model.fit()</span><br><span class="line">sm.stats.anova_lm(result, typ=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>243.219699</td>
      <td>1.0</td>
      <td>10.801193</td>
      <td>1.086810e-03</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>257.492979</td>
      <td>1.0</td>
      <td>11.435058</td>
      <td>7.781097e-04</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>2.516668</td>
      <td>1.0</td>
      <td>0.111763</td>
      <td>7.382881e-01</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>487.155674</td>
      <td>1.0</td>
      <td>21.634196</td>
      <td>4.245644e-06</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>1871.324082</td>
      <td>1.0</td>
      <td>83.104012</td>
      <td>1.979441e-18</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.061834</td>
      <td>1.0</td>
      <td>0.002746</td>
      <td>9.582293e-01</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>1232.412493</td>
      <td>1.0</td>
      <td>54.730457</td>
      <td>6.013491e-13</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>479.153926</td>
      <td>1.0</td>
      <td>21.278844</td>
      <td>5.070529e-06</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>242.257440</td>
      <td>1.0</td>
      <td>10.758460</td>
      <td>1.111637e-03</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>1194.233533</td>
      <td>1.0</td>
      <td>53.034960</td>
      <td>1.308835e-12</td>
    </tr>
    <tr>
      <th>B</th>
      <td>270.634230</td>
      <td>1.0</td>
      <td>12.018651</td>
      <td>5.728592e-04</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>2410.838689</td>
      <td>1.0</td>
      <td>107.063426</td>
      <td>7.776912e-23</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>218.970357</td>
      <td>1.0</td>
      <td>9.724299</td>
      <td>1.925030e-03</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>11078.784578</td>
      <td>492.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>각각의 독립변수들의 전체와 비교했을 때 얼마만큼 중요도를 가지는데 정량적으로 나온 결과값이야. 여기서 주목해야할 부분은 PR&gt;(&gt;F)부분으로 summary에서도 나오는 p-value값을 디테일하게 풀어놓은 값이고 예를 들어 LSTAT, RM의 경우 10의 -23승, 10의 -18승으로 수치가 제일 낮은걸 알 수 있어. 그러면 이 2가지의 독립변수가 종속변수에 가장 큰 영향을 미쳤다고 해석하면 되는거야
표의 F값을 보고도 알 수 있지만 F값은 확률의 의미는 없기 때문에 단순 순위를 매기는거 라면 결정할 수 있지만 만약 귀무가설/대립가설을 accept 하냐 reject 하냐의 확률적 의미를 판단한다면 F값만으로는 불가능해</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="범주형을-사용한-비선형성"><a href="#범주형을-사용한-비선형성" class="headerlink" title="범주형을 사용한 비선형성"></a>범주형을 사용한 비선형성</h5><pre><code>독립변수의 비선형성을 포착하는 또 다른 방법 중 하나는 강제로 범주형 값으로 만드는 것이다. 범주형 값이 되면서 독립변수의 오차가 생기지만 이로 인한 오차보다 비선형성으로 얻을 수 있는 이익이 클 수도 있다.

보스턴 집값 데이터에서 종속변수와 RM 변수의 관계는 선형에 가깝지만 방의 갯수가 아주 작아지거나 아주 커지면 선형모형에서 벗어난다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sns.scatterplot(x=<span class="string">"RM"</span>, y=<span class="string">"MEDV"</span>, data=df0, s=<span class="number">60</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="836" alt="output_39_0" src="https://user-images.githubusercontent.com/59719711/81926554-17754200-961d-11ea-9ea7-69b37349b510.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_rm = sm.OLS.from_formula(<span class="string">'MEDV ~ RM'</span>, data=df0)</span><br><span class="line">result_rm = model_rm.fit()</span><br><span class="line">print(result_rm.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.484
Model:                            OLS   Adj. R-squared:                  0.483
Method:                 Least Squares   F-statistic:                     471.8
Date:                Thu, 14 May 2020   Prob (F-statistic):           2.49e-74
Time:                        19:28:18   Log-Likelihood:                -1673.1
No. Observations:                 506   AIC:                             3350.
Df Residuals:                     504   BIC:                             3359.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept    -34.6706      2.650    -13.084      0.000     -39.877     -29.465
RM             9.1021      0.419     21.722      0.000       8.279       9.925
==============================================================================
Omnibus:                      102.585   Durbin-Watson:                   0.684
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              612.449
Skew:                           0.726   Prob(JB):                    1.02e-133
Kurtosis:                       8.190   Cond. No.                         58.4
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


이렇게 RM 데이터 전체를 놓고 보면 종속변수 y와 아주 큰 상관관계가 있는것으로 보이지만 위에 그래프에서 봤듯이, 방의 갯수가 아주 적거나, 많으면 선형성을 보이지 않는 구간에 대해 조금 더 디테일하게 상관관게를 보고 싶다면 RM 데이터를 강제로 범주화 시켜 RM 데이터가 가지는 비선형성을 잡을 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rooms = np.arange(<span class="number">3</span>,<span class="number">10</span>)</span><br><span class="line">labels = [str(r) <span class="keyword">for</span> r <span class="keyword">in</span> rooms[:<span class="number">-1</span>]]</span><br><span class="line">df0[<span class="string">'CAT_RM'</span>] = np.round(df[<span class="string">'RM'</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sns.barplot(<span class="string">'CAT_RM'</span>, <span class="string">'MEDV'</span>, data=df0)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="836" alt="output_42_0" src="https://user-images.githubusercontent.com/59719711/81926587-222fd700-961d-11ea-88fb-a5ff2aec6b90.png">


<pre><code>이렇게 하면 RM 변수으로 인한 종속변수의 변화를 비선형 상수항으로 모형화 할 수 있다. 선형모형보다 성능이 향상된 것을 볼 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_rm2 = sm.OLS.from_formula(<span class="string">"MEDV ~ C(np.round(RM))"</span>, data=df0)</span><br><span class="line">result_rm2 = model_rm2.fit()</span><br><span class="line">print(result_rm2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.537
Model:                            OLS   Adj. R-squared:                  0.532
Method:                 Least Squares   F-statistic:                     115.8
Date:                Thu, 14 May 2020   Prob (F-statistic):           3.57e-81
Time:                        19:33:48   Log-Likelihood:                -1645.6
No. Observations:                 506   AIC:                             3303.
Df Residuals:                     500   BIC:                             3329.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
==========================================================================================
                             coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------------------
Intercept                 17.0200      2.814      6.049      0.000      11.492      22.548
C(np.round(RM))[T.5.0]    -2.0741      2.998     -0.692      0.489      -7.964       3.816
C(np.round(RM))[T.6.0]     2.3460      2.836      0.827      0.409      -3.226       7.918
C(np.round(RM))[T.7.0]    11.0272      2.869      3.843      0.000       5.389      16.665
C(np.round(RM))[T.8.0]    28.5425      3.093      9.228      0.000      22.466      34.619
C(np.round(RM))[T.9.0]    23.6133      4.595      5.139      0.000      14.586      32.641
==============================================================================
Omnibus:                       81.744   Durbin-Watson:                   0.799
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              467.887
Skew:                           0.542   Prob(JB):                    2.51e-102
Kurtosis:                       7.584   Cond. No.                         31.1
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><h5 id="시간-독립변수의-변형"><a href="#시간-독립변수의-변형" class="headerlink" title="시간 독립변수의 변형"></a>시간 독립변수의 변형</h5><pre><code>독립변수가 시간인 경우에는 특정 시점에서 경과된 시간값으로 변형해야 한다. 일간 전기 사용량 데이터를 예로 들어 설명한다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = sm.datasets.get_rdataset(<span class="string">"elecdaily"</span>, package=<span class="string">"fpp2"</span>)</span><br><span class="line"></span><br><span class="line">df_elec = data.data.drop(columns=[<span class="string">"WorkDay"</span>, <span class="string">"Temperature"</span>])</span><br><span class="line">df_elec[<span class="string">"Date"</span>] = pd.date_range(<span class="string">"2014-1-1"</span>, <span class="string">"2014-12-31"</span>)</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>파이썬 datetime 자료형은 toordinal 명령으로 특정 시점으로부터 경과한 시간의 일단위 값을 구하거나 timestamp 메서드로 초단위 값을 구할 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime <span class="keyword">as</span> dt</span><br><span class="line"></span><br><span class="line">df_elec[<span class="string">"Ordinal"</span>] = df_elec.Date.map(dt.datetime.toordinal)</span><br><span class="line">df_elec[<span class="string">"Timestamp"</span>] = df_elec.Date.map(dt.datetime.timestamp)</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
      <th>Ordinal</th>
      <th>Timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
      <td>735594</td>
      <td>1.419606e+09</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
      <td>735595</td>
      <td>1.419692e+09</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
      <td>735596</td>
      <td>1.419779e+09</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
      <td>735597</td>
      <td>1.419865e+09</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
      <td>735598</td>
      <td>1.419952e+09</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>여기에서는 일단위 시간 값을 사용하여 회귀분석을 한다. 시간 값의 경우 크기가 크므로 반드시 스케일링을 해 주어야 한다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model5 = sm.OLS.from_formula(<span class="string">"Demand ~ scale(Ordinal)"</span>, data=df_elec)</span><br><span class="line">result5 = model5.fit()</span><br><span class="line">print(result5.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Demand   R-squared:                       0.031
Model:                            OLS   Adj. R-squared:                  0.028
Method:                 Least Squares   F-statistic:                     11.58
Date:                Thu, 14 May 2020   Prob (F-statistic):           0.000739
Time:                        19:35:40   Log-Likelihood:                -1709.7
No. Observations:                 365   AIC:                             3423.
Df Residuals:                     363   BIC:                             3431.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        221.2775      1.374    160.997      0.000     218.575     223.980
scale(Ordinal)    -4.6779      1.374     -3.404      0.001      -7.381      -1.975
==============================================================================
Omnibus:                       43.105   Durbin-Watson:                   0.677
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               96.485
Skew:                           0.614   Prob(JB):                     1.12e-21
Kurtosis:                       5.199   Cond. No.                         1.00
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


하지만 시간 독립변수는 이 외에더 다양한 특징들을 숨기고 있다. 예들 들어 연도, 월, 일, 요일 데이터를 별도의 독립변수로 분리하거나 한 달 내에서 몇번째 날짜인지 월의 시작 또는 끝인지를 나타내는 값은 모두 특징값이 될 수 있다. 판다스에서는 dt 특수 연산자를 사용하여 이러한 값을 구할 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df_elec[<span class="string">"Year"</span>] = df_elec[<span class="string">'Date'</span>].dt.year</span><br><span class="line">df_elec[<span class="string">"Month"</span>] = df_elec.Date.dt.month</span><br><span class="line">df_elec[<span class="string">"DayOfYear"</span>] = df_elec.Date.dt.dayofyear</span><br><span class="line">df_elec[<span class="string">"DayOfMonth"</span>] = df_elec.Date.dt.daysinmonth</span><br><span class="line">df_elec[<span class="string">"DayOfWeek"</span>] = df_elec.Date.dt.dayofweek</span><br><span class="line">df_elec[<span class="string">"WeekOfYear"</span>] = df_elec.Date.dt.weekofyear</span><br><span class="line">df_elec[<span class="string">"Weekday"</span>] = df_elec.Date.dt.weekday</span><br><span class="line">df_elec[<span class="string">"IsMonthStart"</span>] = df_elec.Date.dt.is_month_start</span><br><span class="line">df_elec[<span class="string">"IsMonthEnd"</span>] = df_elec.Date.dt.is_month_end</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
      <th>Ordinal</th>
      <th>Timestamp</th>
      <th>Year</th>
      <th>Month</th>
      <th>DayOfYear</th>
      <th>DayOfMonth</th>
      <th>DayOfWeek</th>
      <th>WeekOfYear</th>
      <th>Weekday</th>
      <th>IsMonthStart</th>
      <th>IsMonthEnd</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
      <td>735594</td>
      <td>1.419606e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>361</td>
      <td>31</td>
      <td>5</td>
      <td>52</td>
      <td>5</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
      <td>735595</td>
      <td>1.419692e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>362</td>
      <td>31</td>
      <td>6</td>
      <td>52</td>
      <td>6</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
      <td>735596</td>
      <td>1.419779e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>363</td>
      <td>31</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
      <td>735597</td>
      <td>1.419865e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>364</td>
      <td>31</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
      <td>735598</td>
      <td>1.419952e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>365</td>
      <td>31</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>이렇게 추가적인 특징값을 이용하여 구한 모형은 성능이 향상된다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">feature_names = df_elec.columns.tolist()</span><br><span class="line">feature_names.remove(<span class="string">"Demand"</span>)</span><br><span class="line">feature_names.remove(<span class="string">"Date"</span>)</span><br><span class="line"></span><br><span class="line">formula = <span class="string">"""</span></span><br><span class="line"><span class="string">Demand ~ scale(Ordinal) + C(Month) + DayOfYear + </span></span><br><span class="line"><span class="string">         C(DayOfMonth) + C(DayOfWeek) + C(Weekday) + C(IsMonthStart) + C(IsMonthEnd)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">model6 = sm.OLS.from_formula(formula, data=df_elec)</span><br><span class="line">result6 = model6.fit()</span><br><span class="line">print(result6.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Demand   R-squared:                       0.537
Model:                            OLS   Adj. R-squared:                  0.511
Method:                 Least Squares   F-statistic:                     19.98
Date:                Thu, 14 May 2020   Prob (F-statistic):           4.74e-46
Time:                        19:37:49   Log-Likelihood:                -1574.8
No. Observations:                 365   AIC:                             3192.
Df Residuals:                     344   BIC:                             3273.
Df Model:                          20                                         
Covariance Type:            nonrobust                                         
===========================================================================================
                              coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------------------
Intercept                  58.6105      2.423     24.188      0.000      53.844      63.377
C(Month)[T.2]              14.5730      4.587      3.177      0.002       5.551      23.595
C(Month)[T.3]              -1.2369      8.663     -0.143      0.887     -18.276      15.802
C(Month)[T.4]             -29.1875     10.239     -2.851      0.005     -49.326      -9.049
C(Month)[T.5]              23.4037     15.493      1.511      0.132      -7.069      53.876
C(Month)[T.6]              11.3667      3.758      3.024      0.003       3.974      18.759
C(Month)[T.7]              64.8095     22.750      2.849      0.005      20.063     109.556
C(Month)[T.8]              66.5692     26.490      2.513      0.012      14.467     118.671
C(Month)[T.9]              22.7687      9.491      2.399      0.017       4.100      41.437
C(Month)[T.10]             59.0491     33.895      1.742      0.082      -7.619     125.717
C(Month)[T.11]             33.4276     16.778      1.992      0.047       0.427      66.429
C(Month)[T.12]             72.2523     41.334      1.748      0.081      -9.047     153.552
C(DayOfMonth)[T.30]        38.3755     13.530      2.836      0.005      11.763      64.988
C(DayOfMonth)[T.31]         5.6620      7.806      0.725      0.469      -9.691      21.015
C(DayOfWeek)[T.1]           3.4766      1.829      1.900      0.058      -0.121       7.075
C(DayOfWeek)[T.2]           1.5756      1.821      0.865      0.387      -2.006       5.157
C(DayOfWeek)[T.3]           2.8568      1.831      1.560      0.120      -0.745       6.459
C(DayOfWeek)[T.4]           0.8832      1.831      0.482      0.630      -2.719       4.485
C(DayOfWeek)[T.5]         -12.8982      1.831     -7.045      0.000     -16.499      -9.297
C(DayOfWeek)[T.6]         -16.4623      1.829     -8.999      0.000     -20.060     -12.864
C(Weekday)[T.1]             3.4766      1.829      1.900      0.058      -0.121       7.075
C(Weekday)[T.2]             1.5756      1.821      0.865      0.387      -2.006       5.157
C(Weekday)[T.3]             2.8568      1.831      1.560      0.120      -0.745       6.459
C(Weekday)[T.4]             0.8832      1.831      0.482      0.630      -2.719       4.485
C(Weekday)[T.5]           -12.8982      1.831     -7.045      0.000     -16.499      -9.297
C(Weekday)[T.6]           -16.4623      1.829     -8.999      0.000     -20.060     -12.864
C(IsMonthStart)[T.True]     1.2012      5.781      0.208      0.836     -10.169      12.571
C(IsMonthEnd)[T.True]       4.7608      5.781      0.824      0.411      -6.609      16.131
scale(Ordinal)           -101.7884      4.209    -24.182      0.000    -110.068     -93.509
DayOfYear                   0.6769      0.085      7.926      0.000       0.509       0.845
==============================================================================
Omnibus:                      150.460   Durbin-Watson:                   0.577
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1586.415
Skew:                           1.422   Prob(JB):                         0.00
Kurtosis:                      12.809   Cond. No.                     1.05e+18
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The smallest eigenvalue is 1.49e-29. This might indicate that there are
strong multicollinearity problems or that the design matrix is singular.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-13T09:33:34.000Z" title="2020-05-13T09:33:34.000Z">2020-05-13</time><span class="level-item">19 minutes read (About 2792 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/13/Linear-Regression-with-scale-categorical-regression-and-partial-regression/">Linear Regression with scale, categorical regression, and partial regression</a></h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> :</span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">'windows'</span>:</span><br><span class="line">        <span class="comment"># windows의 경우</span></span><br><span class="line">        font_name = font_manager.FomntProperties(fname=<span class="string">"c:/Windows/Font"</span>)</span><br><span class="line">        rc(<span class="string">'font'</span>, family = font_name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># mac의 경우</span></span><br><span class="line">        rc(<span class="string">'font'</span>, family = <span class="string">'AppleGothic'</span>)</span><br><span class="line"><span class="keyword">except</span> :</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h5 id="스케일링"><a href="#스케일링" class="headerlink" title="스케일링"></a>스케일링</h5><img width="542" alt="스크린샷 2020-05-13 오후 6 20 21" src="https://user-images.githubusercontent.com/59719711/81794987-8af85000-9546-11ea-80c2-df81105e3ee1.png">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>이 summary report는 어제 보스턴 집값 데이터를 활용하여 선형회귀분석을 한 결과값이야. 아랫부분의 Cond. No. 라고 쓰여져 있는 부분인데 조건수(conditional number)는 가장 큰 고유치와 가장 작은 고유치의 비율을 뜻해.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 14 columns</p>
</div>



<pre><code>이것은 일부러 TAX변수를 크게 만들어 조건수를 증폭시켜본 데이터야</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">dfX2 = dfX.copy()</span><br><span class="line">dfX2[<span class="string">"TAX"</span>] *= <span class="number">1e13</span></span><br><span class="line">df2 = pd.concat([dfX2, dfy], axis=<span class="number">1</span>)</span><br><span class="line">model2 = sm.OLS.from_formula(<span class="string">"MEDV ~ "</span> + <span class="string">"+"</span>.join(boston.feature_names), data=df2)</span><br><span class="line">result2 = model2.fit()</span><br><span class="line">print(result2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.333
Model:                            OLS   Adj. R-squared:                  0.329
Method:                 Least Squares   F-statistic:                     83.39
Date:                Wed, 13 May 2020   Prob (F-statistic):           8.62e-44
Time:                        16:03:11   Log-Likelihood:                -1737.9
No. Observations:                 506   AIC:                             3484.
Df Residuals:                     502   BIC:                             3501.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -0.0038      0.000     -8.543      0.000      -0.005      -0.003
CRIM          -0.1567      0.046     -3.376      0.001      -0.248      -0.066
ZN             0.1273      0.016      7.752      0.000       0.095       0.160
INDUS         -0.1971      0.019    -10.433      0.000      -0.234      -0.160
CHAS           0.0034      0.000     12.430      0.000       0.003       0.004
NOX           -0.0023      0.000     -9.285      0.000      -0.003      -0.002
RM             0.0267      0.002     14.132      0.000       0.023       0.030
AGE            0.1410      0.017      8.443      0.000       0.108       0.174
DIS           -0.0286      0.004     -7.531      0.000      -0.036      -0.021
RAD            0.1094      0.018      6.163      0.000       0.075       0.144
TAX         1.077e-15   2.66e-16      4.051      0.000    5.55e-16     1.6e-15
PTRATIO       -0.1124      0.011    -10.390      0.000      -0.134      -0.091
B              0.0516      0.003     19.916      0.000       0.046       0.057
LSTAT         -0.6569      0.056    -11.790      0.000      -0.766      -0.547
==============================================================================
Omnibus:                       39.447   Durbin-Watson:                   0.863
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               46.611
Skew:                           0.704   Prob(JB):                     7.56e-11
Kurtosis:                       3.479   Cond. No.                     1.19e+17
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.19e+17. This might indicate that there are
strong multicollinearity or other numerical problems.


조건수(Conditional No.)가 1000조 수준으로 증가한 것을 볼 수 있지? 오른쪽 제일 상단에 보이는 R-squared라는 값으로 표시되는 성능지표도 크게 감소한것을 볼 수 있어. R-squared 는 이 모델 성능에 대해 몇점인지를 알려주는 기능이라고 보면 되(0.333으로 나왔으니 100점 만점에 33.3점이라는 소리야)

statsmodels에서는  scale() 이라는 명령을 사용하여 스케일링을 할 수 있는데, 이 방식으로 스케일을 하면 스케일링에 사용된 평균과 표준편차를 저장하였다가 나중에 predict() 라는 명령을 사용할 때도 같은 스케일을 사용하기 때문에 편리한 것을 알 수 있어. 다만! 스케일링을 할 때에는 카테고리 변수, 즉 범주형 데이터는 스케일링을 하지 않는다는 것에 주의 해주면 되.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">feature_names = list(boston.feature_names)</span><br><span class="line">feature_names.remove(<span class="string">"CHAS"</span>) </span><br><span class="line">feature_names = [<span class="string">'scale(&#123;&#125;)'</span>.format(name) <span class="keyword">for</span> name <span class="keyword">in</span> feature_names] + [<span class="string">'CHAS'</span>]</span><br><span class="line">model3 = sm.OLS.from_formula(<span class="string">"MEDV ~ "</span> + <span class="string">"+"</span>.join(feature_names), data=df2)</span><br><span class="line">result3 = model3.fit()</span><br><span class="line">print(result3.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.741
Model:                            OLS   Adj. R-squared:                  0.734
Method:                 Least Squares   F-statistic:                     108.1
Date:                Wed, 13 May 2020   Prob (F-statistic):          6.72e-135
Time:                        16:11:05   Log-Likelihood:                -1498.8
No. Observations:                 506   AIC:                             3026.
Df Residuals:                     492   BIC:                             3085.
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         22.3470      0.219    101.943      0.000      21.916      22.778
scale(CRIM)       -0.9281      0.282     -3.287      0.001      -1.483      -0.373
scale(ZN)          1.0816      0.320      3.382      0.001       0.453       1.710
scale(INDUS)       0.1409      0.421      0.334      0.738      -0.687       0.969
scale(NOX)        -2.0567      0.442     -4.651      0.000      -2.926      -1.188
scale(RM)          2.6742      0.293      9.116      0.000       2.098       3.251
scale(AGE)         0.0195      0.371      0.052      0.958      -0.710       0.749
scale(DIS)        -3.1040      0.420     -7.398      0.000      -3.928      -2.280
scale(RAD)         2.6622      0.577      4.613      0.000       1.528       3.796
scale(TAX)        -2.0768      0.633     -3.280      0.001      -3.321      -0.833
scale(PTRATIO)    -2.0606      0.283     -7.283      0.000      -2.617      -1.505
scale(B)           0.8493      0.245      3.467      0.001       0.368       1.331
scale(LSTAT)      -3.7436      0.362    -10.347      0.000      -4.454      -3.033
CHAS               2.6867      0.862      3.118      0.002       0.994       4.380
==============================================================================
Omnibus:                      178.041   Durbin-Watson:                   1.078
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126
Skew:                           1.521   Prob(JB):                    8.84e-171
Kurtosis:                       8.281   Cond. No.                         10.6
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


독립변수 데이터를 스케일링한것만으로 조건수의 수치가 확 내려간 것을 볼 수 있어. 어때? 쉽지?

조건수를 될 수 있으면 낮춰주는게 각 독립변수의 오차범위를 줄여줄 수 있다고 해. 그래서 큰 값의 데이터들은 스케일링을 통해 사이즈를 줄여주는 거지.</code></pre><h5 id="범주형-독립변수의-회귀분석"><a href="#범주형-독립변수의-회귀분석" class="headerlink" title="범주형 독립변수의 회귀분석"></a>범주형 독립변수의 회귀분석</h5><pre><code>이번에는 연속형 데이터가 아닌 범주형 데이터의 회귀분석을 하는 방법에 대해 알아보자! 범주형 데이터는 측정 결과가 몇 개의 범주 또는 향목의 형태로 나타나는 자료를 말하는데 그것을 숫자로 표현한 것이라고 할 수 있어. 예를 들면 남자는 1 여자는 0 이런식이지!

아무튼..

여기서 다룰 학습은 그러한 범주형 독립변수(데이터)의 회귀분석 모델링 시 에는 앞서 배운 더미변수화가 필수라는 거야. 풀랭크(full-rank) 방식과 축소랭크(reduced-rank) 방식이 있는데 풀랭크방식에서는 더미변수의 값을 원핫인코딩(one-hot-encoding) 방식으로 지정을 하는거야

예를 들어서..

남자는 1 이고 여자는 0 이면 
남자 : d1=1, d2=0
여자 : d1=0, d2=1 이런식으로 쓴다는 거지

축소랭크 방식에서는 특정한 하나의 범주값을 기준값(reference, baseline)으로 하고 기준값에 대응하는 더미변수의 가중치는 항상 1으로 놓아 계산 하는 방법이지

무슨 말인지 어렵지? 그럼 실 데이터로 예를 들어보도록 할게.

아래의 데이터는 1920년부터 1939년까지 영국 노팅험 지역의 기온을 나타낸 데이터야. 이 데이터에서 독립 변수는 월(monath)이며 범주값으로 처리를 할거야 그리고 value로 표기된 값이 종속변수인 해당 월의 평균 기온이라고 할 수 있지. 분석의 목적은 독립변수인 월 값을 이용하여 종속변수인 월 평균 기온을 예측하는 것이야.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> calendar <span class="keyword">import</span> isleap</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_partial_year</span><span class="params">(number)</span>:</span></span><br><span class="line">   <span class="comment">#연 단위 숫자에서 날짜를 계산하는 코드</span></span><br><span class="line">    year = int(number)</span><br><span class="line">    d = datetime.timedelta(days=(number - year) * (<span class="number">365</span> + isleap(year)))</span><br><span class="line">    day_one = datetime.datetime(year, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    date = d + day_one</span><br><span class="line">    <span class="keyword">return</span> date</span><br><span class="line"></span><br><span class="line">df_nottem = sm.datasets.get_rdataset(<span class="string">"nottem"</span>).data</span><br><span class="line"></span><br><span class="line">df_nottem[<span class="string">"date0"</span>] = df_nottem[[<span class="string">"time"</span>]].applymap(convert_partial_year)</span><br><span class="line">df_nottem[<span class="string">"date"</span>] = pd.DatetimeIndex(df_nottem[<span class="string">"date0"</span>]).round(<span class="string">'60min'</span>) + datetime.timedelta(seconds=<span class="number">3600</span>*<span class="number">24</span>)</span><br><span class="line">df_nottem[<span class="string">"month"</span>] = df_nottem[<span class="string">"date"</span>].dt.strftime(<span class="string">"%m"</span>).astype(<span class="string">'category'</span>)</span><br><span class="line"><span class="keyword">del</span> df_nottem[<span class="string">"date0"</span>], df_nottem[<span class="string">"date"</span>]</span><br><span class="line">df_nottem</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>time</th>
      <th>value</th>
      <th>month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1920.000000</td>
      <td>40.6</td>
      <td>01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1920.083333</td>
      <td>40.8</td>
      <td>02</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1920.166667</td>
      <td>44.4</td>
      <td>03</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1920.250000</td>
      <td>46.7</td>
      <td>04</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1920.333333</td>
      <td>54.1</td>
      <td>05</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>235</th>
      <td>1939.583333</td>
      <td>61.8</td>
      <td>08</td>
    </tr>
    <tr>
      <th>236</th>
      <td>1939.666667</td>
      <td>58.2</td>
      <td>09</td>
    </tr>
    <tr>
      <th>237</th>
      <td>1939.750000</td>
      <td>46.7</td>
      <td>10</td>
    </tr>
    <tr>
      <th>238</th>
      <td>1939.833333</td>
      <td>46.6</td>
      <td>11</td>
    </tr>
    <tr>
      <th>239</th>
      <td>1939.916667</td>
      <td>37.8</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
<p>240 rows × 3 columns</p>
</div>



<pre><code>박스플롯을 통해 해당 월에 종속변수데이터가 어디에 주로 모여있는지 확인을 해보는거야</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_nottem.boxplot(<span class="string">"value"</span>, <span class="string">"month"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="382" alt="output_14_0" src="https://user-images.githubusercontent.com/59719711/81795405-0a861f00-9547-11ea-8d19-a3c30dfdf966.png">


<pre><code>%% 범주형 독립변수의 경우 앞서 시행한 회귀분석에서 추가해준 상수항(add_constant)을 추가하지 않아.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 풀랭크 방식</span></span><br><span class="line">model = sm.OLS.from_formula(<span class="string">"value ~ C(month) + 0"</span>, df_nottem)</span><br><span class="line">result = model.fit()</span><br><span class="line">print(result.summary())</span><br><span class="line"></span><br><span class="line"><span class="comment"># C()로 카테고리로 처리</span></span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  value   R-squared:                       0.930
Model:                            OLS   Adj. R-squared:                  0.927
Method:                 Least Squares   F-statistic:                     277.3
Date:                Wed, 13 May 2020   Prob (F-statistic):          2.96e-125
Time:                        16:28:22   Log-Likelihood:                -535.82
No. Observations:                 240   AIC:                             1096.
Df Residuals:                     228   BIC:                             1137.
Df Model:                          11                                         
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------
C(month)[01]    39.6950      0.518     76.691      0.000      38.675      40.715
C(month)[02]    39.1900      0.518     75.716      0.000      38.170      40.210
C(month)[03]    42.1950      0.518     81.521      0.000      41.175      43.215
C(month)[04]    46.2900      0.518     89.433      0.000      45.270      47.310
C(month)[05]    52.5600      0.518    101.547      0.000      51.540      53.580
C(month)[06]    58.0400      0.518    112.134      0.000      57.020      59.060
C(month)[07]    61.9000      0.518    119.592      0.000      60.880      62.920
C(month)[08]    60.5200      0.518    116.926      0.000      59.500      61.540
C(month)[09]    56.4800      0.518    109.120      0.000      55.460      57.500
C(month)[10]    49.4950      0.518     95.625      0.000      48.475      50.515
C(month)[11]    42.5800      0.518     82.265      0.000      41.560      43.600
C(month)[12]    39.5300      0.518     76.373      0.000      38.510      40.550
==============================================================================
Omnibus:                        5.430   Durbin-Watson:                   1.529
Prob(Omnibus):                  0.066   Jarque-Bera (JB):                5.299
Skew:                          -0.281   Prob(JB):                       0.0707
Kurtosis:                       3.463   Cond. No.                         1.00
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS.from_formula(<span class="string">"value ~ C(month)"</span>, df_nottem)</span><br><span class="line">result = model.fit()</span><br><span class="line">print(result.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  value   R-squared:                       0.930
Model:                            OLS   Adj. R-squared:                  0.927
Method:                 Least Squares   F-statistic:                     277.3
Date:                Wed, 13 May 2020   Prob (F-statistic):          2.96e-125
Time:                        16:32:20   Log-Likelihood:                -535.82
No. Observations:                 240   AIC:                             1096.
Df Residuals:                     228   BIC:                             1137.
Df Model:                          11                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         39.6950      0.518     76.691      0.000      38.675      40.715
C(month)[T.02]    -0.5050      0.732     -0.690      0.491      -1.947       0.937
C(month)[T.03]     2.5000      0.732      3.415      0.001       1.058       3.942
C(month)[T.04]     6.5950      0.732      9.010      0.000       5.153       8.037
C(month)[T.05]    12.8650      0.732     17.575      0.000      11.423      14.307
C(month)[T.06]    18.3450      0.732     25.062      0.000      16.903      19.787
C(month)[T.07]    22.2050      0.732     30.335      0.000      20.763      23.647
C(month)[T.08]    20.8250      0.732     28.450      0.000      19.383      22.267
C(month)[T.09]    16.7850      0.732     22.931      0.000      15.343      18.227
C(month)[T.10]     9.8000      0.732     13.388      0.000       8.358      11.242
C(month)[T.11]     2.8850      0.732      3.941      0.000       1.443       4.327
C(month)[T.12]    -0.1650      0.732     -0.225      0.822      -1.607       1.277
==============================================================================
Omnibus:                        5.430   Durbin-Watson:                   1.529
Prob(Omnibus):                  0.066   Jarque-Bera (JB):                5.299
Skew:                          -0.281   Prob(JB):                       0.0707
Kurtosis:                       3.463   Cond. No.                         12.9
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


축소랭크 방식 ( +0 제거) - &apos;기준이 되는 데이터 값에서  다른 범주형 데이터 값이 얼마나 다르냐&apos; 의 의미로 보면 됨, 즉 1월을 기준으로 2월에는 차이가 얼마나 있느냐 를 나타내는거야. 풀랭크 방식과 축소랭크 방식의 차이를 조금은 알 수 있게된거같아.

이 이상은 내가 이해를 못했기 때문에 넘어가도록 할게.</code></pre><h5 id="부분회귀"><a href="#부분회귀" class="headerlink" title="부분회귀"></a>부분회귀</h5><pre><code>만약 회귀분석을 한 후에 새로운 독립변수를 추가하여 다시 회귀분석을 한다면 그 전에 회귀분석으로 구했던 가중치의 값은 변할까 변하지 않을까? 예를 들어  𝑥1 이라는 독립변수만으로 회귀분석한 결과가 다음과 같다고 하자.</code></pre><img width="202" alt="스크린샷 2020-05-13 오후 4 49 48" src="https://user-images.githubusercontent.com/59719711/81795180-cdba2800-9546-11ea-9243-aeeca5cda269.png">

<pre><code>이 때 새로운 독립변수  𝑥2 를 추가하여 회귀분석을 하게 되면 이 때 나오는  𝑥1 에 대한 가중치  𝑤′1 가 원래의  𝑤1 과 같을까 다를까?</code></pre><img width="307" alt="스크린샷 2020-05-13 오후 4 49 52" src="https://user-images.githubusercontent.com/59719711/81795240-de6a9e00-9546-11ea-9ef1-5bd349d3ec8a.png">

<pre><code>답부터 말하자면

일반적으로  𝑤′1 의 값은 원래의  𝑤1 의 값과 다르다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfX0 = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfX = sm.add_constant(dfX0)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfX, dfy], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model_boston = sm.OLS(dfy, dfX)</span><br><span class="line">result_boston = model_boston.fit()</span><br><span class="line">print(result_boston.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.741
Model:                            OLS   Adj. R-squared:                  0.734
Method:                 Least Squares   F-statistic:                     108.1
Date:                Wed, 13 May 2020   Prob (F-statistic):          6.72e-135
Time:                        18:01:08   Log-Likelihood:                -1498.8
No. Observations:                 506   AIC:                             3026.
Df Residuals:                     492   BIC:                             3085.
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         36.4595      5.103      7.144      0.000      26.432      46.487
CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043
ZN             0.0464      0.014      3.382      0.001       0.019       0.073
INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141
CHAS           2.6867      0.862      3.118      0.002       0.994       4.380
NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262
RM             3.8099      0.418      9.116      0.000       2.989       4.631
AGE            0.0007      0.013      0.052      0.958      -0.025       0.027
DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084
RAD            0.3060      0.066      4.613      0.000       0.176       0.436
TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005
PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696
B              0.0093      0.003      3.467      0.001       0.004       0.015
LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425
==============================================================================
Omnibus:                      178.041   Durbin-Watson:                   1.078
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126
Skew:                           1.521   Prob(JB):                    8.84e-171
Kurtosis:                       8.281   Cond. No.                     1.51e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.51e+04. This might indicate that there are
strong multicollinearity or other numerical problems.


이렇게 보면 AGE는 집값을 결정하는데 음의 상관관계를 가진다고 볼 수 있다고 할 수 있어</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.regplot(x=<span class="string">"AGE"</span>, y=<span class="string">"MEDV"</span>, data=df)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="389" alt="output_25_0" src="https://user-images.githubusercontent.com/59719711/81795459-1c67c200-9547-11ea-9580-72d65bfab466.png">


<pre><code>plot_partregress(endog, exog_i, exog_others, data=None, obs_labels=True, ret_coords=False)

endog: 종속변수 문자열
exog_i: 분석 대상이 되는 독립변수 문자열
exog_others: 나머지 독립변수 문자열의 리스트
data: 모든 데이터가 있는 데이터프레임
obs_labels: 데이터 라벨링 여부
ret_coords: 잔차 데이터 반환 여부

하지만! 다른 독립변수에 영향을 받은 AGE가 집값에 영향을 미쳤는지에 대한 부분을 확인해보면 그래프는 다음과 같아.
AGE 데이터에 대한 부분회귀인셈이지.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">others = list(set(df.columns).difference(set([<span class="string">"MEDV"</span>, <span class="string">"AGE"</span>])))</span><br><span class="line">p, resids = sm.graphics.plot_partregress(</span><br><span class="line">    <span class="string">"MEDV"</span>, <span class="string">"AGE"</span>, others, data=df, obs_labels=<span class="literal">False</span>, ret_coords=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 크게 상관이 없다는 거로 나오게 되</span></span><br></pre></td></tr></table></figure>

<img width="395" alt="output_29_0" src="https://user-images.githubusercontent.com/59719711/81795521-2be70b00-9547-11ea-9d31-c7d0f66eedab.png">


<pre><code>sm.graphics.plot_partregress_grid 명령을 쓰면 전체 데이터에 대해 한번에 부분회귀 플롯을 그릴 수 있어.

plot_partregress_grid(result, fig)

result: 회귀분석 결과 객체
fig: plt.figure 객체</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">20</span>))</span><br><span class="line">sm.graphics.plot_partregress_grid(result_boston, fig=fig)</span><br><span class="line">fig.suptitle(<span class="string">""</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img width="563" alt="output_32_0" src="https://user-images.githubusercontent.com/59719711/81795567-399c9080-9547-11ea-8128-fc56699f56a0.png">


<pre><code>CCPR 플롯
CCPR(Component-Component plus Residual) 플롯도 부분회귀 플롯과 마찬가지로 특정한 하나의 변수의 영향을 살펴보기 위한 것이야

부분회귀분석과 비슷하지만 다른점이 하나 있는데 그것은 위에서 언급한 다른 변수에 영향을 받은 AGE가 아니라 AGE 데이터 그 자체와 집값의 상관관계를 보기위한 방법이라고 보면 되</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sm.graphics.plot_ccpr(result_boston, <span class="string">"AGE"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img width="395" alt="output_34_0" src="https://user-images.githubusercontent.com/59719711/81795631-49b47000-9547-11ea-9b2d-70d08594dd10.png">


<pre><code>CCPR 플롯에서는 부분회귀 플롯과 달리 독립변수가 원래의 값 그대로 나타난다는 점을 다시 한번 상기 시켜줄게</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">15</span>))</span><br><span class="line">sm.graphics.plot_ccpr_grid(result_boston, fig=fig)</span><br><span class="line">fig.suptitle(<span class="string">""</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img width="564" alt="output_36_0" src="https://user-images.githubusercontent.com/59719711/81795667-533dd800-9547-11ea-8b7d-5ca07cf8a5ed.png">


<pre><code>plot_regress_exog(result, exog_idx)

result: 회귀분석 결과 객체
exog_idx: 분석 대상이 되는 독립변수 문자열</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = sm.graphics.plot_regress_exog(result_boston, <span class="string">"AGE"</span>)</span><br><span class="line">plt.tight_layout(pad=<span class="number">4</span>, h_pad=<span class="number">0.5</span>, w_pad=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="356" alt="output_38_0" src="https://user-images.githubusercontent.com/59719711/81795721-62248a80-9547-11ea-9e1f-12d645504968.png">
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-12T09:28:55.000Z" title="2020-05-12T09:28:55.000Z">2020-05-12</time><span class="level-item">10 minutes read (About 1558 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/12/%E1%84%89%E1%85%A5%E1%86%AB%E1%84%92%E1%85%A7%E1%86%BC%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8_%E1%84%8C%E1%85%A5%E1%86%BC%E1%84%85%E1%85%B5/">선형회귀분석 정리</a></h1><div class="content"><p>선형회귀분석 정리<br>오늘의 데이터 사이언스 스쿨에서는 본격적으로 제대로 된 선형회귀분석에 대해 배울 수 있었어. 또 배운 내용을 바탕으로 파이썬을 이용하여 패키지를 이용해 직접 구현해볼 수도 있었는데, 요약된 정보들이 가지는 함축적인 의미가 있어. 길고, 어려운 내용들이었지만 간신히 맥락은 잡고 있는 것 같아 잊기 전에 빠른 정리를 통해 복습을 하려고 해. listen.</p>
<p>우선 선형회귀분석이란, 종속 변수 y와 한 개 이상의 독립 변수 x와의 선형 관계를 모델링하는 방법이야. 사실 이런 단어들을 이용해 설명하면 쉬운 것도 어렵게 느껴지기 마련인데, 내가 수업시간에 깨달은 선형회귀분석 내용은 아래와 같아.</p>
<img width="1214" alt="스크린샷 2020-05-12 오후 6 31 31" src="https://user-images.githubusercontent.com/59719711/81667918-e4954780-947e-11ea-9b8c-4591666ce580.png">

<p>seaborn 데이터셋에 있는 tip 데이터를 가져와봤어. 총 지출 비용, 팁의 금액, 팁을 준 사람의 성별과 흡연 여부, 요일 시간, 함께 온 인원들의 정보 나열되어 있네. 막무가내로 서로 연관성 없이 나열되어 있는 것 같은 이 데이터들 속에서 그 어떤 상관성이 있을까?<br>가령, 식사 인원이 많으면 많을 수록 팁의 비용이 커지거나, 저녁 타임에 오는 손님이 팁을 더 많이 준다 등 데이터를 통해 이러한 인사이트를 얻어 내야 하는 것인데, 이러한 선형회귀분석은 이러한 데이터의 성별, 흡연여부, 식사 시간대 등과 같은 데이터(독립변수, x)들이 팁(종속변수, y)에 영향을 주는지, 혹은 영향을 주지 않는지, 영향을 주면 어떤 항목이 가장 영향을 많이 주는지 알 수 있는 방법 중에 하나라고 할 수 있지.</p>
<p>그렇다면 팁 데이터를 벡터값 y로 놓고 나머지 벡터들, 즉 나머지 행렬 데이터를 x로 놓고 일반적으로 알고 있는 ‘y = wx’를  만들 수 있겠지? 여기서 기울기에 해당하는 ‘w’가 바로 우리가 알고 싶어 하는 가중치라는 것이야.<br>x의 항목들(성별, 흡연여부, 식사시간대 등) 중 어떤 항목이 팁이 많고 적음에 상관이 있는지, 즉 팁에 긍정적인 영향을 미쳐서 팁의 금액이 올라가게 하는지, 혹은 부정적인 영향을 미쳐서 팁의 금액을 내려가게 하는지, 혹은 전혀 상관이 없는지 말야.</p>
<p>이 때 wx를 x에 대한 함수로 나타난다면 y와 x 의 관계는 이렇게 정리할 수 있어.</p>
<p><img src="https://user-images.githubusercontent.com/59719711/81668790-1fe44600-9480-11ea-9fc9-3e84c3effece.png" alt="image"><br>(어렵다 참)</p>
<p>아무튼!</p>
<p>여기서 y 위의 ^와 물결표가 붙으면서 좀 더 깊게 들어가게 되는데, ^가 붙은 y를 y hat이라고 해. y는 우리가 마주하고 있는 현실 세계에서 일어난 실제 데이터이고, y hat은 예측한 가중치, w의 영향을 받은 ‘예측값’이라고 할 수 있어. 때문에 우리가 원하는 것은 어떤 값을 가질 지 모르는 가중치 w의 값을 조정하여 우리가 예측한 예측치 y hat과 실제 발생한 데이터 값 y의 차이(잔차)를 줄이는 것이라고 할 수 있지.</p>
<p><img src="https://user-images.githubusercontent.com/59719711/81669155-c2042e00-9480-11ea-9862-63dcd2791f4c.png" alt="image (1)"></p>
<p>언급했던 y, y hat, w 모두는 스칼라 값이 아니라 벡터 혹은 행렬의 형태를 갖추고 있어. 위의 사진에서 가중치 값 w는 이 선형회귀 모형의 모수 즉 parameter 야. 그리고 x1, x2 … 는 tip 데이터에서는 종속 변수 tip데이터를 제외한 나머지, 즉 성별, 흡연여부, 식사 시간대 등이 되는거야.</p>
<p>우선 선형회귀분석에 결정론적 방법과 확률론적 방법이라는 2가지 방법이 있어. 결정론적 방법은 단순하게 독립변수 x에 대응하는 종속변수 y 값을 계산하는 함수를 만들어 내는 것인 반면 확률론적 방법은 이름 그대로 x, y 뒤에 어떤 ‘확률 모형’이 숨어져 있다는 가정이 ‘추가’되는데, 이 가정이 추가됨으로써 결정론적 방법보다 더 많은 정보를 가지고 시작하게 된다고 할 수 있지.(비록 가정이라 할지라도) 더 많은 정보를 가지고 시작함으로써 결정론적 방법보다 조금 더 깊은 인사이트를 도출할 수 있어.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> :</span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">'windows'</span>:</span><br><span class="line">        <span class="comment"># windows의 경우</span></span><br><span class="line">        font_name = font_manager.FomntProperties(fname=<span class="string">"c:/Windows/Font"</span>)</span><br><span class="line">        rc(<span class="string">'font'</span>, family = font_name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># mac의 경우</span></span><br><span class="line">        rc(<span class="string">'font'</span>, family = <span class="string">'AppleGothic'</span>)</span><br><span class="line"><span class="keyword">except</span> :</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 14 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot(df[[<span class="string">'MEDV'</span>,<span class="string">'RM'</span>]])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.PairGrid at 0x1a2a600f90&gt;</code></pre><img width="361" alt="output_3_1" src="https://user-images.githubusercontent.com/59719711/81673250-4dcc8900-9486-11ea-98f7-683760804f5c.png">




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot(df[[<span class="string">'MEDV'</span>,<span class="string">'CRIM'</span>]])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.PairGrid at 0x1a2a60d0d0&gt;</code></pre><img width="361" alt="output_4_1" src="https://user-images.githubusercontent.com/59719711/81673306-68066700-9486-11ea-8088-860245701f6e.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot(df[[<span class="string">'MEDV'</span>,<span class="string">'AGE'</span>]])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.PairGrid at 0x1a2adfd150&gt;</code></pre><img width="370" alt="output_5_1" src="https://user-images.githubusercontent.com/59719711/81673336-76548300-9486-11ea-9485-ba132d64d474.png">


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot(df[[<span class="string">'MEDV'</span>,<span class="string">'CHAS'</span>]])</span><br></pre></td></tr></table></figure>




<pre><code>&lt;seaborn.axisgrid.PairGrid at 0x1a2b239d50&gt;</code></pre><img width="365" alt="output_6_1" src="https://user-images.githubusercontent.com/59719711/81673361-82404500-9486-11ea-88e0-0472e2c33a37.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br><span class="line"></span><br><span class="line">model = LinearRegression().fit(dfx, dfy)</span><br><span class="line">predicted = model.predict(dfx)</span><br><span class="line">plt.scatter(dfy, predicted, s=<span class="number">10</span>)</span><br><span class="line">plt.xlabel(<span class="string">"실제 가격"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"예측 가격"</span>)</span><br><span class="line">plt.title(<span class="string">"보스턴 주택가격 예측결과"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="389" alt="output_7_0" src="https://user-images.githubusercontent.com/59719711/81673398-8c624380-9486-11ea-9678-bac5f9e74d4c.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS(dfy, dfx)</span><br><span class="line">result = model.fit()</span><br><span class="line">result.params</span><br></pre></td></tr></table></figure>




<pre><code>CRIM      -0.092897
ZN         0.048715
INDUS     -0.004060
CHAS       2.853999
NOX       -2.868436
RM         5.928148
AGE       -0.007269
DIS       -0.968514
RAD        0.171151
TAX       -0.009396
PTRATIO   -0.392191
B          0.014906
LSTAT     -0.416304
dtype: float64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(result.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                   MEDV   R-squared (uncentered):                   0.959
Model:                            OLS   Adj. R-squared (uncentered):              0.958
Method:                 Least Squares   F-statistic:                              891.3
Date:                Tue, 12 May 2020   Prob (F-statistic):                        0.00
Time:                        19:14:28   Log-Likelihood:                         -1523.8
No. Observations:                 506   AIC:                                      3074.
Df Residuals:                     493   BIC:                                      3128.
Df Model:                          13                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
CRIM          -0.0929      0.034     -2.699      0.007      -0.161      -0.025
ZN             0.0487      0.014      3.382      0.001       0.020       0.077
INDUS         -0.0041      0.064     -0.063      0.950      -0.131       0.123
CHAS           2.8540      0.904      3.157      0.002       1.078       4.630
NOX           -2.8684      3.359     -0.854      0.394      -9.468       3.731
RM             5.9281      0.309     19.178      0.000       5.321       6.535
AGE           -0.0073      0.014     -0.526      0.599      -0.034       0.020
DIS           -0.9685      0.196     -4.951      0.000      -1.353      -0.584
RAD            0.1712      0.067      2.564      0.011       0.040       0.302
TAX           -0.0094      0.004     -2.395      0.017      -0.017      -0.002
PTRATIO       -0.3922      0.110     -3.570      0.000      -0.608      -0.176
B              0.0149      0.003      5.528      0.000       0.010       0.020
LSTAT         -0.4163      0.051     -8.197      0.000      -0.516      -0.317
==============================================================================
Omnibus:                      204.082   Durbin-Watson:                   0.999
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1374.225
Skew:                           1.609   Prob(JB):                    3.90e-299
Kurtosis:                      10.404   Cond. No.                     8.50e+03
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 8.5e+03. This might indicate that there are
strong multicollinearity or other numerical problems.</code></pre></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-08T05:19:22.000Z" title="2020-05-08T05:19:22.000Z">2020-05-08</time><span class="level-item">16 minutes read (About 2342 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/08/%EB%8D%B0%EC%9D%B4%ED%84%B0%ED%94%84%EB%A0%88%EC%9E%84-%EB%B3%91%ED%95%A9%ED%95%98%EA%B8%B0-merge-concat/">데이터프레임 병합하기(merge, concat)</a></h1><div class="content"><p>복수의 데이터프레임을 하나로 만드는 과정을 만져보자</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df1 = pd.DataFrame(&#123;<span class="string">'국어'</span>:[<span class="number">87</span>, <span class="number">69</span>], <span class="string">'수학'</span>:[<span class="number">77</span>,<span class="number">96</span>]&#125;, index=[<span class="string">'홍길동'</span>, <span class="string">'임꺽정'</span>])</span><br><span class="line">df1</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>수학</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>홍길동</th>
      <td>87</td>
      <td>77</td>
    </tr>
    <tr>
      <th>임꺽정</th>
      <td>69</td>
      <td>96</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df2 = pd.DataFrame(&#123;<span class="string">'국어'</span>:[<span class="number">82</span>,<span class="number">81</span>], <span class="string">'영어'</span>:[<span class="number">86</span>,<span class="number">90</span>]&#125;, index=[<span class="string">'전봉준'</span>,<span class="string">'장길산'</span>])</span><br><span class="line">df2</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>전봉준</th>
      <td>82</td>
      <td>86</td>
    </tr>
    <tr>
      <th>장길산</th>
      <td>81</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df3 = pd.DataFrame(&#123;<span class="string">'국어'</span>:[<span class="number">82</span>,<span class="number">81</span>], <span class="string">'영어'</span>:[<span class="number">86</span>,<span class="number">90</span>]&#125;, index=[<span class="string">'전봉준'</span>,<span class="string">'장길산'</span>])</span><br><span class="line">df3</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>전봉준</th>
      <td>82</td>
      <td>86</td>
    </tr>
    <tr>
      <th>장길산</th>
      <td>81</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="concat함수"><a href="#concat함수" class="headerlink" title="concat함수"></a>concat함수</h3><pre><code>세로로 병합하기(그냥 아래로 붙이는거)

데이터프레임끼리 컬럼이 달라도 된다. (없는 컬럼엔 NaN값으로 알아서 채워짐)
근데, 데이터프레임간에 컬럼이 서로 다르면 sort=False를 넣어줘야 경고가 발생하지 않아

[sort 파라미터는 컬럼 이름을 정렬해주는 옵션]</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_concat1 = pd.concat([df1, df2, df3], sort=<span class="literal">False</span>)</span><br><span class="line">df_concat1</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>수학</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>홍길동</th>
      <td>87</td>
      <td>77.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>임꺽정</th>
      <td>69</td>
      <td>96.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>전봉준</th>
      <td>82</td>
      <td>NaN</td>
      <td>86.0</td>
    </tr>
    <tr>
      <th>장길산</th>
      <td>81</td>
      <td>NaN</td>
      <td>90.0</td>
    </tr>
    <tr>
      <th>전봉준</th>
      <td>82</td>
      <td>NaN</td>
      <td>86.0</td>
    </tr>
    <tr>
      <th>장길산</th>
      <td>81</td>
      <td>NaN</td>
      <td>90.0</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>가로로 병합하기 (위에 언급했듯이 axis=1 옵션만 주면 되)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_concat2 = pd.concat([df1, df2, df3], sort=<span class="literal">False</span>, axis=<span class="number">1</span>)</span><br><span class="line">df_concat2</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>수학</th>
      <th>국어</th>
      <th>영어</th>
      <th>국어</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>홍길동</th>
      <td>87.0</td>
      <td>77.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>임꺽정</th>
      <td>69.0</td>
      <td>96.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>전봉준</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>82.0</td>
      <td>86.0</td>
      <td>82.0</td>
      <td>86.0</td>
    </tr>
    <tr>
      <th>장길산</th>
      <td>NaN</td>
      <td>NaN</td>
      <td>81.0</td>
      <td>90.0</td>
      <td>81.0</td>
      <td>90.0</td>
    </tr>
  </tbody>
</table>
</div>



<p>쉽지?? 넘어가도록 할게</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="merge함수"><a href="#merge함수" class="headerlink" title="merge함수"></a>merge함수</h3><pre><code>공통 컬럼을 기준으로 병합하기 가능</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df1, df2)</span><br><span class="line"></span><br><span class="line">df1이랑 df2는 서로 겹치는 게 없어서 컬럼만 나오네</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>수학</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df1, df2, how=<span class="string">'outer'</span>)</span><br><span class="line"></span><br><span class="line">서로 겹치지 않는 부분은 그냥 NaN으로 채우면서 서로 병합하는거야</span><br><span class="line">방법은 how = <span class="string">'outer'</span> 파라미터를 쓰면 돼</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>수학</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>87</td>
      <td>77.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>69</td>
      <td>96.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>82</td>
      <td>NaN</td>
      <td>86.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>81</td>
      <td>NaN</td>
      <td>90.0</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>how 파라미터는 outer, inner만 있는게 아니야.
left, right도 있어</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df1, df2, how=<span class="string">'left'</span>)</span><br><span class="line"></span><br><span class="line">왼쪽꺼를 기준으로 놓고, 오른쪽의 데이터를 가져와서 합병시키되, </span><br><span class="line">오른쪽에서 가져올 데이터가 없는 자리에는 NaN값으로 채워 넣어줘</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>수학</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>87</td>
      <td>77</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>69</td>
      <td>96</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df1, df2, how=<span class="string">'right'</span>)</span><br><span class="line"></span><br><span class="line">마찬가지로 이거는 오른쪽을 기준으로</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>국어</th>
      <th>수학</th>
      <th>영어</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>82</td>
      <td>NaN</td>
      <td>86</td>
    </tr>
    <tr>
      <th>1</th>
      <td>81</td>
      <td>NaN</td>
      <td>90</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>merge 함수와 비슷한 기능의 join 이라는 함수도 있어</code></pre><p>근데 join함수는 merge랑 완전 같은 기능이라 따로 정리는 안할거야<br>이러한 기능이 필요할 땐 merge함수를 쓰면 되지</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>중복되는 데이터가 존재하는 경우의 열단위 병합(merge)</p>
<ul>
<li>어떻게든 조합을 만들어내니까 너무 걱정마</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_1 = pd.DataFrame(&#123;<span class="string">'아이디'</span>:[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>], <span class="string">'결제금액'</span>:[<span class="number">1000</span>, <span class="number">1200</span>, <span class="number">1700</span>, <span class="number">3200</span>]&#125;)</span><br><span class="line">df_1</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>아이디</th>
      <th>결제금액</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a</td>
      <td>1000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b</td>
      <td>1200</td>
    </tr>
    <tr>
      <th>2</th>
      <td>c</td>
      <td>1700</td>
    </tr>
    <tr>
      <th>3</th>
      <td>d</td>
      <td>3200</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_2 = pd.DataFrame(&#123;<span class="string">'아이디'</span>:[<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'c'</span>,<span class="string">'d'</span>], <span class="string">'적립금'</span>:[<span class="number">120</span>, <span class="number">1700</span>, <span class="number">200</span>, <span class="number">320</span>]&#125;)</span><br><span class="line">df_2</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>아이디</th>
      <th>적립금</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a</td>
      <td>120</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b</td>
      <td>1700</td>
    </tr>
    <tr>
      <th>2</th>
      <td>c</td>
      <td>200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>d</td>
      <td>320</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df_1, df_2)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>아이디</th>
      <th>결제금액</th>
      <th>적립금</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a</td>
      <td>1000</td>
      <td>120</td>
    </tr>
    <tr>
      <th>1</th>
      <td>b</td>
      <td>1200</td>
      <td>1700</td>
    </tr>
    <tr>
      <th>2</th>
      <td>c</td>
      <td>1700</td>
      <td>200</td>
    </tr>
    <tr>
      <th>3</th>
      <td>d</td>
      <td>3200</td>
      <td>320</td>
    </tr>
  </tbody>
</table>
</div>



<p>일단 기본 merge를 시켜서 모든 경우의수를 다 봐<br>그리고 나서 수정을 하든말든 오키?</p>
<pre><code>겹치는 컬럼이 2개 이상인 경우에는?</code></pre><p>간단해. 이럴때는 ‘on’ 이라는 파라미터를 사용하면 on값을 기준으로 merge가 되</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_a = pd.DataFrame(&#123;<span class="string">'고객명'</span>:[<span class="string">'길동'</span>,<span class="string">'길산'</span>],</span><br><span class="line">                    <span class="string">'데이터'</span>:[<span class="string">'2000'</span>,<span class="string">'1700'</span>],</span><br><span class="line">                    <span class="string">'날짜'</span>:[<span class="string">'2020-05-08'</span>, <span class="string">'2020-06-08'</span>]&#125;)</span><br><span class="line">df_a</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>데이터</th>
      <th>날짜</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>2000</td>
      <td>2020-05-08</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>1700</td>
      <td>2020-06-08</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_b = pd.DataFrame(&#123;<span class="string">'고객명'</span>:[<span class="string">'길동'</span>,<span class="string">'길산'</span>],</span><br><span class="line">                    <span class="string">'데이터'</span>:[<span class="string">'21세'</span>,<span class="string">'17세'</span>],</span><br><span class="line">                    &#125;)</span><br><span class="line">df_b</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>데이터</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>21세</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>17세</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df_a, df_b)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>데이터</th>
      <th>날짜</th>
    </tr>
  </thead>
  <tbody>
  </tbody>
</table>
</div>



<p>merge가 되지 않아. 왜냐믄 공통되는 컬럼이 2개가 되니깐 둘 다 참조를 하게되서.. 두 컬럼 사이에 교집합이 없으니 merge를 해도 소용이 없는거야</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.merge(df_a, df_b, on=<span class="string">'고객명'</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>데이터_x</th>
      <th>날짜</th>
      <th>데이터_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>2000</td>
      <td>2020-05-08</td>
      <td>21세</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>1700</td>
      <td>2020-06-08</td>
      <td>17세</td>
    </tr>
  </tbody>
</table>
</div>



<p>자 on 파라미터로 기준을 고객명으로 줬더니 출력이 됐어.<br>이거를 보면 알 수 있듯이, 기준열은 아니면서 이름이 같은 열인 경우에는 _x 와 _y가 붙어</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>_x 랑 _y가 좀 그렇지? 그러면 컬럼명을 변경을 하자</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">xx = pd.merge(df_a, df_b, on=<span class="string">'고객명'</span>)</span><br><span class="line">xx = xx.rename(columns=&#123;<span class="string">'데이터_x'</span>: <span class="string">'금액'</span>, <span class="string">'데이터_y'</span>:<span class="string">'나이'</span>&#125;)</span><br><span class="line">xx</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>금액</th>
      <th>날짜</th>
      <th>나이</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>2000</td>
      <td>2020-05-08</td>
      <td>21세</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>1700</td>
      <td>2020-06-08</td>
      <td>17세</td>
    </tr>
  </tbody>
</table>
</div>



<p>Good Job!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>공통 컬럼은 존재하지 않지만, 우리가 이름이 다른 두 컬럼을 지정해서 merge하라고 명령 할수도 있어</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_a</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>데이터</th>
      <th>날짜</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>2000</td>
      <td>2020-05-08</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>1700</td>
      <td>2020-06-08</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_b = df_b.rename(columns=&#123;<span class="string">'고객명'</span>:<span class="string">'이름'</span>&#125;)</span><br><span class="line">df_b</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>이름</th>
      <th>데이터</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>21세</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>17세</td>
    </tr>
  </tbody>
</table>
</div>



<p>자 해보자</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">merged = pd.merge(df_a, df_b, left_on=<span class="string">'고객명'</span>, right_on=<span class="string">'이름'</span>)</span><br><span class="line">merged</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>데이터_x</th>
      <th>날짜</th>
      <th>이름</th>
      <th>데이터_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>2000</td>
      <td>2020-05-08</td>
      <td>길동</td>
      <td>21세</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>1700</td>
      <td>2020-06-08</td>
      <td>길산</td>
      <td>17세</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>왼쪽의 고객명과 오른쪽의 이름이 같은 데이터를 병합하라는 의미네. ㅇㅋ 이렇게 되는구나. 그럼 이제 겹치는 컬럼을 지우자</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">merged.drop(<span class="string">'이름'</span>,axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">merged</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>고객명</th>
      <th>데이터_x</th>
      <th>날짜</th>
      <th>데이터_y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>길동</td>
      <td>2000</td>
      <td>2020-05-08</td>
      <td>21세</td>
    </tr>
    <tr>
      <th>1</th>
      <td>길산</td>
      <td>1700</td>
      <td>2020-06-08</td>
      <td>17세</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>??? : merge는 항상 컬럼 기준이야??</p>
<p>오~ 너 참 똑똑이구나?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Index를 기준으로 당연히 merge가 되</p>
<p>left_index, right_index 파라미터를 이용하면되는데,, 일단 해보자고</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">역사 = pd.DataFrame(&#123;<span class="string">'역사'</span>:[<span class="number">90</span>,<span class="number">82</span>]&#125;, index=[<span class="string">'필구'</span>,<span class="string">'봉구'</span>])</span><br><span class="line">역사</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>역사</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>필구</th>
      <td>90</td>
    </tr>
    <tr>
      <th>봉구</th>
      <td>82</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">수학 = pd.DataFrame(&#123;<span class="string">'수학'</span>:[<span class="number">81</span>,<span class="number">92</span>]&#125;, index=[<span class="string">'필구'</span>,<span class="string">'맹구'</span>])</span><br><span class="line">수학</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>수학</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>필구</th>
      <td>81</td>
    </tr>
    <tr>
      <th>맹구</th>
      <td>92</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">역사수학 = pd.merge(역사, 수학, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>)</span><br><span class="line">역사수학</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>역사</th>
      <th>수학</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>필구</th>
      <td>90</td>
      <td>81</td>
    </tr>
  </tbody>
</table>
</div>



<p>두 데이터에서 겹치는 index인 필구만 잡아서 추가해주네 ㅇㅋ?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">역사수학 = pd.merge(역사, 수학, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>, how=<span class="string">'outer'</span>)</span><br><span class="line">역사수학</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>역사</th>
      <th>수학</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>맹구</th>
      <td>NaN</td>
      <td>92.0</td>
    </tr>
    <tr>
      <th>봉구</th>
      <td>82.0</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>필구</th>
      <td>90.0</td>
      <td>81.0</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>그러면 이런 경우에는 어떻게 해야하는 거야?</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">역사 = pd.DataFrame(&#123;<span class="string">'역사'</span>:[<span class="number">90</span>,<span class="number">82</span>]&#125;, index=[<span class="string">'필구'</span>,<span class="string">'봉구'</span>])</span><br><span class="line">역사</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>역사</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>필구</th>
      <td>90</td>
    </tr>
    <tr>
      <th>봉구</th>
      <td>82</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">수학 = pd.DataFrame(&#123;<span class="string">'수학'</span>:[<span class="number">81</span>,<span class="number">92</span>],<span class="string">'이름'</span>:[<span class="string">'필구'</span>,<span class="string">'봉구'</span>]&#125;)</span><br><span class="line">수학</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>수학</th>
      <th>이름</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>81</td>
      <td>필구</td>
    </tr>
    <tr>
      <th>1</th>
      <td>92</td>
      <td>봉구</td>
    </tr>
  </tbody>
</table>
</div>



<p>이 두개를 merge하고 싶은데,<br>서로 참조시킬 것이 하나는 index에 있고, 다른 하나는 column으로 갖고 있잖아..</p>
<p>이럴때 바로 left/right_index와 left/right_on을 응용해서 쉐킷쉐킷!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">역사수학_ = pd.merge(역사,수학, left_index=<span class="literal">True</span>, right_on=<span class="string">'이름'</span>)</span><br><span class="line">역사수학_</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>역사</th>
      <th>수학</th>
      <th>이름</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>90</td>
      <td>81</td>
      <td>필구</td>
    </tr>
    <tr>
      <th>1</th>
      <td>82</td>
      <td>92</td>
      <td>봉구</td>
    </tr>
  </tbody>
</table>
</div>



<h3 id="정리만-해주고-끝내자-힘들다"><a href="#정리만-해주고-끝내자-힘들다" class="headerlink" title="정리만 해주고 끝내자 힘들다!"></a>정리만 해주고 끝내자 힘들다!</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">역사수학_.index = 역사수학_[<span class="string">'이름'</span>].values</span><br><span class="line">역사수학_.drop(<span class="string">'이름'</span>, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line">역사수학_</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>역사</th>
      <th>수학</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>필구</th>
      <td>90</td>
      <td>81</td>
    </tr>
    <tr>
      <th>봉구</th>
      <td>82</td>
      <td>92</td>
    </tr>
  </tbody>
</table>
</div>


</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-07T00:58:34.000Z" title="2020-05-07T00:58:34.000Z">2020-05-07</time><span class="level-item">a minute read (About 181 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/07/Python-Pandas-%E1%84%8B%E1%85%A6%E1%84%89%E1%85%A5-%E1%84%90%E1%85%B3%E1%86%A8%E1%84%8C%E1%85%A5%E1%86%BC-%E1%84%8F%E1%85%A5%E1%86%AF%E1%84%85%E1%85%A5%E1%86%B7%E1%84%80%E1%85%A1%E1%86%B9%E1%84%8B%E1%85%B4-row%E1%84%85%E1%85%B3%E1%86%AF-%E1%84%8C%E1%85%A6%E1%84%80%E1%85%A5%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5/">Python Pandas 에서 특정 컬럼값의 row를 제거하기</a></h1><div class="content"><img width="791" alt="특정값제거1" src="https://user-images.githubusercontent.com/59719711/81243933-11df9100-904c-11ea-9c84-b72eb2064d8f.png">

<p>파이썬의 Pandas를 사용하면서 특정값의 row 가 존재할 때, 이 row를 제거하려면 그 값이 들어가는 row를 제외한 나머지 값들을 다시 dataframe으로 load하면 손쉽게 데이터를 처리할 수 있다.</p>
<p>위의 그림은 랜덤으로 생성한 데이터에서 몇몇 부분의 데이터가 0이 존재하는 그림이다. 여기에서 0값을 가지는 데이터를 제거하는 데이터 전처리 작업이다.</p>
<p>아래 그림은 그 결과값이다.</p>
<img width="508" alt="특정값제거2" src="https://user-images.githubusercontent.com/59719711/81244154-8b777f00-904c-11ea-8a9d-f38221055a60.png">

<p>null값이 아닌 특정값을 제거하고자 할 때 사용하면 데이터 전처리를 할 떄 매우 유용할 것으로 보인다.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-04T11:40:02.000Z" title="2020-05-04T11:40:02.000Z">2020-05-04</time><span class="level-item">2 minutes read (About 306 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/04/%E1%84%86%E1%85%AE%E1%86%AB%E1%84%8C%E1%85%A1%E1%84%92%E1%85%A7%E1%86%BC-%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5-%E1%84%89%E1%85%AE%E1%86%BA%E1%84%8C%E1%85%A1%E1%84%92%E1%85%A7%E1%86%BC%20%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%85%E1%85%A9%20%E1%84%87%E1%85%A7%E1%86%AB%E1%84%92%E1%85%AA%E1%86%AB%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5/">시계열 데이터 전처리하기</a></h1><div class="content"><p>Python pandas DataFrame 이나 Series 내 ‘문자열 칼럼’을 ‘숫자형’으로 변환(how to convert string columns to numeric data types in pandas DataFrame, Series) 하는 2가지 방법에 대한 해결책! </p>
<p>(1) pd.to_numeric() 함수를 이용한 문자열 칼럼의 숫자형 변환<br>(2) astype() 메소드를 이용한 문자열 칼럼의 숫자형 변환</p>
<p>1-1. 한개의 문자열 칼럼을 숫자형으로 바꾸기<br>변수명[‘새로운컬럼’] = pd.to_numeric(변수명[‘숫자형으로 바꿀 문자형 컬럼’])</p>
<p>1-2. apply() 함수와 to_numeric() 함수를 사용해 DataFrame 내 다수의 문자열 칼럼을 숫자형으로 바꾸기<br>변수명[[‘새로운컬럼1’, ‘새로운컬럼2’]] = 변수명[[‘기존컬럼’, ‘기존컬럼’]].apply(pd.to_numeric)</p>
<p>1-3. 모두 한번에 바꾸기<br>[새로운변수명] = [기존변수명].apply(pd.to_numeric)</p>
<p>2-1. DataFrame 내 모든 문자열 칼럼을 float로 한꺼번에 변환하기<br>[세로운변수명] = [변수명].astype(float)</p>
<p>2-2. DataFrame 내 문자열 칼럼별로 int, float 데이터 형식 개별 지정해서 숫자형으로 변환하기<br>[새로운변수명] = [변수명].astype({‘컬럼1’: int,<br> ‘컬럼2’: np.float})</p>
<ul>
<li>DataFrame에 문자가 포함된 칼럼이 같이 있을 경우 ValueError</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-29T08:20:04.000Z" title="2020-04-29T08:20:04.000Z">2020-04-29</time><span class="level-item">4 minutes read (About 659 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/29/%EA%B3%B5%EA%B3%B5%EB%8D%B0%EC%9D%B4%ED%84%B0csv-%ED%95%9C%EA%B8%80%EA%B9%A8%EC%A7%90%ED%98%84%EC%83%81-%EB%AC%B8%EC%A0%9C%ED%95%B4%EA%B2%B0-md/">공공데이터csv_한글깨짐현상_문제해결.md</a></h1><div class="content"><h2 id="pandas-공데이터-한글깨짐현상-문제해결"><a href="#pandas-공데이터-한글깨짐현상-문제해결" class="headerlink" title="pandas 공데이터 한글깨짐현상 문제해결"></a>pandas 공데이터 한글깨짐현상 문제해결</h2><ul>
<li>공공데이터 포털에서 다운로드 받은 csv파일을 pandas에서 로딩할 때 한글깨짐 현상을 해결하는 방법에 대하여 알아보겠습니다.</li>
<li>한글 깨짐 현상을 해결하기 전에 영어는 아무 문제가 없지만, 한글 파일을 읽어올 때는 종종 문제가 발생하게 됩니다.</li>
</ul>
<ol>
<li>Encoding. 기본적인 이해</li>
</ol>
<ul>
<li><p>문자형 데이터는 컴퓨터가 인식을 하지 못하기 때문에 우리는 이것을 컴퓨터가 이해할 수 있도록 Bit 형태로 변형해야합니다.</p>
</li>
<li><p>1Byte = 8Bit</p>
</li>
<li><p>Ascii 계열의 문자열은 0~127까지 표현되기 때문에 1Byte 안에 충분히 표현될 수 있습니다. 하지만, 한글은 Ascii 안에 표현이 불가하기 때문에 표현하기 위해서는 Byte가 충분히 더 필요합니다.</p>
</li>
<li><p>인코딩은 한글과 같은 Ascii 범위를 벗어난 문자를 표현하기 위한 변형 작업이라고 이해하시면 쉽습니다. 하지만, 문제는 이러한 인코딩 방식이 여러가지 입니다.</p>
</li>
</ul>
<ol start="2">
<li>공공데이터(csv) 파일의 encoding</li>
</ol>
<ul>
<li><p>공공데이터파일은 utf8 방식이면 좋겠으나, 아쉽게도(?) cp949 혹은 euc-kr 형식으로 인코딩이 되어 있습니다.</p>
</li>
<li><p>이러한 이유때문에 pandas에서 파일을 불러오면,,</p>
<ul>
<li>‘utf8 codec can’t decode byte 0xb1 in position 0: invalid start byte’</li>
</ul>
</li>
</ul>
<p>라는 에러메세지가 발생하게 됩니다.</p>
<ul>
<li>해결책1</li>
</ul>
<ul>
<li>pandas에서 파일을 불러올 시, ‘engine=python’ 이라는 코드를 같이 작성하기</li>
<li>df = pd.read_csv(‘test.csv’, engine=’python’)</li>
<li>불러오게 되면 작동은 하나 한글이 ???형식으로 나타나게 되기도 합니다.</li>
</ul>
<ul>
<li>해결책2</li>
</ul>
<ul>
<li>pandas에서 파일을 불러올 시, ‘encoding=utf8’ 이라는 코드를 같이 작성하기</li>
<li>df = pd.read_csv(‘test.csv’, encoding=’utf8’)</li>
<li>그러나 공공데이터의 경우 해결되지 않는 경우가 많습니다.</li>
</ul>
<ul>
<li>해결책3</li>
</ul>
<ul>
<li>Excel에서 파일의 인코딩 옵션 변경하기</li>
<li>파일을 불러온 후, 다름이름 저장하기를 통해 고급옵션의 파일인코딩 형식을 utf8로 변경 후 저장하기</li>
</ul>
<ul>
<li>해결책4<br>해결책1번의 코드를 작성한 후, encoding=cp949 라는 코드를 통해 불러오기<br>(이렇게 해서 공공데이터 불러오기를 성공하였으나, utf8의 호환성이 가장 좋기에 utf8로 불러오는 것이 가장 좋다고 판단되어집니다.)</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-27T10:24:50.859Z" title="2020-04-27T10:24:50.859Z">2020-04-27</time><span class="level-item">a minute read (About 219 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/27/wglee87DB-%EC%97%91%EC%85%80%ED%8C%8C%EC%9D%BC-insert%ED%95%98%EA%B8%B0/">wglee87DB-엑셀파일-insert하기</a></h1><div class="content"><h3 id="엑셀로-정리된-파일들을-mysql-데이터베이스로-한번에-가져오는-방법-기록용"><a href="#엑셀로-정리된-파일들을-mysql-데이터베이스로-한번에-가져오는-방법-기록용" class="headerlink" title="엑셀로 정리된 파일들을 mysql 데이터베이스로 한번에 가져오는 방법(기록용)"></a>엑셀로 정리된 파일들을 mysql 데이터베이스로 한번에 가져오는 방법(기록용)</h3><ol>
<li>엑셀파일의 전처리 작업<ul>
<li>가져올 데이터만 남기고 열 이름은 삭제</li>
</ul>
</li>
</ol>
<ol start="2">
<li>엑셀파일을 csv파일로 저장<ul>
<li>다른이름으로 저장하기 &gt; encoding=utf8 (utf8 미설정 시 한글폰트가 깨질 수 있음) &gt; 확장자 csv로<br>저장하기</li>
</ul>
</li>
</ol>
<ol start="3">
<li>mysql로 접속하기<ul>
<li>mysql에 접속 (필자는 sequel pro를 활용)</li>
</ul>
</li>
</ol>
<ol start="4">
<li>데이터베이스, 테이블 생성 및 encoding 변환<ul>
<li>단, 테이블 구조와 csv파일 구조가 같아야함</li>
<li>CREATE TABLE [테이블명](column이름 텍스트형식)</li>
<li>encoding=utf8로 변환</li>
<li>ALTER DATABASE [DB명] CHARACTER SET = utf8</li>
<li>ALTER TABLE [테이블명] CHARACTER SET = utf8</li>
</ul>
</li>
</ol>
<ol start="5">
<li>데이터 insert<ul>
<li>LOAD DATA LOCAL INFILE [FILE_PATH] INTO TABLE DB명.TABLE명 FIELDS TERMINATED BY ‘,’;</li>
</ul>
</li>
</ol>
<hr>
<p>title: ‘[wglee87DB] 엑셀파일 insert하기’<br>date: 2020-04-27 19:24:50<br>tags:</p>
<hr>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-25T05:56:58.189Z" title="2020-04-25T05:56:58.189Z">2020-04-25</time><span class="level-item">a few seconds read (About 32 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/25/%EA%B3%B5%EB%B6%80%EB%82%B4%EC%9A%A9/">공부내용</a></h1><div class="content"><ol>
<li>markdown, vim, git 기초개념</li>
<li>github에 repo 생성 후 파일 add, commit, push 하는 방법</li>
<li>github 블로그 생성 (hexo를 통해)</li>
</ol>
<hr>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-04-22T12:03:11.853Z" title="2020-04-22T12:03:11.853Z">2020-04-22</time><span class="level-item">a few seconds read (About 43 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/04/22/200422-%EA%B3%B5%EB%B6%80%EB%82%B4%EC%9A%A9/">200422-공부내용</a></h1><div class="content"><ol>
<li><p>수학(math)</p>
<ul>
<li>데이터분석에서의 미,적분</li>
<li>최적화(optimize)</li>
</ul>
</li>
<li><p>git</p>
<ul>
<li>2번째 강의(branch 강의)</li>
<li>첫번째 협업 연습(fork and merge)</li>
</ul>
</li>
</ol>
<hr>
<p>title: 200422-공부내용<br>date: 2020-04-22 21:00:53<br>tags:</p>
<hr>
</div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Your name"></figure><p class="title is-size-4 is-block line-height-inherit">Your name</p><p class="is-size-6 is-block">Your title</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Your location</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/ppoffice"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-23T10:40:19.000Z">2020-06-23</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/23/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5-PCA-%EC%A3%BC%EC%84%B1%EB%B6%84-%EB%B6%84%EC%84%9D/">비지도학습 : PCA 주성분 분석</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-17T11:38:49.000Z">2020-06-17</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/17/mglearn%EC%97%90-%EB%8C%80%ED%95%B4/">mglearn에 대해</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-13T08:39:13.000Z">2020-06-13</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/13/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-Data-Scaling-with-sklearn/">데이터 전처리(Data Scaling with sklearn)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-09T10:02:14.000Z">2020-06-09</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/09/Mysql-Database-%EC%9A%A9%EB%9F%89-%ED%99%95%EC%9D%B8/">[Mysql]Database 용량 확인</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-04T11:22:46.000Z">2020-06-04</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/04/DataFrame-Functions/">DataFrame Functions</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/fastcampus/"><span class="tag">fastcampus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Geony Data World" height="28"></a><p class="size-small"><span>&copy; 2020 WGLee87</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://wglee87.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>