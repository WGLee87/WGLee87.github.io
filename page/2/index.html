<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Geony&#039;s Tech Blog</title><meta description="Data Analyst&amp;#39;s blog"><meta property="og:type" content="blog"><meta property="og:title" content="Geony&#039;s Tech Blog"><meta property="og:url" content="http://wglee87.github.io/"><meta property="og:site_name" content="Geony&#039;s Tech Blog"><meta property="og:description" content="Data Analyst&amp;#39;s blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://wglee87.github.io/img/og_image.png"><meta property="article:author" content="wglee87"><meta property="article:tag" content="data_analysis"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://wglee87.github.io"},"headline":"Geony's Tech Blog","image":["http://wglee87.github.io/img/og_image.png"],"author":{"@type":"Person","name":"WGLee87"},"description":"Data Analyst&#39;s blog"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/" alt="Geony&#039;s Tech Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="/null">Download on GitHub</a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-06-13T08:39:13.000Z" title="2020-06-13T08:39:13.000Z">2020-06-13</time><span class="level-item">11 minutes read (About 1611 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/06/13/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-Data-Scaling-with-sklearn/">ë°ì´í„° ì „ì²˜ë¦¬(Data Scaling with sklearn)</a></h1><div class="content"><pre><code>ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì´ë€ ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •ì˜ í•˜ë‚˜ì…ë‹ˆë‹¤.

ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì„ í•´ì£¼ëŠ” ì´ìœ ëŠ” ë°ì´í„°ì˜ ê°’ì´ ë„ˆë¬´ í¬ê±°ë‚˜ í˜¹ì€ ì‘ì€ ê²½ìš°ì— ëª¨ë¸ ì•Œê³ ë¦¬ì¦˜ í•™ìŠµê³¼ì •ì—ì„œ 0ìœ¼ë¡œ ìˆ˜ë ´í•˜ê±°ë‚˜ ë¬´í•œìœ¼ë¡œ ë°œì‚°í•´ë²„ë¦´ ìˆ˜ ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ë”°ë¼ì„œ, scalingì€ ë°ì´í„° ì „ì²˜ë¦¬ ê³¼ì •ì—ì„œ êµ‰ì¥íˆ ì¤‘ìš”í•œ ê³¼ì •ì…ë‹ˆë‹¤.

ê°€ë³ê²Œ ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤</code></pre><h5 id="1-scaleì´ë€"><a href="#1-scaleì´ë€" class="headerlink" title="1. scaleì´ë€?"></a>1. scaleì´ë€?</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!pip install mglearn</span><br></pre></td></tr></table></figure>

<pre><code>Collecting mglearn
  Downloading mglearn-0.1.9.tar.gz (540 kB)
[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 540 kB 506 kB/s eta 0:00:01
[?25hRequirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (1.18.1)
Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (3.2.1)
Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (0.22.2.post1)
Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (1.0.3)
Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (7.0.0)
Requirement already satisfied: cycler in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (0.10.0)
Requirement already satisfied: imageio in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (2.8.0)
Requirement already satisfied: joblib in /opt/anaconda3/lib/python3.7/site-packages (from mglearn) (0.14.1)
Requirement already satisfied: python-dateutil&gt;=2.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib-&gt;mglearn) (2.8.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib-&gt;mglearn) (1.2.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from matplotlib-&gt;mglearn) (2.4.7)
Requirement already satisfied: scipy&gt;=0.17.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn-&gt;mglearn) (1.4.1)
Requirement already satisfied: pytz&gt;=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas-&gt;mglearn) (2019.3)
Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from cycler-&gt;mglearn) (1.14.0)
Building wheels for collected packages: mglearn
  Building wheel for mglearn (setup.py) ... [?25ldone
[?25h  Created wheel for mglearn: filename=mglearn-0.1.9-py2.py3-none-any.whl size=582638 sha256=6bf4e55bc798dd18a2ce5a5d67e6f134dfc35d54bb51cd8020f85b838a7173b1
  Stored in directory: /Users/wglee/Library/Caches/pip/wheels/f1/17/e1/1720d6dcd70187b6b6c3750cb3508798f2b1d57c9d3214b08b
Successfully built mglearn
Installing collected packages: mglearn
Successfully installed mglearn-0.1.9</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mglearn</span><br><span class="line">mglearn.plots.plot_scaling()</span><br></pre></td></tr></table></figure>


<img width="854" alt="output_3_0" src="https://user-images.githubusercontent.com/59719711/84565399-d602be80-ada3-11ea-95bc-d17cdde6b4a3.png">


<pre><code>(1) StandardScaler
ê° featureì˜ í‰ê· ì„ 0, ë¶„ì‚°ì„ 1ë¡œ ë³€ê²½í•©ë‹ˆë‹¤. ëª¨ë“  íŠ¹ì„±ë“¤ì´ ê°™ì€ ìŠ¤ì¼€ì¼ì„ ê°–ê²Œ ë©ë‹ˆë‹¤.


(2) RobustScaler
ëª¨ë“  íŠ¹ì„±ë“¤ì´ ê°™ì€ í¬ê¸°ë¥¼ ê°–ëŠ”ë‹¤ëŠ” ì ì—ì„œ StandardScalerì™€ ë¹„ìŠ·í•˜ì§€ë§Œ, í‰ê· ê³¼ ë¶„ì‚° ëŒ€ì‹  medianê³¼ quartileì„ ì‚¬ìš©í•©ë‹ˆë‹¤. RobustScalerëŠ” ì´ìƒì¹˜ì— ì˜í–¥ì„ ë°›ì§€ ì•ŠìŠµë‹ˆë‹¤.


(3) MinMaxScaler
ëª¨ë“  featureê°€ 0ê³¼ 1ì‚¬ì´ì— ìœ„ì¹˜í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤. ë°ì´í„°ê°€ 2ì°¨ì› ì…‹ì¼ ê²½ìš°, ëª¨ë“  ë°ì´í„°ëŠ” xì¶•ì˜ 0ê³¼ 1 ì‚¬ì´ì—, yì¶•ì˜ 0ê³¼ 1ì‚¬ì´ì— ìœ„ì¹˜í•˜ê²Œ ë©ë‹ˆë‹¤.


(4) Normalizer
StandardScaler, RobustScaler, MinMaxScalerê°€ ê° columnsì˜ í†µê³„ì¹˜ë¥¼ ì´ìš©í•œë‹¤ë©´ NormalizerëŠ” rowë§ˆë‹¤ ê°ê° ì •ê·œí™”ë©ë‹ˆë‹¤. NormalizerëŠ” ìœ í´ë¦¬ë“œ ê±°ë¦¬ê°€ 1ì´ ë˜ë„ë¡ ë°ì´í„°ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤. (ìœ í´ë¦¬ë“œ ê±°ë¦¬ëŠ” ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•  ë•Œ ì“°ëŠ” ë°©ë²•)</code></pre><h5 id="2-Code"><a href="#2-Code" class="headerlink" title="2. Code"></a>2. Code</h5><pre><code>scikit-learnì— ìˆëŠ” ì•„ì´ë¦¬ìŠ¤ ë°ì´í„°ì…‹ìœ¼ë¡œ ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.4</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<pre><code>ë°ì´í„°ë¥¼ í•™ìŠµìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„í• í–ˆìŠµë‹ˆë‹¤.

scalerë¥¼ ì‚¬ìš©í•˜ê¸° ì´ì „ì— ì£¼ì˜í•´ì•¼ë  ì ì„ ë¨¼ì € ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

scalerëŠ” fitê³¼ transform ë©”ì„œë“œë¥¼ ì§€ë‹ˆê³  ìˆìŠµë‹ˆë‹¤. fit ë©”ì„œë“œë¡œ ë°ì´í„° ë³€í™˜ì„ í•™ìŠµí•˜ê³ , transform ë©”ì„œë“œë¡œ ì‹¤ì œ ë°ì´í„°ì˜ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•©ë‹ˆë‹¤. 

ì´ë•Œ, fit ë©”ì„œë“œëŠ” í•™ìŠµìš© ë°ì´í„°ì—ë§Œ ì ìš©í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ í›„, transform ë©”ì„œë“œë¥¼ í•™ìŠµìš© ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì ìš©í•©ë‹ˆë‹¤. scalerëŠ” fit_transform()ì´ë€ ë‹¨ì¶• ë©”ì„œë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤. í•™ìŠµìš© ë°ì´í„°ì—ëŠ” fit_transform()ë©”ì„œë“œë¥¼ ì ìš©í•˜ê³ , í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ëŠ” transform()ë©”ì„œë“œë¥¼ ì ìš©í•©ë‹ˆë‹¤.</code></pre><h6 id="1-StandardScaler-code"><a href="#1-StandardScaler-code" class="headerlink" title="(1) StandardScaler code"></a>(1) StandardScaler code</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler</span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">X_train_scale = scaler.fit_transform(X_train)</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : &#123;&#125;'</span>.format(X_train.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : &#123;&#125;'</span>.format(X_train.max(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : &#123;&#125;'</span>.format(X_train_scale.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : &#123;&#125;'</span>.format(X_train_scale.max(axis=<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>

<pre><code>ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : [4.3 2.2 1.1 0.1]
ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : [7.9 4.4 6.9 2.5]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : [-1.73905934 -2.11220356 -1.37231262 -1.32054283]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : [2.32920943 3.06374081 1.74766642 1.68511841]</code></pre><h6 id="2-RobustScaler-code"><a href="#2-RobustScaler-code" class="headerlink" title="(2) RobustScaler code"></a>(2) RobustScaler code</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> RobustScaler</span><br><span class="line">scaler = RobustScaler()</span><br><span class="line">X_train_scale = scaler.fit_transform(X_train)</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : &#123;&#125;'</span>.format(X_train.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : &#123;&#125;'</span>.format(X_train.max(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : &#123;&#125;'</span>.format(X_train_scale.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : &#123;&#125;'</span>.format(X_train_scale.max(axis=<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>

<pre><code>ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : [4.3 2.2 1.1 0.1]
ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : [7.9 4.4 6.9 2.5]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : [-1.01818182 -1.47826087 -0.82993197 -0.70588235]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : [1.6        2.34782609 0.74829932 0.70588235]</code></pre><h6 id="3-MinMaxScaler-code"><a href="#3-MinMaxScaler-code" class="headerlink" title="(3) MinMaxScaler code"></a>(3) MinMaxScaler code</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">X_train_scale = scaler.fit_transform(X_train)</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : &#123;&#125;'</span>.format(X_train.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : &#123;&#125;'</span>.format(X_train.max(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : &#123;&#125;'</span>.format(X_train_scale.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : &#123;&#125;'</span>.format(X_train_scale.max(axis=<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>

<pre><code>ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : [4.3 2.2 1.1 0.1]
ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : [7.9 4.4 6.9 2.5]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : [0. 0. 0. 0.]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : [1. 1. 1. 1.]</code></pre><h6 id="4-Normalizer-code"><a href="#4-Normalizer-code" class="headerlink" title="(4) Normalizer code"></a>(4) Normalizer code</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> Normalizer </span><br><span class="line">scaler = Normalizer()</span><br><span class="line">X_train_scale = scaler.fit_transform(X_train)</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : &#123;&#125;'</span>.format(X_train.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : &#123;&#125;'</span>.format(X_train.max(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : &#123;&#125;'</span>.format(X_train_scale.min(axis=<span class="number">0</span>)))</span><br><span class="line">print(<span class="string">'ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : &#123;&#125;'</span>.format(X_train_scale.max(axis=<span class="number">0</span>)))</span><br></pre></td></tr></table></figure>

<pre><code>ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Min value : [4.3 2.2 1.1 0.1]
ìŠ¤ì¼€ì¼ ì¡°ì • ì „  features Max value : [7.9 4.4 6.9 2.5]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Min value : [0.67017484 0.2383917  0.16783627 0.0147266 ]
ìŠ¤ì¼€ì¼ ì¡°ì • í›„  features Max value : [0.86093857 0.60379053 0.63265489 0.2553047 ]</code></pre><h5 id="3-ì ìš©í•´ë³´ê¸°"><a href="#3-ì ìš©í•´ë³´ê¸°" class="headerlink" title="3. ì ìš©í•´ë³´ê¸°"></a>3. ì ìš©í•´ë³´ê¸°</h5><pre><code>ì˜ì‚¬ê²°ì •ë‚˜ë¬´(decisionTree)ë¡œ breat_cancer ë°ì´í„°ì…‹ì„ í•™ìŠµí•´ë³´ê² ìŠµë‹ˆë‹¤.
ë¨¼ì €, ë°ì´í„° ìŠ¤ì¼€ì¼ë§ì„ ì ìš©í•˜ì§€ ì•Šì€ ì±„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_breast_cancer</span><br><span class="line"></span><br><span class="line">cancer = load_breast_cancer()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=<span class="number">0</span>)</span><br><span class="line">tree = DecisionTreeClassifier(criterion=<span class="string">'entropy'</span>, max_depth=<span class="number">1</span>)</span><br><span class="line">tree.fit(X_train, y_train)</span><br><span class="line">print(<span class="string">'test accuracy : %3f'</span> %tree.score(X_test, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>test accuracy : 0.881119


ë‹¤ìŒì€ ë°ì´í„°ë¥¼ MinMaxScalerë¡œ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•˜ê³  ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ëª¨ë¸ë¡œ í•™ìŠµì‹œì¼œë³´ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">X_train_scale = scaler.fit_transform(X_train)</span><br><span class="line">X_test_scale = scaler.fit_transform(X_test)</span><br><span class="line">tree.fit(X_train_scale, y_train)</span><br><span class="line">print(<span class="string">'test accuracy : %3f'</span> %tree.score(X_test_scale, y_test))</span><br></pre></td></tr></table></figure>

<pre><code>test accuracy : 0.860140


ë¹„ìŠ·í•˜ê²Œ ë‚˜ì˜¨ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-06-09T10:02:14.000Z" title="2020-06-09T10:02:14.000Z">2020-06-09</time><span class="level-item">a few seconds read (About 62 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/06/09/Mysql-Database-%EC%9A%A9%EB%9F%89-%ED%99%95%EC%9D%B8/">[Mysql]Database ìš©ëŸ‰ í™•ì¸</a></h1><div class="content"><p>[ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ìš©ëŸ‰ í™•ì¸]<br>select table_schema â€˜Linear_Regressionâ€™, sum(data_length + index_length) / 1024 / 1024 â€˜size(MB)â€™ from information_schema.tables group by table_schema</p>
<p>[íŠ¹ì • DBëª… status í™•ì¸]<br>show table status like â€˜DBëª…â€™</p>
<p>[íŠ¹ì • DB ìš©ëŸ‰ ëŠ˜ë¦¬ê¸°]<br>alter table â€˜DBëª…â€™ max_rows = 400000000 avg_row_length=1500</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-06-04T11:22:46.000Z" title="2020-06-04T11:22:46.000Z">2020-06-04</time><span class="level-item">3 minutes read (About 403 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/06/04/DataFrame-Functions/">DataFrame Functions</a></h1><div class="content"><h6 id="ë°ì´í„°-ë¶„í¬-ë³€í™˜"><a href="#ë°ì´í„°-ë¶„í¬-ë³€í™˜" class="headerlink" title="ë°ì´í„° ë¶„í¬ ë³€í™˜"></a>ë°ì´í„° ë¶„í¬ ë³€í™˜</h6><pre><code>ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì€ ë³€ìˆ˜ê°€ íŠ¹ì • ë¶„í¬ë¥¼ ë”°ë¥¸ë‹¤ëŠ” ê°€ì •ì„ ê¸°ë°˜ìœ¼ë¡œ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì„ í˜• ëª¨ë¸ì˜ ê²½ìš°, ì¢…ì†ë³€ìˆ˜ê°€ ì •ê·œë¶„í¬ì™€ ìœ ì‚¬í•  ê²½ìš° ì„±ëŠ¥ì´ ë†’ì•„ì§€ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆë‹¤. ìì£¼ ì“°ì´ëŠ” ë°©ë²•ì€ Log, Exp, Sqrt ë“± í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ë°ì´í„° ë¶„í¬ë¥¼ ë³€í™˜í•˜ëŠ” ê²ƒì´ë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment"># íŠ¹ì • ë³€ìˆ˜ì—ë§Œ í•¨ìˆ˜ ì ìš©</span></span><br><span class="line">df[<span class="string">'X_log'</span>] = preprocessing.scale(np.log(df[<span class="string">'X'</span>]+<span class="number">1</span>)) <span class="comment"># ë¡œê·¸</span></span><br><span class="line">df[<span class="string">'X_sqrt'</span>] = preprocessing.scale(np.sqrt(df[<span class="string">'X'</span>]+<span class="number">1</span>)) <span class="comment"># ì œê³±ê·¼</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ë°ì´í„° í”„ë ˆì„ ì „ì²´ì— í•¨ìˆ˜ ì ìš© (ë‹¨, ìˆ«ìí˜• ë³€ìˆ˜ë§Œ ìˆì–´ì•¼ í•¨)</span></span><br><span class="line">df_log = df.apply(<span class="keyword">lambda</span> x: np.log(x+<span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<h6 id="ì¤‘ë³µëœ-í–‰-ì œê±°"><a href="#ì¤‘ë³µëœ-í–‰-ì œê±°" class="headerlink" title="ì¤‘ë³µëœ í–‰ ì œê±°"></a>ì¤‘ë³µëœ í–‰ ì œê±°</h6><pre><code>ìœ„, ì•„ë˜ í–‰ì´ ëª¨ë‘ ê°™ì€ ì„±ë¶„ì„ ê°€ì§€ëŠ” í–‰ì´ ì—¬ëŸ¬ê°œ ìˆì„ë•Œ, í•˜ë‚˜ë§Œ ì‚¬ìš©í•˜ê¸°(ë°ì´í„°í”„ë ˆì„)
ì¤‘ë³µëœ í–‰ì´ ì œê±°ë˜ê³  uniqueí•œ ê°’ë§Œ ê°€ì ¸ì˜¬ ìˆ˜ ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df.drop_duplicates()</span><br><span class="line"></span><br><span class="line">df.drop_duplicated() ëŠ” booleanê°’ìœ¼ë¡œ ë°˜í™˜!</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'name'</span>] = df[<span class="string">'name'</span>].apply(<span class="keyword">lambda</span> e: e.split()[<span class="number">0</span>])</span><br><span class="line">df[<span class="string">'email'</span>].str.get(i=<span class="number">0</span>)  ë°ì´í„°í”„ë ˆì„ì´ë‚˜ ì‹œë¦¬ì¦ˆí˜•ì‹ì—ì„œ ë¬¸ìë¥¼ ë‚˜ëˆ„ê³  [<span class="number">0</span>]ë²ˆì§¸ ë¬¸ìë§Œ ê°€ì ¸ì˜¤ê¸°</span><br></pre></td></tr></table></figure>

<h6 id="ë°ì´í„°-í”„ë ˆì„-ëª¨ë“ -ì—´ì—-íŠ¹ì •-ìŠ¤ì¹¼ë¼ê°’-or-íŠ¹ì •-ì»¬ëŸ¼-value-ì—°ì‚°"><a href="#ë°ì´í„°-í”„ë ˆì„-ëª¨ë“ -ì—´ì—-íŠ¹ì •-ìŠ¤ì¹¼ë¼ê°’-or-íŠ¹ì •-ì»¬ëŸ¼-value-ì—°ì‚°" class="headerlink" title="ë°ì´í„° í”„ë ˆì„ ëª¨ë“  ì—´ì— íŠ¹ì • ìŠ¤ì¹¼ë¼ê°’ or íŠ¹ì • ì»¬ëŸ¼.value ì—°ì‚°"></a>ë°ì´í„° í”„ë ˆì„ ëª¨ë“  ì—´ì— íŠ¹ì • ìŠ¤ì¹¼ë¼ê°’ or íŠ¹ì • ì»¬ëŸ¼.value ì—°ì‚°</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[ì»¬ëŸ¼ëª…] *= (ìŠ¤ì¹¼ë¼ê°’)  / í•´ë‹¹ ë°ì´í„°í”„ë ˆì„ ì»¬ëŸ¼ì´ ì™€ë„ ë¨</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[ì»¬ëŸ¼ëª…] = df[ì»¬ëŸ¼ëª…].div(ìŠ¤ì¹¼ë¼ê°’ <span class="keyword">or</span> ì»¬ëŸ¼, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>   a=10, b=20, c=3</p>
<p>   Operator    Description    Example<br>    +    ë”í•˜ê¸°             a + b        30<br>    -    ë¹¼ê¸°                a - b       -10<br>    *    ê³±í•˜ê¸°              a * b       200<br>    /    ë‚˜ëˆ„ê¸°              b / a        2.0<br>    % ë‚˜ë¨¸ì§€            b % a        0<br>    **    ì œê³±               a ** c      1000<br>    //    ëª«                 a // c          3</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-06-02T10:49:44.000Z" title="2020-06-02T10:49:44.000Z">2020-06-02</time><span class="level-item">a minute read (About 125 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/06/02/SQLite-db-view-tool-md/">SQLite db view tool.md</a></h1><div class="content"><p>DB Browser for SQLite</p>
<p><a href="http://sqlitebrowser.org/">http://sqlitebrowser.org/</a></p>
<p>ì‚¬ì´íŠ¸ ë“¤ì–´ê°€ì„œ, í•´ë‹¹ OSì—ì„œ ë§ëŠ” íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œ í•˜ì. ì„¤ì¹˜ ì™„ë£Œ í›„, í”„ë¡œê·¸ë¨ì„ ê°€ë™í•˜ì—¬, ì—´ê¸°ë¥¼ í†µí•´ SQLite ì˜ íŒŒì¼ì„ ì—´ì–´ì„œ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ì•„ë˜ì™€ ê°™ì´ ë³¼ ìˆ˜ ìˆë‹¤.</p>
<p><img src="https://user-images.githubusercontent.com/59719711/83511951-67537480-a50a-11ea-9bca-762b7deadfed.png" alt="screenshot"></p>
<p>ì‚¬ì´íŠ¸ì—ì„œ ì ‘ì†í•˜ì—¬ ìœ„ì— ì¹´í…Œê³ ë¦¬ ë¶€ë¶„ì— downloadë¥¼ í´ë¦­ í›„ í•´ë‹¹ OSì— ë§ëŠ” ê²ƒì„ ì„¤ì¹˜í•´ì£¼ë©´ ë.</p>
<p>ì‰½ì§€?</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-31T01:48:53.000Z" title="2020-05-31T01:48:53.000Z">2020-05-31</time><span class="level-item">2 minutes read (About 285 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/31/NodeJS-n-%E1%84%8B%E1%85%B3%E1%86%AF-%E1%84%90%E1%85%A9%E1%86%BC%E1%84%92%E1%85%A1%E1%84%8B%E1%85%A7-NodeJS-%E1%84%87%E1%85%A5%E1%84%8C%E1%85%A5%E1%86%AB-%E1%84%87%E1%85%A7%E1%86%AB%E1%84%80%E1%85%A7%E1%86%BC%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5/">[NodeJS]_n_á„‹á…³á†¯_á„á…©á†¼á„’á…¡á„‹á…§_NodeJS_á„‡á…¥á„Œá…¥á†«_á„‡á…§á†«á„€á…§á†¼á„’á…¡á„€á…µ</a></h1><div class="content"><pre><code>NodeJSì˜ ê²½ìš° ë²„ì „ ë³€ê²½ì´ êµ‰ì¥íˆ ì¦ê³  ë²„ì „ë§ˆë‹¤ ì˜ì¡´ì„± íŒ¨í‚¤ì§€ê°€ ë§¤ìš° í¬ê¸° ë•Œë¬¸ì— ì—¬ê¸°ì„œëŠ” NodeJS ë²„ì „ì„ ê°„ë‹¨íˆ ë³€ê²½í•˜ëŠ” n ì„ ì†Œê°œí•˜ë„ë¡ í• ê²Œ</code></pre><h6 id="1-npm-ì„-í†µí•˜ì—¬-n-ì„¤ì¹˜í•˜ê¸°"><a href="#1-npm-ì„-í†µí•˜ì—¬-n-ì„¤ì¹˜í•˜ê¸°" class="headerlink" title="1. npm ì„ í†µí•˜ì—¬ n ì„¤ì¹˜í•˜ê¸°"></a>1. npm ì„ í†µí•˜ì—¬ n ì„¤ì¹˜í•˜ê¸°</h6><pre><code>ìš°ì„  í˜„ì¬ nodejs ì˜ ë²„ì „ì„ í™•ì¸í•´ ë´…ë‹ˆë‹¤. </code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!node -v</span><br></pre></td></tr></table></figure>

<pre><code>v12.17.0


ê·¸ë¦¬ê³  npm ì„ í†µí•˜ì—¬ n ì„ global ë¡œ ì„¤ì¹˜í•˜ì! (nodeJSë¥¼ ì»¨íŠ¸ë¡¤ í•  ìˆ˜ ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¼ ì•„ì£¼ ì¤‘ìš”í•´!)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!sudo npm install -g n</span><br></pre></td></tr></table></figure>

<pre><code>Password:

ê·¸ë¦¬ê³  nì„ ì¬ëŒ€ë¡œ ì„¤ì¹˜ ë˜ì—ˆëŠ”ì§€ í™•ì¸ì„ ìœ„í•˜ì—¬ ë²„ì „ì„ í™•ì¸í•˜ë„ë¡ í•˜ì</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&lt;img width=<span class="string">"483"</span> alt=<span class="string">"á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-05-31 á„‹á…©á„Œá…¥á†« 10 43 54"</span> src=<span class="string">"https://user-images.githubusercontent.com/59719711/83342570-0a01cc80-a32c-11ea-83d3-a67d05de3533.png"</span>&gt;</span><br></pre></td></tr></table></figure>

<h6 id="2-n-ì„-ì´ìš©í•˜ì—¬-ë²„ì „-ë³€ê²½í•˜ê¸°"><a href="#2-n-ì„-ì´ìš©í•˜ì—¬-ë²„ì „-ë³€ê²½í•˜ê¸°" class="headerlink" title="2. n ì„ ì´ìš©í•˜ì—¬ ë²„ì „ ë³€ê²½í•˜ê¸°"></a>2. n ì„ ì´ìš©í•˜ì—¬ ë²„ì „ ë³€ê²½í•˜ê¸°</h6><pre><code>ë²„ì „ ë³€ê²½ë°©ë²•ì€ ë§¤ìš° ê°„ë‹¨í•´. n ë’¤ì— lts, latest í˜¹ì€ ë²„ì „ì„ ì ìœ¼ë©´ ë!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># lts ë²„ì „ ì„¤ì¹˜</span></span><br><span class="line">n lts</span><br><span class="line"> </span><br><span class="line"><span class="comment"># ìµœì‹  ë²„ì „ ì„¤ì¹˜</span></span><br><span class="line">n latest</span><br><span class="line"> </span><br><span class="line"><span class="comment"># íŠ¹ì • ë²„ì „ ì„¤ì¹˜</span></span><br><span class="line">n <span class="number">11</span></span><br></pre></td></tr></table></figure>

<pre><code>ë§ˆì§€ë§‰ìœ¼ë¡œ NodeJSì˜ ë²„ì „ì„ ë³€ê²½ í›„ í”„ë¡œì íŠ¸ì˜ node_modulesë¥¼ ì‚­ì œí•˜ê³  yarn í˜¹ì€ npmìœ¼ë¡œ íŒ¨í‚¤ì§€ë¥¼ ì¬ì„¤ì¹˜ í•˜ê±°ë‚˜ ì—…ê·¸ë ˆì´ë“œ í•˜ëŠ” ê²ƒì„ ì¶”ì²œí•´. ì•ˆê·¸ëŸ¬ë©´ ì¢…ì¢… ì˜¤ë¥˜ê°€ ë°œìƒí•´</code></pre></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-28T10:44:58.000Z" title="2020-05-28T10:44:58.000Z">2020-05-28</time><span class="level-item">3 minutes read (About 486 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/28/wget-%EC%84%A4%EC%B9%98%ED%95%98%EB%8A%94%EB%B2%95/">wget ì„¤ì¹˜í•˜ëŠ”ë²•</a></h1><div class="content"><h6 id="Mac-OS-Xì—ì„œ-wgetì„-ì„¤ì¹˜í•˜ëŠ”-ë°©ë²•"><a href="#Mac-OS-Xì—ì„œ-wgetì„-ì„¤ì¹˜í•˜ëŠ”-ë°©ë²•" class="headerlink" title="Mac OS Xì—ì„œ wgetì„ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•"></a>Mac OS Xì—ì„œ wgetì„ ì„¤ì¹˜í•˜ëŠ” ë°©ë²•</h6><pre><code>wgetëŠ” ì •ë§ í¸ë¦¬í•œ ëª…ë ¹ì¤„ ìœ í‹¸ë¦¬í‹°ì§€ë§Œ, ì•ˆíƒ€ê¹ê²Œë„ OS Xì—ëŠ” í¬í•¨ë˜ì§€ ì•Šì•˜ë‹¤. ë¬¼ë¡   Curlì€ ì ì ˆí•œ ëŒ€ì²´ë¬¼ì´ ë  ìˆ˜ ìˆì§€ë§Œ, ì¢…ì¢… wgetë¡œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì“°ì—¬ì§€ê³ , curlì„ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê²ƒì€ ì–´ë µê³  ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆì–´ì„œ wgetì´ ì„ í˜¸ë˜ëŠ” ê²½í–¥ì´ ìˆë‹¤.

homebrewë¡œ wgetì„ ì„¤ì¹˜í•˜ë©´ ëœë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!brew install wget</span><br></pre></td></tr></table></figure>

<pre><code>Updating Homebrew...
[34m==&gt;[0m [1mAuto-updated Homebrew![0m
Updated 2 taps (homebrew/core and homebrew/cask).
[34m==&gt;[0m [1mUpdated Formulae[0m
plenv               postgresql@11       swiftformat         tomee-webprofile
postgresql          postgresql@9.5      tomee-plume
postgresql@10       postgresql@9.6      tomee-plus
[34m==&gt;[0m [1mUpdated Casks[0m
cryo                                     switchresx

[33mWarning:[0m wget 1.20.3_2 is already installed and up-to-date
To reinstall 1.20.3_2, run `brew reinstall wget`</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!brew uninstall --force node</span><br><span class="line">!brew uninstall icu4c &amp;&amp; brew install icu4c</span><br><span class="line">!brew unlink icu4c &amp;&amp; brew link icu4c --force</span><br><span class="line">!brew install node</span><br></pre></td></tr></table></figure>

<pre><code>Uninstalling node... (4,660 files, 60.3MB)
[31mError:[0m Refusing to uninstall /usr/local/Cellar/icu4c/66.1
because it is required by graphviz, harfbuzz and pango, which are currently installed.
You can override this and force removal with:
  brew uninstall --ignore-dependencies icu4c
Unlinking /usr/local/Cellar/icu4c/66.1... 0 symlinks removed
[33mWarning:[0m Refusing to link macOS provided/shadowed software: icu4c
If you need to have icu4c first in your PATH run:
  echo &apos;export PATH=&quot;/usr/local/opt/icu4c/bin:$PATH&quot;&apos; &gt;&gt; /Users/wglee/.bash_profile
  echo &apos;export PATH=&quot;/usr/local/opt/icu4c/sbin:$PATH&quot;&apos; &gt;&gt; /Users/wglee/.bash_profile

For compilers to find icu4c you may need to set:
  export LDFLAGS=&quot;-L/usr/local/opt/icu4c/lib&quot;
  export CPPFLAGS=&quot;-I/usr/local/opt/icu4c/include&quot;
Updating Homebrew...
[34m==&gt;[0m [1mDownloading https://homebrew.bintray.com/bottles/node-14.3.0.catalina.bottle[0m
[34m==&gt;[0m [1mDownloading from https://akamai.bintray.com/e3/e34c4c25365bc0f5cc245d791dd93[0m
######################################################################## 100.0%
[34m==&gt;[0m [1mPouring node-14.3.0.catalina.bottle.tar.gz[0m
[34m==&gt;[0m [1mCaveats[0m
Bash completion has been installed to:
  /usr/local/etc/bash_completion.d
[34m==&gt;[0m [1mSummary[0m
ğŸº  /usr/local/Cellar/node/14.3.0: 4,659 files, 60.8MB


** í•„ìê°€ ê°‘ìê¸° hexoê°€ ì‘ë™ë˜ì§€ ì•Šì•„ ì ì–ì´ ë‹¹í™©í•˜ë˜ ì¤‘ í•´ê²°ë²•ì„ ì°¾ì•„ì„œ ì´ê²ƒë„ ê³µìœ í•´.
!brew uninstall --force node
!brew uninstall icu4c &amp;&amp; brew install icu4c
!brew unlink icu4c &amp;&amp; brew link icu4c --force
!brew install node

ë…¸ë“œ ì–¸ì¸ìŠ¤í†¨ í›„ ì¬ì„¤ì¹˜í•˜ë©´ ë¬¸ì œ ì—†ì´ ì‘ë™í•œë‹¤.</code></pre></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-19T10:53:06.000Z" title="2020-05-19T10:53:06.000Z">2020-05-19</time><span class="level-item">3 minutes read (About 499 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/19/%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%97%90%EC%84%9C-%EC%84%A4%EC%B9%98%EB%90%98%EC%96%B4%EC%9E%88%EB%8A%94-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC-%EB%B2%84%EC%A0%84-%EC%B2%B4%ED%81%AC%ED%95%98%EA%B8%B0/">íŒŒì´ì¬ì—ì„œ ì„¤ì¹˜ë˜ì–´ìˆëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ì²´í¬í•˜ê¸°</a></h1><div class="content"><p>íŒŒì´ì¬ì„ ì‚¬ìš©í•˜ë‹¤ ë³´ë©´ ì‚¬ìš©í•˜ê³ ì í•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ì— ë”°ë¼ ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ì„ì—ë„ ë¶ˆêµ¬í•˜ê³  ëª…ë ¹ì–´ê°€ ë‹¤ë¥¸ ê²½ìš°ê°€ ìˆì–´. ê·¸ëŸ´ ê²½ìš° ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë²„ì „ì„ ì•Œì•„ì•¼ ê±°ê¸°ì— ë§ê²Œ ì§„í–‰ì„ í•  ìˆ˜ ìˆê² ì§€?</p>
<p>ì´ë•Œ, ì„¤ì¹˜í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì˜ ë²„ì „ì´ ë¬´ì—‡ì¸ì§€ë¶€í„° ë¨¼ì € í™•ì¸í•´ë³´ì!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip freeze</span><br></pre></td></tr></table></figure>

<pre><code>anaconda-client==1.7.2
anaconda-navigator==1.9.12
appnope==0.1.0
asn1crypto==1.3.0
attrs==19.3.0
autopep8==1.5.2
autopy==4.0.0
backcall==0.1.0
backports.functools-lru-cache==1.6.1
backports.tempfile==1.0
backports.weakref==1.0.post1
beautifulsoup4==4.6.0
bleach==3.1.0
boto==2.49.0
boto3==1.13.12
botocore==1.16.12
branca==0.4.0
bs4==0.0.1
cachetools==4.0.0
certifi==2020.4.5.1
cffi==1.14.0
chardet==3.0.4
chart-studio==1.0.0
click==7.1.1
cloudpickle==1.3.0
clyent==1.2.2
colorama==0.4.3
colorlover==0.3.0
conda==4.8.3
conda-build==3.18.9
conda-package-handling==1.6.0
conda-verify==3.4.2
configobj==5.0.6
cryptography==2.8
cufflinks==0.17.3
cvxpy==1.0.31
cycler==0.10.0
cytoolz==0.10.1
dask==2.14.0
decorator==4.4.2
defusedxml==0.6.0
dill==0.3.1.1
docutils==0.15.2
dpkt==1.9.2
ecos==2.0.7.post1
entrypoints==0.3
et-xmlfile==1.0.1
filelock==3.0.12
finance-datareader==0.9.6
folium==0.10.1
funcy==1.14
future==0.18.2
gensim==3.8.3
glob2==0.7
google-api-core==1.16.0
google-auth==1.12.0
google-auth-oauthlib==0.4.1
google-cloud-bigquery==1.24.0
google-cloud-core==1.3.0
google-resumable-media==0.5.0
googleapis-common-protos==1.51.0
idna==2.9
imageio==2.8.0
importlib-metadata==1.5.0
inflect==4.1.0
ipykernel==5.1.4
ipython==7.13.0
ipython-genutils==0.2.0
ipywidgets==7.5.1
jaraco.itertools==5.0.0
jdcal==1.4.1
jedi==0.16.0
Jinja2==2.11.1
jmespath==0.10.0
joblib==0.14.1
JPype1==0.7.5
jsonschema==3.2.0
jupyter-client==6.1.2
jupyter-core==4.6.3
jupyterthemes==0.20.0
kiwisolver==1.2.0
konlpy==0.5.2
lesscpy==0.14.0
libarchive-c==2.8
lief==0.9.0
lxml==4.5.0
MarkupSafe==1.1.1
matplotlib==3.2.1
missingno==0.4.2
mistune==0.8.4
mkl-fft==1.0.15
mkl-random==1.1.0
mkl-service==2.3.0
more-itertools==8.2.0
mpmath==1.1.0
multiprocess==0.70.9
navigator-updater==0.2.1
nbconvert==5.6.1
nbformat==5.0.4
netifaces==0.10.9
networkx==2.4
nltk==3.5
notebook==6.0.3
numexpr==2.7.1
numpy==1.18.1
oauthlib==3.1.0
olefile==0.46
opencv-python==4.2.0.34
openpyxl==3.0.3
osqp==0.6.1
packaging==20.3
pandas==1.0.3
pandas-gbq==0.13.1
pandocfilters==1.4.2
parso==0.6.2
patsy==0.5.1
pexpect==4.8.0
pgmpy==0.1.10
picklable-itertools==0.1.1
pickleshare==0.7.5
Pillow==7.0.0
pkginfo==1.5.0.1
plotly==4.5.0
pluggy==0.13.1
ply==3.11
prometheus-client==0.7.1
prompt-toolkit==3.0.4
protobuf==3.11.3
psutil==5.7.0
ptyprocess==0.6.0
py==1.8.1
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycodestyle==2.5.0
pycosat==0.6.3
pycparser==2.20
pydata-google-auth==0.3.0
Pygments==2.6.1
pyLDAvis==2.1.2
PyMySQL==0.9.3
pyOpenSSL==19.1.0
pyparsing==2.4.7
pyrsistent==0.16.0
PySocks==1.7.1
pytest==5.4.2
python-dateutil==2.8.1
python-xlib==0.27
pytz==2019.3
PyWavelets==1.1.1
PyYAML==5.3.1
pyzmq==18.1.1
QtPy==1.9.0
regex==2020.5.14
requests==2.23.0
requests-file==1.4.3
requests-oauthlib==1.3.0
retrying==1.3.3
rsa==4.0
ruamel-yaml==0.15.87
s3transfer==0.3.3
schedule==0.6.0
scikit-image==0.16.2
scikit-learn==0.22.2.post1
scipy==1.4.1
scs==2.1.2
seaborn==0.10.0
selenium==3.141.0
Send2Trash==1.5.0
six==1.14.0
sklearn==0.0
smart-open==2.0.0
soupsieve==2.0
soynlp==0.0.493
SQLAlchemy==1.3.16
statsmodels==0.11.0
sympy==1.5.1
terminado==0.8.3
testpath==0.4.4
toolz==0.10.0
torch==1.5.0
tornado==6.0.4
tqdm==4.44.1
traitlets==4.3.3
tweepy==3.8.0
urllib3==1.25.8
wcwidth==0.1.9
webencodings==0.5.1
wget==3.2
widgetsnbextension==3.5.1
wordcloud==1.7.0
xlrd==1.2.0
xmltodict==0.12.0
zipp==2.2.0
Note: you may need to restart the kernel to use updated packages.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>ì–´ë•Œ? ì‰½ì§€? ë¬¼ë¡  íŠ¹ì • ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¡ì•„ì„œ í•˜ëŠ” ë°©ë²•ë„ ìˆì§€ë§Œ, ì—¬ê¸°ì„œ ì†Œê°œí•˜ëŠ” ë°©ë²•ì€ ì„¤ì¹˜ëœ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë²„ì „ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì´ì•¼. íŒŒì´ì¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¢…ë¥˜ê°€ ë§¤ìš° ë§ì€ë° ì´ ëª…ë ¹ì–´ í•˜ë‚˜ë¡œ ëª¨ë“  ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ë²„ì „ì„ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë‹ˆê¹Œ ìƒë‹¹íˆ í¸ë¦¬í•œ ê²ƒ ê°™ë„¤.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-15T08:54:06.000Z" title="2020-05-15T08:54:06.000Z">2020-05-15</time><span class="level-item">25 minutes read (About 3688 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/15/Data-Analytics-on-Football/">Data Analytic on Football</a></h1><div class="content"><p>[ìˆ«ìëŠ” ê±°ì§“ë§í•˜ì§€ ì•ŠëŠ”ë‹¤: ì™œ ì¶•êµ¬ í´ëŸ½ë“¤ì´ ê·¸ë ‡ê²Œ ì• ë„ë¦¬í‹±ìŠ¤ë¥¼ ì¤‘ìš”í•˜ê²Œ ìƒê°í• ê¹Œ(The numbers donâ€™t lie: why football clubs place such importance on analytics)]</p>
<p><img src="https://user-images.githubusercontent.com/59719711/82031796-54047480-96d5-11ea-8271-0e0216738f5c.jpg" alt="WEST_HAM-main2-large_trans++01hEHXp48ZjlCwDoPtrE-G07QTvTgRHNz-gQ-gQnMTo"></p>
<p>ì›¨ìŠ¤íŠ¸ í–„ì˜ ë¡œë¦¬ ìº ë²¨ì€ ë¹… í´ëŸ½ì—ì„œ í•µì‹¬ ê²°ì •ì— ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ë– ì˜¤ë¥´ëŠ” ì¶•êµ¬ ì• ë„ë¦¬ìŠ¤íŠ¸ë“¤ ì¤‘ì˜ í•˜ë‚˜ì´ë‹¤.</p>
<p>ì„ ìˆ˜ë“¤ì´ ë– ë‚œ í•œì°¸ í›„ì˜ ì›¨ìŠ¤íŠ¸ í–„ ìœ ë‚˜ì´í‹°ë“œì˜ ì±„ë“œì›° í—¬ìŠ¤ í›ˆë ¨ì¥ì˜ ì¡°ìš©í•œ êµ¬ì„ì—ì„œ ë¡œë¦¬ ìº ë²¨ì€ ì»´í“¨í„° í™”ë©´ì„ ì‘ì‹œí•˜ê³  ìˆë‹¤. ì´ê²ƒì´ ë³´ë¹„ ë¬´ì–´ì™€ ì œí”„ í—ˆìŠ¤íŠ¸ ê²½ì˜ ë‘ ë²ˆì§¸ ì§‘ì´ì—ˆë˜ ì´ë˜ë¡œ ê·¸ ì£¼ë³€ì˜ ê±°ì£¼ì§€ë“¤ì€ ì˜¤ì§ í”¼ìƒì ìœ¼ë¡œ ë³€í–ˆì„ ë¿ì´ë‚˜, í•„ë“œ ë°–ì˜ ì¤€ë¹„ì˜ ë³µì¡ì„±ì€ ì™„ì „íˆ ë°”ë€Œê³  ìˆë‹¤.</p>
<p>ìº ë²¨ì€ ì›¨ìŠ¤íŠ¸ í–„ì˜ ê¸°ìˆ  ìŠ¤ì¹´ìš°íŠ¸ì´ì ë¶„ì„ê°€ì´ë‹¤. ì˜¥ìŠ¤í¬ë“œ ì¡¸ì—…ìƒì´ì, ì•Œë¼ìŠ¤í…Œì–´ ìº ë²¨ì˜ ì•„ë“¤ë“¤ ì¤‘ í•˜ë‚˜ì¸  ê·¸ëŠ” ì„±ê³µì ì¸ í¬ì»¤ ì„ ìˆ˜ì˜€ìœ¼ë©°, ì•½ê°„ì˜ ì„ ìˆ˜ ê²½í—˜ê³¼ ì½”ì¹­ ë°°ê²½ì„ ê°€ì¡Œë‹¤. ê·¸ì˜ ì´ˆì ì€ ì¶•êµ¬ì— ê´€í•œ ë¬´í•œí•œ í†µê³„ì ì´ ë°ì´í„°ë“¤ì„ ì´í•´í•˜ëŠ” ê²ƒì´ë©°, ê·¸ë˜ì„œ í´ëŸ½ì˜ í•µì‹¬ì ì¸ ì˜ì‚¬ ê²°ì •ìë“¤ì—ê²Œ ë¬´ì—‡ì´ ì •ë§ ì¤‘ìš”í•œì§€ë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì´ë‹¤.</p>
<p><img src="https://user-images.githubusercontent.com/59719711/82031862-6c748f00-96d5-11ea-934a-558cd2f91617.jpg" alt="WEST_HAM-epa-large_trans++ZgEkZX3M936N5BQK4Va8RWtT0gK_6EfZT336f62EI5U"></p>
<p>ì€ê³¨ë¡œ ì¹¸í…ŒëŠ” ì˜¬ì‹œì¦Œì˜ ì˜ì…ì´ê³  ì¶•êµ¬ ì• ë„ë¦¬í‹±ìŠ¤ì˜ ìŠ¹ë¦¬ì´ë‹¤.</p>
<p>ë”êµ¬ë‚˜, ì¶•êµ¬ì˜ ê°€ì¥ íš¨ê³¼ì ì¸ ë¶„ì„ ì‘ì—…ë“¤ ì¤‘ ëª‡ëª‡ê³¼ ë‹¨ìˆœíˆ êµ¬ë§¤ë ¥ì„ ê±°ì˜ ë°˜ì˜í•˜ì§€ ì•Šê³  ìˆëŠ” í”„ë¦¬ë¯¸ì–´ ë¦¬ê·¸ í…Œì´ë¸” ì‚¬ì´ì˜ ì ì¬ì ì¸ ìƒê´€ ê´€ê³„ëŠ” ë¶„ëª…í•˜ë‹¤. ë ˆìŠ¤í„° ì‹œí‹°ì™€ ì›¨ìŠ¤íŠ¸ í–„ì€ ì˜¤ëŠ˜ ë§Œë‚˜ ê²½ê¸°ë¥¼ ê°–ì§€ë§Œ, ì˜ˆë¥¼ ë“¤ì–´ ì–´ë–»ê²Œ ê·¸ë“¤ì´, ë§Œì²´ìŠ¤í„° ìœ ë‚˜ì´í‹°ë“œê°€ ë§ˆë£¨ì•™ í ë¼ì´ë‹ˆ, ì•ˆë” ì—ë ˆë¼ ê·¸ë¦¬ê³  ë°”ìŠ¤í‹°ì•ˆ ìŠˆë°”ì¸ìŠˆíƒ€ì´ê±°ì— 7ì²œë§Œ íŒŒìš´ë“œë¥¼ ìŸì•„ë¶€ì„ ë•Œ, ì€ê³¨ë¡œ ì¹¸í…Œ, ë””ë¯¸íŠ¸ë¦¬ íŒŒì˜ˆ ê·¸ë¦¬ê³  ë¦¬ì•¼ë“œ ë§ˆë ˆì¦ˆë¥¼ ì²œ 6ë°±ë§Œ íŒŒìš´ë“œì— ë°œê²¬í•´ëƒˆì„ê¹Œ? ê·¸ë¦¬ê³  ë¬´ì—‡ì´ í† íŠ¼í–„ í•«ìŠ¤í¼ê°€ ë¸ë¦¬ ì•Œë¦¬ì™€ ì—ë¦­ ë‹¤ì´ì–´ë¡œ ì´ëŒì—ˆëŠ”ì§€ í˜¹ì€ ì‚¬ìš°ìŠ¤í–„íŠ¼ì„ ì‚¬ë””ì˜¤ ë§ˆë„¤ì™€ ë²„ì§ˆ ë°˜ ë‹¤ì´í¬ë¡œ ì´ëŒì—ˆì„ê¹Œ? ì™œ íŒ€ë“¤ì´ ì „ì— ì—†ì´ ì ì€ í¬ë¡œìŠ¤ë¥¼ í•˜ê³  ìˆì„ê¹Œ? ë¬´ì—‡ì´ ë ˆìŠ¤í„°ì˜ ë…íŠ¹í•œ íŠ¹ì§•ì¼ê¹Œ? ì™œ í© ê³¼ë¥´ë””ì˜¬ë¼ì™€ ê°™ì€ ê°ë…ë“¤ì´ ë¨¼ ê±°ë¦¬ì—ì„œì˜ ìŠˆíŒ…ì„ ì¥ë ¤í•˜ì§€ ì•Šì„ê¹Œ? ê·¸ë¦¬ê³  ëª¨ë“  ì‹œì¦Œë“¤ ì¤‘ì—ì„œ ê°€ì¥ ë†€ë¼ìš´, í…Œì´ë¸”ì´ ê±°ì§“ë§ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì€ ì •ë§ ì‚¬ì‹¤ì¼ê¹Œ?</p>
<p><img src="https://user-images.githubusercontent.com/59719711/82031949-88783080-96d5-11ea-84a3-4c77c58be603.jpg" alt="WEST_HAM-epa-large_trans++ZgEkZX3M936N5BQK4Va8RWtT0gK_6EfZT336f62EI5U"></p>
<p>ìº ë²¨ì€ ì›¨ìŠ¤íŠ¸ í–„ì˜ ê¸°ìˆ  ìŠ¤ì¹´ìš°íŠ¸ì´ì ì• ë„ë¦¬ìŠ¤íŠ¸ì´ë‹¤.</p>
<p>ì• ë„ë¦¬í‹±ìŠ¤ëŠ” ìµœì†Œí•œ ë¶€ë¶„ì ì¸ ë‹µì„ ì œê³µí•œë‹¤. ë¹„ë¡ ìº ë²¨ì´ ë¶„ì„ì˜ ê°€ì¹˜ê°€ ì—¬ì „íˆ ì˜ì‚¬ê²°ì •ì˜ ê¸°ì €ë¥¼ êµ¬ì„±í•˜ê³  ìˆëŠ” ê²½í—˜, ì§ê´€, ë³¸ì§ˆì ì¸ ì§€ì‹ê³¼ ì ‘ì´‰ë“¤ì„ ëŒ€ì²´í•œë‹¤ê¸° ë³´ë‹¤ëŠ” ë³´ì¡°í•˜ëŠ” ê²ƒì´ë¼ê³  í™•ì‹ í•˜ì§€ë§Œ ë§ì´ë‹¤. ê·¸ëŠ” â€œë¹„íš¨ìœ¨ì ì¸ ì–´ë–¤ ì‹œì¥ë„ ê¸°íšŒì…ë‹ˆë‹¤.â€ë¼ê³  ë§í•œë‹¤. â€œì¶•êµ¬ê°€ ì¬ëŠ¥ì„ ê°€ì¹˜ í‰ê°€í•˜ëŠ” ì„¸íŠ¸ë‚˜ ë™ì˜ëœ ë°©ì‹ì„ ê°–ê³  ìˆì§€ ì•Šê³  ë„ˆë¬´ë‚˜ ì„ì˜ì ì´ë¼ëŠ” ì‚¬ì‹¤ì€ ê¸°íšŒì…ë‹ˆë‹¤. í†µê³„ì™€ ì• ë„ë¦¬í‹±ìŠ¤ëŠ” ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤. í†µê³„ëŠ” ë‹¹ì‹ ì—ê²Œ ì¼ì–´ë‚œ ì‚¬ê±´ë“¤ì— ëŒ€í•´ì„œ ë§í•´ì¤ë‹ˆë‹¤. ê·¸ë“¤ì€ ë§¥ë½ì—†ì´ëŠ” ì•„ë¬´ ê²ƒë„ ì˜ë¯¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.</p>
<p><img src="https://user-images.githubusercontent.com/59719711/82032034-a5acff00-96d5-11ea-8d65-04f8f4368e07.jpg" alt="analytics2-large_trans++qVzuuqpFlyLIwiB6NTmJwfSVWeZ_vEN7c6bHu2jJnT8"></p>
<p>ë ˆìŠ¤í„°ì˜ ì§ì ‘ì ì¸ ìŠ¤íƒ€ì¼ì€ ê·¸ë“¤ì„ ëšœë ·í•œ í”„ë¦¬ë¯¸ì–´ ë¦¬ê·¸ ì•„ì›ƒë¼ì´ì–´ë¡œ ë§Œë“¤ì—ˆë‹¤.</p>
<p>â€œì• ë„ë¦¬í‹±ìŠ¤ëŠ” ê·¸ëŸ¬í•œ í†µê³„ë“¤ì„ ë¯¸ë˜ì˜ í¼í¬ë¨¼ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ í•´ì„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ëª¨ë“  ê²ƒì„ ì¸¡ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì–´ë ¤ìš´ ê²ƒì€ ë¬´ì—‡ì´ ì¤‘ìš”í•œì§€ë¥¼ ì•Œì•„ë‚´ëŠ” ê²ƒì…ë‹ˆë‹¤. í•œê°€ì§€ ì¢‹ì€ ê²ƒì€ ì¶•êµ¬ëŠ” ê½¤ ë‹¨ìˆœí•˜ë‹¤ëŠ” ê²ƒì…ë‹ˆë‹¤. ëª¨ë“  ê²ƒì€ ê²°êµ­ì—ëŠ” ì–´ë–»ê²Œë“  ê³¨ê³¼ ì—°ê´€ë˜ì–´ ìˆìŠµë‹ˆë‹¤, ê·¸ê²ƒì´ ìš°ë¦¬ì˜ ë“ì  ê¸°íšŒë¥¼ ëŠ˜ë ¤ì£¼ê±°ë‚˜ ì•„ë‹ˆë©´ ì‹¤ì ì„ ë§‰ì•„ì£¼ê±°ë‚˜ìš”. ê·¸ê²ƒì€ ë˜í•œ ê°ë…ì´ íŒ€ì´ ì–´ë–»ê²Œ í”Œë ˆì´í•˜ê¸°ë¥¼ ì›í•˜ëŠ” í‹€ ì•ˆì—ì„œ í†µí•©ë‹ˆë‹¤.â€</p>
<p>ë³´ë‹¤ ë” ë§ì€ í†µì°°ë“¤ì´ ì‚¬ìš°ìŠ¤í–„íŠ¼ì˜ í›ˆë ¨ì‹œì„¤ì—ì„œ ë°œê²¬ë  ìˆ˜ ìˆë‹¤. ê°€ì¥ ë†€ë¼ìš´ ê³³ì€ í´ëŸ½ì˜ 34ì„¸ì˜ ìŠ¤ì¹´ìš°íŒ…ê³¼ ì„ ìˆ˜ì„ ë°œ ì´ì‚¬ì¸ ë¡œìŠ¤ ìœŒìŠ¨ì´ ìë¦¬ì¡ê³  ìˆëŠ” ë°©ì´ë‹¤. ê·¸ì˜ ë°”ë¡œ ì•ì—ëŠ” 15ê°œì˜ ì¼ë ¨ì˜ í™”ë©´ ì•ì—ì„œ ì Šì€ ìŠ¤íƒœí”„ë“¤ì˜ íŒ€ì´ ì •ë³´ë“¤ì„ ì²˜ë¦¬í•˜ê³  ìˆë‹¤. ëª‡ëª‡ì€ ì¶•êµ¬ ë¶„ì„ì˜ íŠ¹ì • ë¶„ì•¼ì—ì„œì˜ í•™ìœ„ë¥¼ ë³´ìœ í•œ ì¸í„´ë“¤ì´ë‹¤. ìœŒìŠ¨ì˜ ì˜¤ë¥¸ìª½ì—ëŠ” ë³´ë‹¤ í¬ë—í¬ë—í•œ ë¨¸ë¦¬ë¥¼ ê°€ì§„ ê´€ê³„ìì¸ ë¡œë“œ ë£¨ë”•ê³¼ ê°™ì€ ì‚¬ëŒì´ ìˆë‹¤. ê·¸ëŠ” ë‰´í¬íŠ¸ì˜ í•„ë“œì—ì„œ ë›°ë˜ 8ì‚´ì˜ ê°€ë ˆìŠ¤ ë² ì¼ì„ ë°œê²¬í•œ ìŠ¤ì¹´ìš°íŠ¸ì´ë‹¤. ìœŒìŠ¨ì˜ ì™¼ìª½ì—ëŠ” â€œë¸”ë™ ë°•ìŠ¤â€ë¼ëŠ” ë‹¨ì–´ê°€ ë¯¸ìŠ¤í…Œë¦¬í•˜ê²Œ ê±¸ë ¤ìˆëŠ” ë¬¸ì´ ìˆë‹¤.</p>
<p><img src="https://user-images.githubusercontent.com/59719711/82032099-bc535600-96d5-11ea-9434-60c71dc5d890.jpg" alt="1111"></p>
<p>í´ ë¯¸ì²¼ì€ ì‚¬ìš°ìŠ¤í–„íŠ¼ì—ì„œ í† íŠ¼í–„ìœ¼ë¡œ ì´ë™í•´ì„œ ì„ ìˆ˜ì„ ë°œ ë° ë¶„ì„ íŒ€ì¥ì´ ë˜ì—ˆë‹¤.</p>
<p>ì‚¬ìš°ìŠ¤í–„íŠ¼ì€ ì´ ë¯¸ë‹ˆ-ì‹œë„¤ë§ˆì— ì“°ì´ëŠ” ë§ì¶¤í˜• ì†Œí”„íŠ¸ì›¨ì–´ë¥¼ ê¾¸ì¤€íˆ ìˆ˜ì •í•˜ê³  ìˆë‹¤. ê·¸ ì†Œí”„íŠ¸ì›¨ì–´ëŠ” ëª‡ë²ˆì˜ í´ë¦­ë“¤ ë§Œìœ¼ë¡œ ì „ì„¸ê³„ì— ìˆëŠ” ì–´ë–¤ ì„ ìˆ˜ì— ëŒ€í•œ ê²ƒë„ ë³¼ ìˆ˜ ìˆë‹¤. ë‹¤ë¥¸ í´ëŸ½ë“¤ì€ ë¹„ìŠ·í•œ ê¸°ìˆ ì„ ê°œë°œ ì¤‘ì´ë©°, ìˆ˜í•™ì ìœ¼ë¡œ ì¬ëŠ¥ë“¤ì„ ê³¨ë¼ë‚´ëŠ” ì‚¬ëŒë“¤ ì‚¬ì´ì—ì„œ, ì´ì  ì‹œì¥ì´ ë– ì˜¤ë¥´ê³  ìˆë‹¤. ì•„ìŠ¤ë‚ ì€ ì˜¬ í•´ ë²¤ ë¤¼ê¸€ì›ŒìŠ¤ë¥¼ ë ˆìŠ¤í„°ë¡œë¶€í„° ë¹¼ëƒˆê³ , ë¯¸êµ­ ê¸°ë°˜ì˜ ë¶„ì„ íšŒì‚¬ì¸ statDNAë¥¼ 2ë°±ë§Œ íŒŒìš´ë“œì— ì‚¬ë“¤ì˜€ë‹¤. ë§ˆìš°ë¦¬ì‹œì˜¤ í¬ì²´í‹°ë…¸ì™€ í•¨ê»˜, í† íŠ¼í–„ì€ ê·¸ë“¤ì˜ ì„ ìˆ˜ì„ ë°œê³¼ ë¶„ì„ íŒ€ì¥ì¸ í´ ë¯¸ì²¼ì„ ì‚¬ìš°ìŠ¤í–„íŠ¼ì—ì„œ ì„ ë°œí–ˆë‹¤. ë¶€ìƒìœ¼ë¡œ 27ì„¸ì— ì„ ìˆ˜ ì»¤ë¦¬ì–´ë¥¼ ëëƒˆë˜ ë¯¸ì²¼ì€ ì´ë ‡ê²Œ ë§í•œë‹¤. â€œì €ëŠ” í•œ ë²ˆ ì¢‹ì€ ê²½ê¸°ë¥¼ ê°€ì§ˆ ë•Œ ë‹¤ë¥¸ 80ê²½ê¸°ì—ì„œëŠ” ê·¸ë ‡ê²Œ ì¢‹ì§€ ì•Šë‹¤ëŠ” ê°„ë‹¨í•œ ì´ë¡ ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.â€</p>
<p>í¬ì»¤ì—ì„œì²˜ëŸ¼, ìº ë²¨ì€ ì„ ìˆ˜ ì„ ë°œì„ â€œë‹¹ì‹ ì˜ ë² íŒ…ì˜ ê²½ì œì ì¸ ë¦¬ìŠ¤í¬ë¥¼ ê°€ìš©í•œ ì •ë³´ë¥¼ ê°€ì§€ê³  ê´€ë¦¬í•˜ëŠ” ê²ƒâ€ì´ë¼ê³  ë¶€ë¥¸ë‹¤. í•˜ì§€ë§Œ ë‹¤ë¥¸ ì ì€ ê·¸ì˜ ì‚°ì—…ì˜ ë‹¤ë¥¸ ë©¤ë²„ë“¤ê³¼ì˜ ë¯¸íŒ…ì´ ë¶„ëª…íˆ í•µì‹¬ì ì´ë¼ëŠ” ê²ƒì„ ê°•ì¡°í•œë‹¤. ê³¼ê±°ì˜ ì¶•êµ¬ì—ì„œì˜ í˜ì‹ ì˜ ì‹œë„ê°€ ì£¼ì €ì•‰ì€ ê³³ì—ëŠ” ì¢…ì¢… ì˜ì‚¬ì†Œí†µì˜ ì‹¤ìˆ˜ë‚˜ ê°œì¸ê°„ì˜ ì¶©ëŒë“¤ì— ê¸°ë°˜í•œë‹¤.</p>
<p>í´ë¼ì´ë¸Œ ìš°ë“œì™€ë“œ ê²½ì€ ë³´í†µ ìƒê°ë˜ëŠ” ê²ƒë³´ë‹¤ í•´ë¦¬ ë ˆë“œë‚©ê³¼ ë” ë‚˜ì€ ê´€ê³„ë¥¼ ê°€ì§€ê³  ìˆë‹¤. í•˜ì§€ë§Œ ê±°ê¸°ì— ë£¨í¼íŠ¸ ë¡œ, ë°ì´ë¸Œ ë°”ì…‹, ë°ë‹ˆìŠ¤ ì™€ì´ì¦ˆì™€ ì‚¬ì´ë¨¼ í´ë¦¬í¬ë“œë¥¼ ë”í•˜ë©´ ë‹¹ì‹ ì´ ê·¸ê²ƒì´ ì–´ë””ì„œ ì˜ëª»ë˜ì—ˆëŠ”ì§€ íŒŒì•…í•˜ê¸° ìœ„í•´ì„œ ì—ë¥´í˜ í¬ì™€ë“œì˜ ì¶”ë¦¬ë ¥ê¹Œì§€ í•„ìš”í•˜ì§€ë„ ì•Šë‹¤. ì• ë„ë¦¬í‹±ìŠ¤ê°€ ì°¨ì´ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê³³ì—ëŠ” ì£¼ë¡œ ë¬¸í™”ê°€ ì •ë¦½ëœë‹¤. â€œë‹¹ì‹ ì´ í”Œë ˆì´í•  í•„ìš”ê°€ ìˆëŠ” í´ëŸ½ë“¤ ì¤‘ì—ëŠ” ì „í†µì´ ê¹Šì´ ë°°ì–´ìˆëŠ” í´ëŸ½ë“¤ì´ ìˆì„ ê²ƒì…ë‹ˆë‹¤. í•˜ì§€ë§Œ ìš´ì´ ì¢‹ê²Œë„ ë‚´ê°€ ìˆì—ˆë˜ í´ëŸ½ë“¤ì€ ì‚¬ê³ ë°©ì‹ì´ ë§¤ìš° ì—´ë ¤ìˆì—ˆìŠµë‹ˆë‹¤.â€ ìœŒìŠ¨ì´ ë§í•œë‹¤.</p>
<p>ìº ë²¨ì€ ì´ë ‡ê²Œ ë”í•œë‹¤: â€œì• ë„ë¦¬í‹±ìŠ¤ ì„¸ê³„ê°€ í˜ê²¨ì›Œí•˜ëŠ” ë¶€ë¶„ì€ ì „í†µì ì¸ ì¶•êµ¬ ì„¸ê³„ë¡œì˜ ë‹¤ë¦¬ë¥¼ ë†“ëŠ” ê²ƒì…ë‹ˆë‹¤. ì •ë³´ë¥¼ ë” ì¹¨íˆ¬ì‹œí‚¤ê¸° ìœ„í•´ì„œìš”. ìˆ˜í•™ì ì¸ ì¸¡ë©´ì—ì„œëŠ” ì™„ë²½íˆ ë…¼ë¦¬ì ìœ¼ë¡œ ë§ì´ë˜ëŠ” ë§ì€ ì •ë³´ë“¤ì„ ì£¼ê³  ìˆ˜ì‹­ë…„ê°„ ë°œì „í•´ ì˜¨ ìŠ¤í¬ì¸ ê°€ ê·¸ê²ƒì„ í•˜ë£¨ ì•„ì¹¨ì— ë°›ì•„ë“¤ì´ê¸°ë¥¼ ê¸°ëŒ€í•˜ëŠ” ê²ƒì€ ì‚¬ì‹¤ ê½¤ ê±´ë°©ì§„ ê²ƒì´ë‹¤. ë‚˜ëŠ” ì´ê²ƒì´ ê°€ì¥ í° ë„ì „ìœ¼ë¡œ ë‚¨ì•„ìˆë‹¤ê³  ë§í•˜ê³  ì‹¶ë‹¤. ì •ë³´ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆê¸° ìœ„í•´ì„œëŠ” ë‹¹ì‹ ì€ ì—­í•™ê´€ê³„ì™€ ë‹¹ì‹ ê³¼ í•¨ê»˜ ì¼í•˜ëŠ” ì‚¬ëŒë“¤ì˜ ì„±ê²©ë“¤ì„ ì´í•´í•´ì•¼ë§Œ í•œë‹¤. ë‚˜ëŠ” ê·¸ê²ƒì´ ì™œ ì• ë„ë¦¬í‹±ìŠ¤ê°€ ë‹¤ë¥¸ ë¹„ì§€ë‹ˆìŠ¤ì—ì„œ ê·¸ë¬ë˜ ê²ƒì²˜ëŸ¼ ì¶•êµ¬ì— ì¹¨íˆ¬í•˜ì§€ ëª»í•œ ì´ìœ ë¼ê³  ìƒê°í•œë‹¤.â€ </p>
<p><img src="https://user-images.githubusercontent.com/59719711/82032159-d12fe980-96d5-11ea-9c26-b10634bad37d.jpg" alt="45"></p>
<p>ì•„ìŠ¤ë‚  ê°ë… ì•„ìŠ¨ ë²µê±°ëŠ” ë˜í•œ ì• ë„ë¦¬í‹±ìŠ¤ë¥¼ ìˆ˜ìš©í•´ì˜¤ê³  ìˆë‹¤.</p>
<p>í•˜ì§€ë§Œ ì´ê²ƒì€ ë³€í•˜ê³  ìˆë‹¤. ìº ë²¨ì€ ê·¸ê°€ ìŠ¬ë˜ë¸ ë¹Œë¦¬ì¹˜ì™€ ì„ ìˆ˜ ì„ ë°œ ë””ë ‰í„°ì¸ í† ë‹ˆ í—¨ë¦¬ ì•„ë˜ì—ì„œ ì¼í•  ìˆ˜ ìˆì–´ì„œ ë§¤ìš° ìš´ì´ ì¢‹ì•˜ë‹¤ê³  ë§í•œë‹¤. ê·¸ë¦¬ê³  ëª¨ë‘ì˜ ì—­í• ì— ë¶„ëª…í•¨ì´ ìˆì—ˆë‹¤. ê·¸ë“¤ì´ ì›í•˜ëŠ” ê²ƒì€ ê°„ë‹¨íˆ ê·¸ë“¤ì˜ ê²°ì •ì„ ë„ì™€ì¤„ ì •ë³´ì— ëŒ€í•œ ë¯¿ì„ë§Œí•œ í‰ê°€ì˜€ë‹¤. ë‚˜ì´ ë§ì€ ê°ë…ë“¤ ì—­ì‹œ ì ‘ê·¼í•˜ê³  ìˆë‹¤. í´ë¼ìš°ë””ì˜¤ ë¼ë‹ˆì—ë¦¬ëŠ” í•œ ì˜ˆì´ë‹¤. ì•„ìŠ¨ ë²µê±°ëŠ” ì˜¬ ì‹œì¦Œ ê³µì‹ìë¦¬ì—ì„œ ì•„ìŠ¤ë‚ ì˜ â€œê¸°ëŒ€ ê³¨ ê°’ (xG)â€ì— ëŒ€í•´ ì–¸ê¸‰í•˜ë©´ì„œ ì¶©ê²©ì„ ì´‰ë°œì‹œì¼°ë‹¤. ê·¸ê²ƒì€ íŒ€ì´ í†µê³„ì ìœ¼ë¡œ ì–¼ë§ˆë‚˜ ìì£¼ ë“ì í•  ìˆ˜ ìˆëŠ”ì§€ì— ëŒ€í•œ ìŠ¤í¬ì¸  ë² íŒ…ê³¼ ì• ë„ë¦¬í‹±ìŠ¤ì—ì„œ í•µì‹¬ì ì¸ ì¸¡ì •ê°’ì´ë‹¤.</p>
<p>ë³´ë£¨ì‹œì•„ ë„ë¥´íŠ¸ë¬¸íŠ¸ì˜ ì½”ì¹˜ í† ë§ˆìŠ¤ íˆ¬í—¬ì€ xGì— ëŒ€í•´ ë” ë°°ìš°ê¸° ìœ„í•´ ë§¤íŠœ ë² ë„˜ì„ ì°¾ì•„ê°”ë‹¤. ë² ë„˜ì€ ìŠ¤í¬ì¸  ë² íŒ…ì—ì„œ ìˆ˜ë°±ë§Œì„ ë²Œì—ˆê³  ê·¸ ì´í›„ë¡œ ë¸Œë ŒíŠ¸í¬ë“œì™€ FCë°‹ì¸Œë€ì„ ì‚¬ë“¤ì˜€ë‹¤. ì„ ìˆ˜ë¥¼ ê°œì¸ì ìœ¼ë¡œ ê´€ì°°í•˜ê¸° ìœ„í•´ í­ë„“ê²Œ ì›€ì§ì´ëŠ” ìº ë²¨ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, ë² ë„˜ì€ ì¶•êµ¬ì²˜ëŸ¼ ë‚®ì€ ë“ì ì„ ê°€ì§„ ìŠ¤í¬ì¸ ì—ì„œì˜ ì–´ë–¤ ìˆ˜í•™ ëª¨ë¸ì˜ ëšœë ·í•œ ë³€ë™ì„±ì„ ë³´ì™„í•˜ê¸° ìœ„í•œ â€œëˆˆìœ¼ë¡œ í•˜ëŠ” ìŠ¤ì¹´ìš°íŒ…â€ì˜ ì¤‘ìš”ì„±ì„ ê°•ì¡°í•œë‹¤. í¬ì»¤ì²˜ëŸ¼, ëœë¤ê³¼ í†µì œë¶ˆê°€ëŠ¥í•œ ì‚¬ê±´ë“¤ì´ íŒë‹¨ë“¤ì„ í˜•ì„±í•˜ëŠ”ë° ì„œë‘ë¥´ëŠ” ê°€ìš´ë°ì— ì¢…ì¢… ê°„ê³¼í•˜ëŠ” ë¶€ë¶„ì ì¸ ì—­í• ì„ í•œë‹¤.</p>
<p>ìº ë²¨ì€ ì´ë ‡ê²Œ ë§í•œë‹¤. â€œì´ê²ƒì€ ì¶•êµ¬ë¥¼ í¥ë¯¸ë¡­ê²Œ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤ë§Œ ì˜ˆì¸¡ë¶ˆê°€ëŠ¥ì€ í•­ìƒ ì‹¬ê°í•œ ë¹„íš¨ìœ¨ì„ ë™ë°˜í•©ë‹ˆë‹¤. ìš´ì„ ë¶ˆí‰í•˜ëŠ” í”„ë¡œ í¬ì»¤ ì„ ìˆ˜ë“¤ì€ í¸í˜‘í•œ ê²ƒì…ë‹ˆë‹¤. ìš´ì´ë¼ëŠ” ê²ƒì€ ê·¸ë“¤ì´ ì‚¬ëŠ” ê²ƒì„ ê°€ëŠ¥ì¼€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ë§Œì•½ ë‚´ê°€ ì •ë§ ë‚˜ìœ ì„ ìˆ˜ì™€ í¬ì»¤ë¥¼ ì¹œë‹¤ë©´, ê·¸ëŠ” 100ë²ˆ ì¤‘ì— 40ë²ˆì„ ì´ê¸¸ ê²ƒì…ë‹ˆë‹¤. ë§Œì•½ ë‚´ê°€ ê°œë¦¬ ì¹´ìŠ¤íŒŒë¡œí”„ì™€ ì²´ìŠ¤ë¥¼ ë‘”ë‹¤ë©´ ê·¸ê°€ 100ë²ˆì„ ì´ê¸°ê² ì£ . ì²´ìŠ¤ ì„ ìˆ˜ë“¤ì€ ë² íŒ…ìœ¼ë¡œ ëˆì„ ë²Œì§€ ì•ŠìŠµë‹ˆë‹¤. ì™œëƒí•˜ë©´ ì•„ë¬´ë„ ê·¸ë“¤ì—ê²Œ ëˆì„ ê±¸ì§€ ì•Šìœ¼ë‹ˆê¹Œìš”.â€</p>
<p><img src="https://user-images.githubusercontent.com/59719711/82032241-e7d64080-96d5-11ea-8ff4-3abe17fb219d.jpg" alt="WEST_HAM-reuters-large_trans++oQmI6CCYeWXI2SDtPW01M2FxAL8YkdOPBcsmeEiEP3A"></p>
<p>ë ˆìŠ¤í„°ì˜ ë™í™”ê°™ì€ ì‹œì¦Œì€ í†µê³„ì ì¸ ëª¨ë¸ë“¤ì´ í‹€ë ¸ìŒì„ ì…ì¦í•´ì˜¤ê³  ìˆë‹¤.</p>
<p>ì• ë„ë¦¬í‹±ìŠ¤ëŠ” ì ì  ë” ë§ì€ ì˜ê²¬ë“¤ë¡œ ê°€ë“ì°¬ í˜„ì¬ ì§€í˜• ì•ˆì—ì„œ ëª©ì†Œë¦¬ë¥¼ ë‚´ê¸° ìœ„í•´ ì‹¸ìš°ê³  ìˆë‹¤. ìº ë²¨ì€ ì´ë ‡ê²Œ ë§í•œë‹¤. â€œì•„ìŠ¨ ë²µê±°ëŠ” ìš°ë¦¬ê°€ ìˆ˜ì§ì ì—ì„œ ìˆ˜í‰ì ì¸ ì‚¬íšŒë¡œ ì›€ì§ì´ê³  ìˆë‹¤ê³  ë§í–ˆìŠµë‹ˆë‹¤. ìˆ˜ì§ì ì¸ ê²ƒì€ ê¼­ëŒ€ê¸°ì— ë¦¬ë”ê°€ ìˆê³  ëª¨ë‘ê°€ ë”°ë¥´ëŠ” ê²ƒì…ë‹ˆë‹¤. ìˆ˜í‰ì ì¸ ê²ƒì€ ì •ë³´ì™€ ì˜ê²¬ë“¤ì— í­ê²©ì„ ë‹¹í•˜ëŠ” ë¦¬ë”ë¥¼ ê°€ì§„ ê²ƒì…ë‹ˆë‹¤. ê·¸ê²ƒì´ ë¦¬ë”ê°€ ì–´ë–¤ ê²ƒì´ ì¤‘ìš”í•˜ê³  ì–´ë–¤ ê²ƒì´ ë…¸ì´ì¦ˆì¸ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” ê²ƒì´ ì •ë§ ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.â€</p>
<p>ê·¸ëŸ¬ë©´ ì²˜ìŒ ì§ˆë¬¸ìœ¼ë¡œ ëŒì•„ê°€ ë³´ì. ì¹¸í…Œ, ë§ˆë„¤ ê·¸ë¦¬ê³  íŒŒì˜ˆëŠ” ê¶ê·¹ì ìœ¼ë¡œ ê¸°ë¯¼í•œ ì¶•êµ¬ì ì¸ ê²°ì •ë“¤ì´ì—ˆë‹¤. í•˜ì§€ë§Œ ì• ë„ë¦¬í‹±ìŠ¤ ì»¤ë®¤ë‹ˆí‹°ì˜ ê¸°ì €ì— ìˆëŠ” í¼í¬ë¨¼ìŠ¤ ì§€í‘œë“¤ì˜ ìŠ¹ë¦¬ì˜€ë‹¤. ë¶„ëª…í•œ í†µê³„ì ì¸ ì¦ê±°ëŠ” í¬ë¡œìŠ¤ë“¤ì´ ìŠ¤ë£¨ ë³¼ ë³´ë‹¤ ì ì€ í™•ë¥ ì˜ ì „ìˆ ì´ë¼ëŠ” ê²ƒì´ê³  ë¨¼ ê±°ë¦¬ì—ì„œì˜ ìŠˆíŒ…ì€ ë” ë‚˜ì€ í¬ì§€ì…˜ìœ¼ë¡œ íŒ¨ìŠ¤í•˜ëŠ” ê²ƒ ë³´ë‹¤ ì ì€ ê³¨ì„ ìƒì‚°í•œë‹¤ëŠ” ê²ƒì´ë‹¤.</p>
<p>ìˆ˜í•™ êµìˆ˜ì´ì ì‚¬ì»¤ë§¤í‹±ìŠ¤ì˜ ì €ì ë°ì´ë¹— ì„¬í„°ì— ë”°ë¥´ë©´, ë ˆìŠ¤í„°ì™€ ë¦¬ê·¸ì˜ ë‹¤ë¥¸ íŒ€ë“¤ê³¼ì˜ ì¶©ê²©ì ì¸ ì°¨ì´ëŠ” ì–´ë–»ê²Œ ê·¸ë“¤ì´ ìƒëŒ€ì ìœ¼ë¡œ ê¸¸ê³  ì§ì„ ì ì¸ íŒ¨ìŠ¤ë“¤ë¡œ ë³¼ì„ ì „ë°©ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì›€ì§ì´ëŠ”ì§€ì´ë‹¤.</p>
<p>ê·¸ëŸ¬ë©´ í…Œì´ë¸”ì€ ì ˆëŒ€ ê±°ì§“ë§í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” í´ë¦¬ì…°ëŠ” ê±°ì§“ì¼ê¹Œ? ê¸€ì„, ì•„ë§ˆë„ ê·¸ê²ƒì€ ì§„ì‹¤ ì „ë¶€ë¥¼ ë§í•˜ì§€ëŠ” ì•ŠëŠ”ë‹¤. ê±°ì˜ ëª¨ë“  xGëª¨ë¸ì€ ì•„ìŠ¤ë‚ ì´ ì‚¬ì‹¤ ì—„ì²­ë‚œ ê¸°íšŒë¥¼ ë†“ì³¤ê³  ì„ ë‘ì— ìˆì—ˆì–´ì•¼ í•œë‹¤ê³  ë§í•˜ê³  ìˆë‹¤. ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì€ ë§Œì•½ ì´ë²ˆ ì‹œì¦Œì´ ë¬´í•œí•œ ê²½ê¸° ìˆ˜ë¥¼ ê°€ì¡Œì„ ë•Œ ë ˆìŠ¤í„°ê°€ 4ìœ„ì—ì„œ 8ìœ„ ì‚¬ì´ì— ë†“ê³  ìˆë‹¤. ë¶„ì‚°ê³¼ ìš´ì€, 38ê²½ê¸° í”„ë¡œê·¸ë¨ì—ì„œ ìƒë‹¹í•œ ì–‘ìœ¼ë¡œ ë‚¨ì•„ìˆë‹¤. ì—¬ì „íˆ ê·¸ ì°¨ì´ë“¤ì€ ì¢ê³ , ë§Œì•½ ì§€ë‚œ í•´ê°€ ì–´ë–¤ ê²ƒë„ ìƒˆë¡œ ì¦ëª…í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ë©´, ì—´ì‹¬íˆ ì¼í•˜ëŠ” ê²ƒê³¼ ìŠ¤ë§ˆíŠ¸í•¨ì´ í´ëŸ½ì˜ ì€í–‰ ê³„ì¢Œì˜ ì‚¬ì´ì¦ˆ ë³´ë‹¤ ë” ì¤‘ìš”í•  ìˆ˜ ìˆë‹¤.</p>
<p>ì¶œ ì²˜ : <a href="http://www.telegraph.co.uk/football/2016/04/16/the-numbers-dont-lie-why-football-clubs-place-such-importance-on/">http://www.telegraph.co.uk/football/2016/04/16/the-numbers-dont-lie-why-football-clubs-place-such-importance-on/</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-14T11:01:27.000Z" title="2020-05-14T11:01:27.000Z">2020-05-14</time><span class="level-item">30 minutes read (About 4483 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/14/leverage-outliar-cooks-distance-anova/">leverage-outliar-cooks_distance_anova</a></h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br></pre></td></tr></table></figure>

<h4 id="ë ˆë²„ë¦¬ì§€-leverage"><a href="#ë ˆë²„ë¦¬ì§€-leverage" class="headerlink" title="ë ˆë²„ë¦¬ì§€ (leverage)"></a>ë ˆë²„ë¦¬ì§€ (leverage)</h4><pre><code>ë…ë¦½ë³€ìˆ˜ì˜ ì „ì²´ ë°ì´í„°ê°€ ì•„ë‹Œ ê°œë³„ì ì¸ ë°ì´í„° í‘œë³¸ í•˜ë‚˜í•˜ë‚˜ê°€ íšŒê·€ë¶„ì„ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ë ¥ì€ ë ˆë²„ë¦¬ì§€ ë¶„ì„ì´ë‚˜ ì•„ì›ƒë¼ì´ì–´ ë¶„ì„ì„ í†µí•´ ì•Œ ìˆ˜ ìˆë‹¤.
ë ˆë²„ë¦¬ì§€(leverage)ëŠ” ì‹¤ì œ ì¢…ì†ë³€ìˆ˜ê°’  ğ‘¦ ê°€ ì˜ˆì¸¡ì¹˜(predicted target)  ğ‘¦Ì‚  ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë‚˜íƒ€ë‚¸ ê°’ì´ë‹¤. self-influence, self-sensitivity ë¼ê³ ë„ í•œë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows Ã— 14 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">df0 = pd.concat([dfX, dfy],axis=<span class="number">1</span>)</span><br><span class="line">df0</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>const</th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>1.0</td>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>1.0</td>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>1.0</td>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>1.0</td>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>1.0</td>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows Ã— 15 columns</p>
</div>



<h5 id="statsmodelsë¥¼-ì´ìš©í•œ-ë ˆë²„ë¦¬ì§€-ê³„ì‚°"><a href="#statsmodelsë¥¼-ì´ìš©í•œ-ë ˆë²„ë¦¬ì§€-ê³„ì‚°" class="headerlink" title="statsmodelsë¥¼ ì´ìš©í•œ ë ˆë²„ë¦¬ì§€ ê³„ì‚°"></a>statsmodelsë¥¼ ì´ìš©í•œ ë ˆë²„ë¦¬ì§€ ê³„ì‚°</h5><pre><code>ë ˆë²„ë¦¬ì§€ ê°’ì€ RegressionResults í´ë˜ìŠ¤ì˜ get_influence ë©”ì„œë“œë¡œ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í•  ìˆ˜ ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 100ê°œì˜ ë°ì´í„° ìƒì„±</span></span><br><span class="line">X0, y, coef = make_regression(n_samples=<span class="number">100</span>, n_features=<span class="number">1</span>, noise=<span class="number">20</span>,</span><br><span class="line">                             coef=<span class="literal">True</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ë ˆë²„ë¦¬ì§€ê°€ ë†’ì€ ê°€ìƒì˜ ë°ì´í„°ë¥¼ ì¶”ê°€</span></span><br><span class="line">data_100 = (<span class="number">4</span>, <span class="number">300</span>)</span><br><span class="line">data_101 = (<span class="number">3</span>, <span class="number">150</span>)</span><br><span class="line">X0 = np.vstack([X0, np.array([data_100[:<span class="number">1</span>], data_101[:<span class="number">1</span>]])])</span><br><span class="line">X = sm.add_constant(X0) <span class="comment">#ìƒìˆ˜í•­ ì¶”ê°€</span></span><br><span class="line">y = np.hstack([y, [data_100[<span class="number">1</span>], data_101[<span class="number">1</span>]]])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt.scatter(X0, y, s=<span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>)</span><br><span class="line">plt.title(<span class="string">"ê°€ìƒì˜ íšŒê·€ë¶„ì„ìš© ë°ì´í„°"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="849" alt="output_6_0" src="https://user-images.githubusercontent.com/59719711/81926194-91f19200-961c-11ea-9b3f-3acaa0daccab.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS(pd.DataFrame(y), pd.DataFrame(X))</span><br><span class="line">result = model.fit()</span><br><span class="line">print(result.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      0   R-squared:                       0.936
Model:                            OLS   Adj. R-squared:                  0.935
Method:                 Least Squares   F-statistic:                     1464.
Date:                Thu, 14 May 2020   Prob (F-statistic):           1.61e-61
Time:                        14:22:53   Log-Likelihood:                -452.71
No. Observations:                 102   AIC:                             909.4
Df Residuals:                     100   BIC:                             914.7
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
0              3.2565      2.065      1.577      0.118      -0.840       7.353
1             78.3379      2.048     38.260      0.000      74.276      82.400
==============================================================================
Omnibus:                       16.191   Durbin-Watson:                   1.885
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.807
Skew:                          -0.534   Prob(JB):                     1.02e-08
Kurtosis:                       5.742   Cond. No.                         1.14
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


ì„ í˜•íšŒê·€ ê²°ê³¼ì—ì„œ get_influence ë©”ì„œë“œë¥¼ í˜¸ì¶œí•˜ë©´ ì˜í–¥ë„ ì •ë³´ ê°ì²´ë¥¼ êµ¬í•  ìˆ˜ ìˆê³ , ì´ ê°ì²´ëŠ” hat_matrix_diag ì†ì„±ìœ¼ë¡œ ë ˆë²„ë¦¬ì§€ ë²¡í„°ì˜ ê°’ì„ ê°€ì§€ê³ ë„ ìˆì–´</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">influence = result.get_influence()</span><br><span class="line">hat = influence.hat_matrix_diag</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt. stem(hat)</span><br><span class="line">plt.axhline(<span class="number">0.02</span>, c = <span class="string">'g'</span>, ls = <span class="string">'--'</span>) <span class="comment"># c = color , ls = linestyle</span></span><br><span class="line">plt.title(<span class="string">'ê° ë°ì´í„°ì˜ ë ˆë²„ë¦¬ì§€ ê°’'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.
  &quot;&quot;&quot;</code></pre><img width="831" alt="output_9_1" src="https://user-images.githubusercontent.com/59719711/81926258-a6ce2580-961c-11ea-9442-38672fbc831a.png">


<pre><code>ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” ì½”ë“œì—ì„œ 0.02ì˜ ê°’ì€ ë ˆë²„ë¦¬ì§€ í‰ê· ê°’ì„ êµ¬í•˜ëŠ” ê³µì‹ ë…ë¦½ë³€ìˆ˜ì˜ ê°¯ìˆ˜ / ë°ì´í„°ì˜ ê°¯ìˆ˜ ë¡œ êµ¬í•˜ë©´ ëœë‹¤</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º <span class="number">2020</span><span class="number">-05</span><span class="number">-14</span> á„‹á…©á„’á…® <span class="number">2</span> <span class="number">31</span> <span class="number">46</span>](https://user-images.githubusercontent.com/<span class="number">59719711</span>/<span class="number">81926278</span>-b2215100<span class="number">-961</span>c<span class="number">-11</span>ea<span class="number">-9613</span>-c5ba582d5de0.png)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(X0, y,s=<span class="number">30</span>)</span><br><span class="line">sm.graphics.abline_plot(model_results=result, ax=ax)</span><br><span class="line"></span><br><span class="line">idx = hat &gt; <span class="number">0.05</span></span><br><span class="line">plt.scatter(X0[idx], y[idx], s=<span class="number">300</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.title(<span class="string">"íšŒê·€ë¶„ì„ ê²°ê³¼ì™€ ë ˆë²„ë¦¬ì§€ í¬ì¸íŠ¸"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="833" alt="output_12_0" src="https://user-images.githubusercontent.com/59719711/81926328-bc434f80-961c-11ea-89ef-927b80f666c7.png">


<pre><code>ê·¸ë˜í”„ë¥¼ í† ëŒ€ë¡œ í•´ì„ì„ í•˜ìë©´, ë°ì´í„°ê°€ í˜¼ìë§Œ ë„ˆë¬´ ì‘ê±°ë‚˜ ë„ˆë¬´ í¬ê²Œ ë‹¨ë…ìœ¼ë¡œ ì¡´ì¬í• ìˆ˜ë¡ ë ˆë²„ë¦¬ì§€ê°€ ì»¤ì§ì„ ì•Œ ìˆ˜ ìˆì–´. ì´ ë§ì€ ì €ëŸ° ë°ì´í„°ì€ ì „ì²´ íšŒê·€ë¶„ì„ ê²°ê³¼ê°’ì— í° ì˜í–¥ì„ ë¯¸ì¹œë‹¤ëŠ” ë§ì´ì•¼</code></pre><h4 id="ì•„ì›ƒë¼ì´ì–´-outlier"><a href="#ì•„ì›ƒë¼ì´ì–´-outlier" class="headerlink" title="ì•„ì›ƒë¼ì´ì–´(outlier)"></a>ì•„ì›ƒë¼ì´ì–´(outlier)</h4><pre><code>ë°ì´í„°ì™€ ë™ë–¨ì–´ì§„ ê°’ì„ ê°€ì§€ëŠ” ë°ì´í„°, ì¦‰ ì”ì°¨ê°€ í° ë°ì´í„°ë¥¼ ì•„ì›ƒë¼ì´ì–´(outlier)ë¼ê³  í•˜ëŠ”ë°, ì”ì°¨ì˜ í¬ê¸°ëŠ” ë…ë¦½ ë³€ìˆ˜ì˜ ì˜í–¥ì„ ë°›ìœ¼ë¯€ë¡œ ì•„ì›ƒë¼ì´ì–´ë¥¼ ì°¾ìœ¼ë ¤ë©´ ì´ ì˜í–¥ì„ ì œê±°í•œ í‘œì¤€í™”ëœ ì”ì°¨ë¥¼ ê³„ì‚°í•´ì•¼ í•œë‹¤ê³  í•´. ë¬´ìŠ¨ë§ì¸ì§€ ì˜ ëª¨ë¥´ê² ì§€ë§Œ ê·¸ë˜

statsmodelsë¥¼ ì´ìš©í•œ í‘œì¤€í™” ì”ì°¨ ê³„ì‚°

ì”ì°¨ëŠ” RegressionResult ê°ì²´ì˜ resid ì†ì„±ì— ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line">plt.stem(result.resid)</span><br><span class="line">plt.title(<span class="string">"ê° ë°ì´í„°ì˜ ì”ì°¨"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.</code></pre><img width="826" alt="output_16_1" src="https://user-images.githubusercontent.com/59719711/81926368-c8c7a800-961c-11ea-9826-24478a19b3b4.png">


<pre><code>í‘œì¤€í™” ì”ì°¨ëŠ” resid_pearson ì†ì„±ì— ìˆê³ , ë³´í†µ í‘œì¤€í™” ì”ì°¨ê°€ 2~4ë³´ë‹¤ í¬ë©´ ì•„ì›ƒë¼ì´ì–´ë¡œ ë³´ëŠ”ê²Œ ì¼ë°˜ì ì´ì•¼</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt. stem(result.resid_pearson)</span><br><span class="line">plt.axhline(<span class="number">3</span>, c=<span class="string">'g'</span>, ls=<span class="string">'--'</span>)</span><br><span class="line">plt.axhline(<span class="number">-3</span>, c=<span class="string">'g'</span>, ls=<span class="string">'--'</span>)</span><br><span class="line">plt.title(<span class="string">'ê° ë°ì´í„°ì˜ í‘œì¤€í™” ì”ì°¨'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.</code></pre><img width="818" alt="output_18_1" src="https://user-images.githubusercontent.com/59719711/81926392-d41ad380-961c-11ea-852b-985bce5ea681.png">


<h4 id="Cookâ€™s-Distance"><a href="#Cookâ€™s-Distance" class="headerlink" title="Cookâ€™s Distance"></a>Cookâ€™s Distance</h4><pre><code>íšŒê·€ ë¶„ì„ì—ëŠ” ë ˆë²„ë¦¬ì§€ ë”°ë¡œ, ì”ì°¨ì˜ í¬ê¸°ê°€ í° ë°ì´í„°ê°€ ì•„ì›ƒë¼ì´ì–´ê°€ ë˜ê³  ê·¸ê²ƒì„ ë³´ëŠ” ë”°ë¡œë”°ë¡œì˜ ê¸°ëŠ¥ë„ ìˆì§€ë§Œ  ì´ ë‘ê°œë¥¼ ë™ì‹œì— ë³´ëŠ” ë°©ë²•ì´ ë°”ë¡œ Cook&apos;s Distanceì•¼. ì•„ë§ˆë„ Cookì´ë¼ëŠ” ì‚¬ëŒì´ ë§Œë“¤ì—ˆì„ ê°€ëŠ¥ì„±ì´..

ë„˜ì–´ê°€ì

ë™ì‹œì— ë³´ëŠ” ê¸°ì¤€ì´ë¼ê³  ìƒê°í•˜ë©´ ë˜ê³ , ë‘˜ì¤‘ í•˜ë‚˜ë§Œ ì»¤ì§€ë”ë¼ë„ ì´ Cook&apos;s distance ê°’ì€ ì»¤ì§€ê²Œ ë¼

ëª¨ë“  ë°ì´í„°ì˜ ë ˆë²„ë¦¬ì§€ì™€ ì”ì°¨ë¥¼ ë™ì‹œì— ë³´ë ¤ë©´ plot_leverage_resid2 ëª…ë ¹ì„ ì‚¬ìš©í•˜ëŠ”ë°, ì´ ëª…ë ¹ì€ xì¶•ìœ¼ë¡œ í‘œì¤€í™” ì”ì°¨ì˜ ì œê³±ì„ í‘œì‹œí•˜ê³  yì¶•ìœ¼ë¡œ ë ˆë²„ë¦¬ì§€ê°’ì„ í‘œì‹œí•œë‹¤. 

ê·¸ë¦¬ê³  ë°ì´í„° ì•„ì´ë””ê°€ í‘œì‹œëœ ë°ì´í„°ë“¤ì´ ë ˆë²„ë¦¬ì§€ê°€ í° ì•„ì›ƒë¼ì´ì–´ ì•¼</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sm.graphics.plot_leverage_resid2(result)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">sm.graphics.influence_plot(result)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<pre><code>&lt;Figure size 1008x432 with 0 Axes&gt;</code></pre><img width="401" alt="output_21_1" src="https://user-images.githubusercontent.com/59719711/81926442-e563e000-961c-11ea-9511-4128f90f70c5.png">




<img width="392" alt="output_21_2" src="https://user-images.githubusercontent.com/59719711/81926462-ed238480-961c-11ea-827c-5e2360d26f75.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> statsmodels.graphics <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line">cooks_d2, pvals = influence.cooks_distance</span><br><span class="line">K = influence.k_vars</span><br><span class="line">fox_cr = <span class="number">4</span> / (len(y) - K - <span class="number">1</span>)</span><br><span class="line">idx = np.where(cooks_d2 &gt; fox_cr)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(X0, y)</span><br><span class="line">plt.scatter(X0[idx], y[idx], s=<span class="number">300</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">utils.annotate_axes(range(len(idx)), idx,</span><br><span class="line">                    list(zip(X0[idx], y[idx])), [(<span class="number">-20</span>, <span class="number">15</span>)] * len(idx), size=<span class="string">"small"</span>, ax=ax)</span><br><span class="line">plt.title(<span class="string">"Fox Recommendaionìœ¼ë¡œ ì„ íƒí•œ ì•„ì›ƒë¼ì´ì–´"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="387" alt="output_22_0" src="https://user-images.githubusercontent.com/59719711/81926491-fb71a080-961c-11ea-815d-7cab11d016fd.png">


<h5 id="ë³´ìŠ¤í„´-ì§‘ê°’-ì˜ˆì¸¡-ë¬¸ì œÂ¶"><a href="#ë³´ìŠ¤í„´-ì§‘ê°’-ì˜ˆì¸¡-ë¬¸ì œÂ¶" class="headerlink" title="ë³´ìŠ¤í„´ ì§‘ê°’ ì˜ˆì¸¡ ë¬¸ì œÂ¶"></a>ë³´ìŠ¤í„´ ì§‘ê°’ ì˜ˆì¸¡ ë¬¸ì œÂ¶</h5><pre><code>ë³´ìŠ¤í„´ ì§‘ê°’ ë¬¸ì œì— ì•„ì›ƒë¼ì´ì–´ë¥¼ ì ìš©í•´ ë³´ì. MEDVê°€ 50ì¸ ë°ì´í„°ëŠ” ìƒì‹ì ìœ¼ë¡œ ìƒê°í•´ë„ ì´ìƒí•œ ë°ì´í„°ì´ë¯€ë¡œ ì•„ì›ƒë¼ì´ì–´ë¼ê³  íŒë‹¨í•  ìˆ˜ ìˆë‹¤. ë‚˜ë¨¸ì§€ ë°ì´í„° ì¤‘ì—ì„œ í­ìŠ¤ ì¶”ì²œê³µì‹ì„ ì‚¬ìš©í•˜ì—¬ ì•„ì›ƒë¼ì´ì–´ë¥¼ ì œì™¸í•œ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br><span class="line"></span><br><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">df0 = pd.concat([dfX, dfy],axis=<span class="number">1</span>)</span><br><span class="line">df0</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">pred = result_boston.predict(dfX)</span><br><span class="line"></span><br><span class="line">influence_boston = result_boston.get_influence()</span><br><span class="line">cooks_d2, pvals = influence_boston.cooks_distance</span><br><span class="line">K = influence.k_vars</span><br><span class="line">fox_cr = <span class="number">4</span> / (len(y) - K - <span class="number">1</span>)</span><br><span class="line">idx = np.where(cooks_d2 &gt; fox_cr)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># MEDV = 50 ì œê±°</span></span><br><span class="line">idx = np.hstack([idx, np.where(boston.target == <span class="number">50</span>)[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(dfy, pred)</span><br><span class="line">plt.scatter(dfy.MEDV[idx], pred[idx], s=<span class="number">200</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">utils.annotate_axes(range(len(idx)), idx,</span><br><span class="line">                    list(zip(dfy.MEDV[idx], pred[idx])), [(<span class="number">-20</span>, <span class="number">15</span>)] * len(idx), size=<span class="string">"small"</span>, ax=ax)</span><br><span class="line">plt.title(<span class="string">"ë³´ìŠ¤í„´ ì§‘ê°’ ë°ì´í„°ì—ì„œ ì•„ì›ƒë¼ì´ì–´"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="374" alt="output_25_0" src="https://user-images.githubusercontent.com/59719711/81926518-04fb0880-961d-11ea-8ec0-70154b06352f.png">


<pre><code>ë‹¤ìŒì€ ì´ë ‡ê²Œ ì•„ì›ƒë¼ì´ì–´ë¥¼ ì œì™¸í•œ í›„ì— ë‹¤ì‹œ íšŒê·€ë¶„ì„ì„ í•œ ê²°ê³¼ì´ë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">idx2 = list(set(range(len(dfX))).difference(idx))</span><br><span class="line">dfX = dfX.iloc[idx2, :].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">dfy = dfy.iloc[idx2, :].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">model_boston2 = sm.OLS(dfy, dfX)</span><br><span class="line">result_boston2 = model_boston2.fit()</span><br><span class="line">print(result_boston2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.812
Model:                            OLS   Adj. R-squared:                  0.806
Method:                 Least Squares   F-statistic:                     156.1
Date:                Thu, 14 May 2020   Prob (F-statistic):          2.41e-161
Time:                        15:14:52   Log-Likelihood:                -1285.2
No. Observations:                 485   AIC:                             2598.
Df Residuals:                     471   BIC:                             2657.
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         18.8999      4.107      4.602      0.000      10.830      26.969
CRIM          -0.0973      0.024     -4.025      0.000      -0.145      -0.050
ZN             0.0278      0.010      2.651      0.008       0.007       0.048
INDUS         -0.0274      0.046     -0.595      0.552      -0.118       0.063
CHAS           0.9228      0.697      1.324      0.186      -0.447       2.292
NOX           -9.4922      2.856     -3.323      0.001     -15.105      -3.879
RM             5.0921      0.371     13.735      0.000       4.364       5.821
AGE           -0.0305      0.010     -2.986      0.003      -0.051      -0.010
DIS           -1.0562      0.150     -7.057      0.000      -1.350      -0.762
RAD            0.1990      0.049      4.022      0.000       0.102       0.296
TAX           -0.0125      0.003     -4.511      0.000      -0.018      -0.007
PTRATIO       -0.7777      0.098     -7.955      0.000      -0.970      -0.586
B              0.0107      0.002      5.348      0.000       0.007       0.015
LSTAT         -0.2846      0.043     -6.639      0.000      -0.369      -0.200
==============================================================================
Omnibus:                       45.944   Durbin-Watson:                   1.184
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.791
Skew:                           0.679   Prob(JB):                     5.17e-15
Kurtosis:                       4.188   Cond. No.                     1.59e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.59e+04. This might indicate that there are
strong multicollinearity or other numerical problems.


R-squared ì˜ ì„±ëŠ¥ì ìˆ˜ê°€ ì˜¬ë¼ê°„ ê²ƒì„ ë³¼ ìˆ˜ ìˆì–´.

ì´ë ‡ê²Œ ì–´ë–¤ íŠ¹ì • ë°ì´í„°ë¥¼ ê°€ì§€ê³  íšŒê·€ë¶„ì„ ëª¨ë¸ë§ì„ í•  ë•Œì—ëŠ” í•˜ê¸° ì „ì— ë ˆë²„ë¦¬ì§€ê°€ í° ë°ì´í„°ì™€ ì•„ì›ƒë¼ì´ì–´ì˜ ê°’ì„ ì´ëŸ¬í•œ ì ˆì°¨ì— ì˜í•´ ë½‘ì•„ì„œ ì œê±°í•˜ê³  ëª¨ë¸ë§ì„ í•œë‹¤ë©´ ë”ìš± ì„±ëŠ¥ì´ ì¢‹ì€ íšŒê·€ë¶„ì„ ëª¨ë¸ë§ì„ í•  ìˆ˜ ìˆëŠ”ê±°ì•¼</code></pre><h4 id="ë¶„ì‚°-ë¶„ì„"><a href="#ë¶„ì‚°-ë¶„ì„" class="headerlink" title="ë¶„ì‚° ë¶„ì„"></a>ë¶„ì‚° ë¶„ì„</h4><pre><code>ì„ í˜•íšŒê·€ë¶„ì„ì˜ ê²°ê³¼ê°€ ì–¼ë§ˆë‚˜ ì¢‹ì€ì§€ëŠ” ë‹¨ìˆœíˆ ì”ì°¨ì œê³±í•©(RSS: Residula Sum of Square)ìœ¼ë¡œ í‰ê°€í•  ìˆ˜ ì—†ë‹¤. ë³€ìˆ˜ì˜ ë‹¨ìœ„ ì¦‰, ìŠ¤ì¼€ì¼ì´ ë‹¬ë¼ì§€ë©´ íšŒê·€ë¶„ì„ê³¼ ìƒê´€ì—†ì´ ì”ì°¨ì œê³±í•©ë„ ë‹¬ë¼ì§€ê¸° ë•Œë¬¸ì´ì•¼ ( ex.1kmì™€ 1000m)

ë¶„ì‚° ë¶„ì„(ANOVA: Analysis of Variance)ì€ ì¢…ì†ë³€ìˆ˜ì˜ ë¶„ì‚°ê³¼ ë…ë¦½ë³€ìˆ˜ì˜ ë¶„ì‚°ê°„ì˜ ê´€ê³„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ í˜•íšŒê·€ë¶„ì„ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³ ì í•˜ëŠ” ë°©ë²•ì´ë‹¤. ë¶„ì‚° ë¶„ì„ì€ ì„œë¡œ ë‹¤ë¥¸ ë‘ ê°œì˜ ì„ í˜•íšŒê·€ë¶„ì„ì˜ ì„±ëŠ¥ ë¹„êµì— ì‘ìš©í•  ìˆ˜ ìˆìœ¼ë©° ë…ë¦½ë³€ìˆ˜ê°€ ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜ì¸ ê²½ìš° ê° ì¹´í…Œê³ ë¦¬ ê°’ì— ë”°ë¥¸ ì˜í–¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ”ë°ë„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ë¼

ì—¬ëŸ¬ ìˆ˜ì‹ë“¤ì´ ì¡´ì¬í•˜ì§€ë§Œ ë‚´ê°€ ì´í•´ë¥¼ ëª»í•˜ê² ê³  ê²°ë¡ ì€ ë‹¤ìŒê³¼ ê°™ì•„.

ëª¨í˜• ì˜ˆì¸¡ì¹˜ì˜ ì›€ì§ì„ì˜ í¬ê¸°(ë¶„ì‚°,ESS)ì€ ì¢…ì†ë³€ìˆ˜ì˜ ì›€ì§ì„ì˜ í¬ê¸°(ë¶„ì‚°,TSS)ë³´ë‹¤ í´ ìˆ˜ ì—†ì–´ ê·¸ë¦¬ê³  ëª¨í˜•ì˜ ì„±ëŠ¥ì´ ì¢‹ì„ìˆ˜ë¡ ëª¨í˜• ì˜ˆì¸¡ì¹˜ì˜ ì›€ì§ì„ì˜ í¬ê¸°ëŠ” ì¢…ì†ë³€ìˆ˜ì˜ ì›€ì§ì„ì˜ í¬ê¸°ì™€ ë¹„ìŠ·í•´ì§„ë‹¤ëŠ” ì ì´ì•¼</code></pre><h5 id="F-ê²€ì •ì„-ì‚¬ìš©í•œ-ë³€ìˆ˜-ì¤‘ìš”ë„-ë¹„êµ"><a href="#F-ê²€ì •ì„-ì‚¬ìš©í•œ-ë³€ìˆ˜-ì¤‘ìš”ë„-ë¹„êµ" class="headerlink" title="F ê²€ì •ì„ ì‚¬ìš©í•œ ë³€ìˆ˜ ì¤‘ìš”ë„ ë¹„êµ"></a>F ê²€ì •ì„ ì‚¬ìš©í•œ ë³€ìˆ˜ ì¤‘ìš”ë„ ë¹„êµ</h5><pre><code>Fê²€ì •ì€ ê° ë…ë¦½ë³€ìˆ˜ì˜ ì¤‘ìš”ë„ë¥¼ ë¹„êµí•˜ê¸° ìœ„í•´ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ë°©ë²•ì€ ì „ì²´ ëª¨í˜•ê³¼ ê° ë³€ìˆ˜ í•˜ë‚˜ë§Œì„ ëº€ ëª¨í˜•ë“¤ì˜ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ê²ƒì¸ë°, ì´ëŠ” ê°„ì ‘ì ìœ¼ë¡œ ê° ë…ë¦½ ë³€ìˆ˜ì˜ ì˜í–¥ë ¥ì„ ì¸¡ì •í•˜ëŠ” ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ë³´ìŠ¤í„´ ì§‘ê°’ ë°ì´í„°ì—ì„œ CRIMì´ë€ ë³€ìˆ˜ë¥¼ ëº€ ëª¨ë¸ê³¼ ì „ì²´ ëª¨ë¸ì˜ ë¹„êµí•˜ëŠ” ê²€ì •ì„ í•˜ë©´ ì´ ê²€ì • ê²°ê³¼ëŠ” CRIMë³€ìˆ˜ì˜ ì¤‘ìš”ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_full = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ CRIM + ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line">model_reduced = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line"></span><br><span class="line">sm.stats.anova_lm(model_reduced.fit(), model_full.fit())</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater
  return (a &lt; x) &amp; (x &lt; b)
/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less
  return (a &lt; x) &amp; (x &lt; b)
/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 &amp; (x &lt;= _a)</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df_resid</th>
      <th>ssr</th>
      <th>df_diff</th>
      <th>ss_diff</th>
      <th>F</th>
      <th>Pr(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>493.0</td>
      <td>11322.004277</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>492.0</td>
      <td>11078.784578</td>
      <td>1.0</td>
      <td>243.219699</td>
      <td>10.801193</td>
      <td>0.001087</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>anova_lm ëª…ë ¹ì—ì„œëŠ” typ ì¸ìˆ˜ë¥¼ 2ë¡œ ì§€ì •í•˜ë©´ í•˜ë‚˜ í•˜ë‚˜ì˜ ë³€ìˆ˜ë¥¼ ëº€ ì¶•ì†Œ ëª¨í˜•ì—ì„œì˜ F ê²€ì •ê°’ì„ í•œêº¼ë²ˆì— ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.</code></pre><h5 id="ì•„ë…¸ë°”-ë¶„ì„-Fê²€ì •"><a href="#ì•„ë…¸ë°”-ë¶„ì„-Fê²€ì •" class="headerlink" title="ì•„ë…¸ë°” ë¶„ì„ - Fê²€ì •"></a>ì•„ë…¸ë°” ë¶„ì„ - Fê²€ì •</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ CRIM + ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line">result = model.fit()</span><br><span class="line">sm.stats.anova_lm(result, typ=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>243.219699</td>
      <td>1.0</td>
      <td>10.801193</td>
      <td>1.086810e-03</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>257.492979</td>
      <td>1.0</td>
      <td>11.435058</td>
      <td>7.781097e-04</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>2.516668</td>
      <td>1.0</td>
      <td>0.111763</td>
      <td>7.382881e-01</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>487.155674</td>
      <td>1.0</td>
      <td>21.634196</td>
      <td>4.245644e-06</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>1871.324082</td>
      <td>1.0</td>
      <td>83.104012</td>
      <td>1.979441e-18</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.061834</td>
      <td>1.0</td>
      <td>0.002746</td>
      <td>9.582293e-01</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>1232.412493</td>
      <td>1.0</td>
      <td>54.730457</td>
      <td>6.013491e-13</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>479.153926</td>
      <td>1.0</td>
      <td>21.278844</td>
      <td>5.070529e-06</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>242.257440</td>
      <td>1.0</td>
      <td>10.758460</td>
      <td>1.111637e-03</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>1194.233533</td>
      <td>1.0</td>
      <td>53.034960</td>
      <td>1.308835e-12</td>
    </tr>
    <tr>
      <th>B</th>
      <td>270.634230</td>
      <td>1.0</td>
      <td>12.018651</td>
      <td>5.728592e-04</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>2410.838689</td>
      <td>1.0</td>
      <td>107.063426</td>
      <td>7.776912e-23</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>218.970357</td>
      <td>1.0</td>
      <td>9.724299</td>
      <td>1.925030e-03</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>11078.784578</td>
      <td>492.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>ê°ê°ì˜ ë…ë¦½ë³€ìˆ˜ë“¤ì˜ ì „ì²´ì™€ ë¹„êµí–ˆì„ ë•Œ ì–¼ë§ˆë§Œí¼ ì¤‘ìš”ë„ë¥¼ ê°€ì§€ëŠ”ë° ì •ëŸ‰ì ìœ¼ë¡œ ë‚˜ì˜¨ ê²°ê³¼ê°’ì´ì•¼. ì—¬ê¸°ì„œ ì£¼ëª©í•´ì•¼í•  ë¶€ë¶„ì€ PR&gt;(&gt;F)ë¶€ë¶„ìœ¼ë¡œ summaryì—ì„œë„ ë‚˜ì˜¤ëŠ” p-valueê°’ì„ ë””í…Œì¼í•˜ê²Œ í’€ì–´ë†“ì€ ê°’ì´ê³  ì˜ˆë¥¼ ë“¤ì–´ LSTAT, RMì˜ ê²½ìš° 10ì˜ -23ìŠ¹, 10ì˜ -18ìŠ¹ìœ¼ë¡œ ìˆ˜ì¹˜ê°€ ì œì¼ ë‚®ì€ê±¸ ì•Œ ìˆ˜ ìˆì–´. ê·¸ëŸ¬ë©´ ì´ 2ê°€ì§€ì˜ ë…ë¦½ë³€ìˆ˜ê°€ ì¢…ì†ë³€ìˆ˜ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì³¤ë‹¤ê³  í•´ì„í•˜ë©´ ë˜ëŠ”ê±°ì•¼
í‘œì˜ Fê°’ì„ ë³´ê³ ë„ ì•Œ ìˆ˜ ìˆì§€ë§Œ Fê°’ì€ í™•ë¥ ì˜ ì˜ë¯¸ëŠ” ì—†ê¸° ë•Œë¬¸ì— ë‹¨ìˆœ ìˆœìœ„ë¥¼ ë§¤ê¸°ëŠ”ê±° ë¼ë©´ ê²°ì •í•  ìˆ˜ ìˆì§€ë§Œ ë§Œì•½ ê·€ë¬´ê°€ì„¤/ëŒ€ë¦½ê°€ì„¤ì„ accept í•˜ëƒ reject í•˜ëƒì˜ í™•ë¥ ì  ì˜ë¯¸ë¥¼ íŒë‹¨í•œë‹¤ë©´ Fê°’ë§Œìœ¼ë¡œëŠ” ë¶ˆê°€ëŠ¥í•´</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="ë²”ì£¼í˜•ì„-ì‚¬ìš©í•œ-ë¹„ì„ í˜•ì„±"><a href="#ë²”ì£¼í˜•ì„-ì‚¬ìš©í•œ-ë¹„ì„ í˜•ì„±" class="headerlink" title="ë²”ì£¼í˜•ì„ ì‚¬ìš©í•œ ë¹„ì„ í˜•ì„±"></a>ë²”ì£¼í˜•ì„ ì‚¬ìš©í•œ ë¹„ì„ í˜•ì„±</h5><pre><code>ë…ë¦½ë³€ìˆ˜ì˜ ë¹„ì„ í˜•ì„±ì„ í¬ì°©í•˜ëŠ” ë˜ ë‹¤ë¥¸ ë°©ë²• ì¤‘ í•˜ë‚˜ëŠ” ê°•ì œë¡œ ë²”ì£¼í˜• ê°’ìœ¼ë¡œ ë§Œë“œëŠ” ê²ƒì´ë‹¤. ë²”ì£¼í˜• ê°’ì´ ë˜ë©´ì„œ ë…ë¦½ë³€ìˆ˜ì˜ ì˜¤ì°¨ê°€ ìƒê¸°ì§€ë§Œ ì´ë¡œ ì¸í•œ ì˜¤ì°¨ë³´ë‹¤ ë¹„ì„ í˜•ì„±ìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì´ìµì´ í´ ìˆ˜ë„ ìˆë‹¤.

ë³´ìŠ¤í„´ ì§‘ê°’ ë°ì´í„°ì—ì„œ ì¢…ì†ë³€ìˆ˜ì™€ RM ë³€ìˆ˜ì˜ ê´€ê³„ëŠ” ì„ í˜•ì— ê°€ê¹ì§€ë§Œ ë°©ì˜ ê°¯ìˆ˜ê°€ ì•„ì£¼ ì‘ì•„ì§€ê±°ë‚˜ ì•„ì£¼ ì»¤ì§€ë©´ ì„ í˜•ëª¨í˜•ì—ì„œ ë²—ì–´ë‚œë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sns.scatterplot(x=<span class="string">"RM"</span>, y=<span class="string">"MEDV"</span>, data=df0, s=<span class="number">60</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="836" alt="output_39_0" src="https://user-images.githubusercontent.com/59719711/81926554-17754200-961d-11ea-9ea7-69b37349b510.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_rm = sm.OLS.from_formula(<span class="string">'MEDV ~ RM'</span>, data=df0)</span><br><span class="line">result_rm = model_rm.fit()</span><br><span class="line">print(result_rm.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.484
Model:                            OLS   Adj. R-squared:                  0.483
Method:                 Least Squares   F-statistic:                     471.8
Date:                Thu, 14 May 2020   Prob (F-statistic):           2.49e-74
Time:                        19:28:18   Log-Likelihood:                -1673.1
No. Observations:                 506   AIC:                             3350.
Df Residuals:                     504   BIC:                             3359.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept    -34.6706      2.650    -13.084      0.000     -39.877     -29.465
RM             9.1021      0.419     21.722      0.000       8.279       9.925
==============================================================================
Omnibus:                      102.585   Durbin-Watson:                   0.684
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              612.449
Skew:                           0.726   Prob(JB):                    1.02e-133
Kurtosis:                       8.190   Cond. No.                         58.4
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


ì´ë ‡ê²Œ RM ë°ì´í„° ì „ì²´ë¥¼ ë†“ê³  ë³´ë©´ ì¢…ì†ë³€ìˆ˜ yì™€ ì•„ì£¼ í° ìƒê´€ê´€ê³„ê°€ ìˆëŠ”ê²ƒìœ¼ë¡œ ë³´ì´ì§€ë§Œ ìœ„ì— ê·¸ë˜í”„ì—ì„œ ë´¤ë“¯ì´, ë°©ì˜ ê°¯ìˆ˜ê°€ ì•„ì£¼ ì ê±°ë‚˜, ë§ìœ¼ë©´ ì„ í˜•ì„±ì„ ë³´ì´ì§€ ì•ŠëŠ” êµ¬ê°„ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ë””í…Œì¼í•˜ê²Œ ìƒê´€ê´€ê²Œë¥¼ ë³´ê³  ì‹¶ë‹¤ë©´ RM ë°ì´í„°ë¥¼ ê°•ì œë¡œ ë²”ì£¼í™” ì‹œì¼œ RM ë°ì´í„°ê°€ ê°€ì§€ëŠ” ë¹„ì„ í˜•ì„±ì„ ì¡ì„ ìˆ˜ ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rooms = np.arange(<span class="number">3</span>,<span class="number">10</span>)</span><br><span class="line">labels = [str(r) <span class="keyword">for</span> r <span class="keyword">in</span> rooms[:<span class="number">-1</span>]]</span><br><span class="line">df0[<span class="string">'CAT_RM'</span>] = np.round(df[<span class="string">'RM'</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sns.barplot(<span class="string">'CAT_RM'</span>, <span class="string">'MEDV'</span>, data=df0)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="836" alt="output_42_0" src="https://user-images.githubusercontent.com/59719711/81926587-222fd700-961d-11ea-88fb-a5ff2aec6b90.png">


<pre><code>ì´ë ‡ê²Œ í•˜ë©´ RM ë³€ìˆ˜ìœ¼ë¡œ ì¸í•œ ì¢…ì†ë³€ìˆ˜ì˜ ë³€í™”ë¥¼ ë¹„ì„ í˜• ìƒìˆ˜í•­ìœ¼ë¡œ ëª¨í˜•í™” í•  ìˆ˜ ìˆë‹¤. ì„ í˜•ëª¨í˜•ë³´ë‹¤ ì„±ëŠ¥ì´ í–¥ìƒëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_rm2 = sm.OLS.from_formula(<span class="string">"MEDV ~ C(np.round(RM))"</span>, data=df0)</span><br><span class="line">result_rm2 = model_rm2.fit()</span><br><span class="line">print(result_rm2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.537
Model:                            OLS   Adj. R-squared:                  0.532
Method:                 Least Squares   F-statistic:                     115.8
Date:                Thu, 14 May 2020   Prob (F-statistic):           3.57e-81
Time:                        19:33:48   Log-Likelihood:                -1645.6
No. Observations:                 506   AIC:                             3303.
Df Residuals:                     500   BIC:                             3329.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
==========================================================================================
                             coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------------------
Intercept                 17.0200      2.814      6.049      0.000      11.492      22.548
C(np.round(RM))[T.5.0]    -2.0741      2.998     -0.692      0.489      -7.964       3.816
C(np.round(RM))[T.6.0]     2.3460      2.836      0.827      0.409      -3.226       7.918
C(np.round(RM))[T.7.0]    11.0272      2.869      3.843      0.000       5.389      16.665
C(np.round(RM))[T.8.0]    28.5425      3.093      9.228      0.000      22.466      34.619
C(np.round(RM))[T.9.0]    23.6133      4.595      5.139      0.000      14.586      32.641
==============================================================================
Omnibus:                       81.744   Durbin-Watson:                   0.799
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              467.887
Skew:                           0.542   Prob(JB):                    2.51e-102
Kurtosis:                       7.584   Cond. No.                         31.1
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><h5 id="ì‹œê°„-ë…ë¦½ë³€ìˆ˜ì˜-ë³€í˜•"><a href="#ì‹œê°„-ë…ë¦½ë³€ìˆ˜ì˜-ë³€í˜•" class="headerlink" title="ì‹œê°„ ë…ë¦½ë³€ìˆ˜ì˜ ë³€í˜•"></a>ì‹œê°„ ë…ë¦½ë³€ìˆ˜ì˜ ë³€í˜•</h5><pre><code>ë…ë¦½ë³€ìˆ˜ê°€ ì‹œê°„ì¸ ê²½ìš°ì—ëŠ” íŠ¹ì • ì‹œì ì—ì„œ ê²½ê³¼ëœ ì‹œê°„ê°’ìœ¼ë¡œ ë³€í˜•í•´ì•¼ í•œë‹¤. ì¼ê°„ ì „ê¸° ì‚¬ìš©ëŸ‰ ë°ì´í„°ë¥¼ ì˜ˆë¡œ ë“¤ì–´ ì„¤ëª…í•œë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = sm.datasets.get_rdataset(<span class="string">"elecdaily"</span>, package=<span class="string">"fpp2"</span>)</span><br><span class="line"></span><br><span class="line">df_elec = data.data.drop(columns=[<span class="string">"WorkDay"</span>, <span class="string">"Temperature"</span>])</span><br><span class="line">df_elec[<span class="string">"Date"</span>] = pd.date_range(<span class="string">"2014-1-1"</span>, <span class="string">"2014-12-31"</span>)</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>íŒŒì´ì¬ datetime ìë£Œí˜•ì€ toordinal ëª…ë ¹ìœ¼ë¡œ íŠ¹ì • ì‹œì ìœ¼ë¡œë¶€í„° ê²½ê³¼í•œ ì‹œê°„ì˜ ì¼ë‹¨ìœ„ ê°’ì„ êµ¬í•˜ê±°ë‚˜ timestamp ë©”ì„œë“œë¡œ ì´ˆë‹¨ìœ„ ê°’ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime <span class="keyword">as</span> dt</span><br><span class="line"></span><br><span class="line">df_elec[<span class="string">"Ordinal"</span>] = df_elec.Date.map(dt.datetime.toordinal)</span><br><span class="line">df_elec[<span class="string">"Timestamp"</span>] = df_elec.Date.map(dt.datetime.timestamp)</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
      <th>Ordinal</th>
      <th>Timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
      <td>735594</td>
      <td>1.419606e+09</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
      <td>735595</td>
      <td>1.419692e+09</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
      <td>735596</td>
      <td>1.419779e+09</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
      <td>735597</td>
      <td>1.419865e+09</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
      <td>735598</td>
      <td>1.419952e+09</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>ì—¬ê¸°ì—ì„œëŠ” ì¼ë‹¨ìœ„ ì‹œê°„ ê°’ì„ ì‚¬ìš©í•˜ì—¬ íšŒê·€ë¶„ì„ì„ í•œë‹¤. ì‹œê°„ ê°’ì˜ ê²½ìš° í¬ê¸°ê°€ í¬ë¯€ë¡œ ë°˜ë“œì‹œ ìŠ¤ì¼€ì¼ë§ì„ í•´ ì£¼ì–´ì•¼ í•œë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model5 = sm.OLS.from_formula(<span class="string">"Demand ~ scale(Ordinal)"</span>, data=df_elec)</span><br><span class="line">result5 = model5.fit()</span><br><span class="line">print(result5.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Demand   R-squared:                       0.031
Model:                            OLS   Adj. R-squared:                  0.028
Method:                 Least Squares   F-statistic:                     11.58
Date:                Thu, 14 May 2020   Prob (F-statistic):           0.000739
Time:                        19:35:40   Log-Likelihood:                -1709.7
No. Observations:                 365   AIC:                             3423.
Df Residuals:                     363   BIC:                             3431.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        221.2775      1.374    160.997      0.000     218.575     223.980
scale(Ordinal)    -4.6779      1.374     -3.404      0.001      -7.381      -1.975
==============================================================================
Omnibus:                       43.105   Durbin-Watson:                   0.677
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               96.485
Skew:                           0.614   Prob(JB):                     1.12e-21
Kurtosis:                       5.199   Cond. No.                         1.00
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


í•˜ì§€ë§Œ ì‹œê°„ ë…ë¦½ë³€ìˆ˜ëŠ” ì´ ì™¸ì—ë” ë‹¤ì–‘í•œ íŠ¹ì§•ë“¤ì„ ìˆ¨ê¸°ê³  ìˆë‹¤. ì˜ˆë“¤ ë“¤ì–´ ì—°ë„, ì›”, ì¼, ìš”ì¼ ë°ì´í„°ë¥¼ ë³„ë„ì˜ ë…ë¦½ë³€ìˆ˜ë¡œ ë¶„ë¦¬í•˜ê±°ë‚˜ í•œ ë‹¬ ë‚´ì—ì„œ ëª‡ë²ˆì§¸ ë‚ ì§œì¸ì§€ ì›”ì˜ ì‹œì‘ ë˜ëŠ” ëì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’ì€ ëª¨ë‘ íŠ¹ì§•ê°’ì´ ë  ìˆ˜ ìˆë‹¤. íŒë‹¤ìŠ¤ì—ì„œëŠ” dt íŠ¹ìˆ˜ ì—°ì‚°ìë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ëŸ¬í•œ ê°’ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df_elec[<span class="string">"Year"</span>] = df_elec[<span class="string">'Date'</span>].dt.year</span><br><span class="line">df_elec[<span class="string">"Month"</span>] = df_elec.Date.dt.month</span><br><span class="line">df_elec[<span class="string">"DayOfYear"</span>] = df_elec.Date.dt.dayofyear</span><br><span class="line">df_elec[<span class="string">"DayOfMonth"</span>] = df_elec.Date.dt.daysinmonth</span><br><span class="line">df_elec[<span class="string">"DayOfWeek"</span>] = df_elec.Date.dt.dayofweek</span><br><span class="line">df_elec[<span class="string">"WeekOfYear"</span>] = df_elec.Date.dt.weekofyear</span><br><span class="line">df_elec[<span class="string">"Weekday"</span>] = df_elec.Date.dt.weekday</span><br><span class="line">df_elec[<span class="string">"IsMonthStart"</span>] = df_elec.Date.dt.is_month_start</span><br><span class="line">df_elec[<span class="string">"IsMonthEnd"</span>] = df_elec.Date.dt.is_month_end</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
      <th>Ordinal</th>
      <th>Timestamp</th>
      <th>Year</th>
      <th>Month</th>
      <th>DayOfYear</th>
      <th>DayOfMonth</th>
      <th>DayOfWeek</th>
      <th>WeekOfYear</th>
      <th>Weekday</th>
      <th>IsMonthStart</th>
      <th>IsMonthEnd</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
      <td>735594</td>
      <td>1.419606e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>361</td>
      <td>31</td>
      <td>5</td>
      <td>52</td>
      <td>5</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
      <td>735595</td>
      <td>1.419692e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>362</td>
      <td>31</td>
      <td>6</td>
      <td>52</td>
      <td>6</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
      <td>735596</td>
      <td>1.419779e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>363</td>
      <td>31</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
      <td>735597</td>
      <td>1.419865e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>364</td>
      <td>31</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
      <td>735598</td>
      <td>1.419952e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>365</td>
      <td>31</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>ì´ë ‡ê²Œ ì¶”ê°€ì ì¸ íŠ¹ì§•ê°’ì„ ì´ìš©í•˜ì—¬ êµ¬í•œ ëª¨í˜•ì€ ì„±ëŠ¥ì´ í–¥ìƒëœë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">feature_names = df_elec.columns.tolist()</span><br><span class="line">feature_names.remove(<span class="string">"Demand"</span>)</span><br><span class="line">feature_names.remove(<span class="string">"Date"</span>)</span><br><span class="line"></span><br><span class="line">formula = <span class="string">"""</span></span><br><span class="line"><span class="string">Demand ~ scale(Ordinal) + C(Month) + DayOfYear + </span></span><br><span class="line"><span class="string">         C(DayOfMonth) + C(DayOfWeek) + C(Weekday) + C(IsMonthStart) + C(IsMonthEnd)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">model6 = sm.OLS.from_formula(formula, data=df_elec)</span><br><span class="line">result6 = model6.fit()</span><br><span class="line">print(result6.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Demand   R-squared:                       0.537
Model:                            OLS   Adj. R-squared:                  0.511
Method:                 Least Squares   F-statistic:                     19.98
Date:                Thu, 14 May 2020   Prob (F-statistic):           4.74e-46
Time:                        19:37:49   Log-Likelihood:                -1574.8
No. Observations:                 365   AIC:                             3192.
Df Residuals:                     344   BIC:                             3273.
Df Model:                          20                                         
Covariance Type:            nonrobust                                         
===========================================================================================
                              coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------------------
Intercept                  58.6105      2.423     24.188      0.000      53.844      63.377
C(Month)[T.2]              14.5730      4.587      3.177      0.002       5.551      23.595
C(Month)[T.3]              -1.2369      8.663     -0.143      0.887     -18.276      15.802
C(Month)[T.4]             -29.1875     10.239     -2.851      0.005     -49.326      -9.049
C(Month)[T.5]              23.4037     15.493      1.511      0.132      -7.069      53.876
C(Month)[T.6]              11.3667      3.758      3.024      0.003       3.974      18.759
C(Month)[T.7]              64.8095     22.750      2.849      0.005      20.063     109.556
C(Month)[T.8]              66.5692     26.490      2.513      0.012      14.467     118.671
C(Month)[T.9]              22.7687      9.491      2.399      0.017       4.100      41.437
C(Month)[T.10]             59.0491     33.895      1.742      0.082      -7.619     125.717
C(Month)[T.11]             33.4276     16.778      1.992      0.047       0.427      66.429
C(Month)[T.12]             72.2523     41.334      1.748      0.081      -9.047     153.552
C(DayOfMonth)[T.30]        38.3755     13.530      2.836      0.005      11.763      64.988
C(DayOfMonth)[T.31]         5.6620      7.806      0.725      0.469      -9.691      21.015
C(DayOfWeek)[T.1]           3.4766      1.829      1.900      0.058      -0.121       7.075
C(DayOfWeek)[T.2]           1.5756      1.821      0.865      0.387      -2.006       5.157
C(DayOfWeek)[T.3]           2.8568      1.831      1.560      0.120      -0.745       6.459
C(DayOfWeek)[T.4]           0.8832      1.831      0.482      0.630      -2.719       4.485
C(DayOfWeek)[T.5]         -12.8982      1.831     -7.045      0.000     -16.499      -9.297
C(DayOfWeek)[T.6]         -16.4623      1.829     -8.999      0.000     -20.060     -12.864
C(Weekday)[T.1]             3.4766      1.829      1.900      0.058      -0.121       7.075
C(Weekday)[T.2]             1.5756      1.821      0.865      0.387      -2.006       5.157
C(Weekday)[T.3]             2.8568      1.831      1.560      0.120      -0.745       6.459
C(Weekday)[T.4]             0.8832      1.831      0.482      0.630      -2.719       4.485
C(Weekday)[T.5]           -12.8982      1.831     -7.045      0.000     -16.499      -9.297
C(Weekday)[T.6]           -16.4623      1.829     -8.999      0.000     -20.060     -12.864
C(IsMonthStart)[T.True]     1.2012      5.781      0.208      0.836     -10.169      12.571
C(IsMonthEnd)[T.True]       4.7608      5.781      0.824      0.411      -6.609      16.131
scale(Ordinal)           -101.7884      4.209    -24.182      0.000    -110.068     -93.509
DayOfYear                   0.6769      0.085      7.926      0.000       0.509       0.845
==============================================================================
Omnibus:                      150.460   Durbin-Watson:                   0.577
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1586.415
Skew:                           1.422   Prob(JB):                         0.00
Kurtosis:                      12.809   Cond. No.                     1.05e+18
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The smallest eigenvalue is 1.49e-29. This might indicate that there are
strong multicollinearity problems or that the design matrix is singular.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-13T09:33:34.000Z" title="2020-05-13T09:33:34.000Z">2020-05-13</time><span class="level-item">19 minutes read (About 2792 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/05/13/Linear-Regression-with-scale-categorical-regression-and-partial-regression/">Linear Regression with scale, categorical regression, and partial regression</a></h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> font_manager, rc</span><br><span class="line"><span class="keyword">import</span> platform</span><br><span class="line"></span><br><span class="line"><span class="keyword">try</span> :</span><br><span class="line">    <span class="keyword">if</span> platform.system() == <span class="string">'windows'</span>:</span><br><span class="line">        <span class="comment"># windowsì˜ ê²½ìš°</span></span><br><span class="line">        font_name = font_manager.FomntProperties(fname=<span class="string">"c:/Windows/Font"</span>)</span><br><span class="line">        rc(<span class="string">'font'</span>, family = font_name)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># macì˜ ê²½ìš°</span></span><br><span class="line">        rc(<span class="string">'font'</span>, family = <span class="string">'AppleGothic'</span>)</span><br><span class="line"><span class="keyword">except</span> :</span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">'axes.unicode_minus'</span>] = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h5 id="ìŠ¤ì¼€ì¼ë§"><a href="#ìŠ¤ì¼€ì¼ë§" class="headerlink" title="ìŠ¤ì¼€ì¼ë§"></a>ìŠ¤ì¼€ì¼ë§</h5><img width="542" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-05-13 á„‹á…©á„’á…® 6 20 21" src="https://user-images.githubusercontent.com/59719711/81794987-8af85000-9546-11ea-80c2-df81105e3ee1.png">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<pre><code>ì´ summary reportëŠ” ì–´ì œ ë³´ìŠ¤í„´ ì§‘ê°’ ë°ì´í„°ë¥¼ í™œìš©í•˜ì—¬ ì„ í˜•íšŒê·€ë¶„ì„ì„ í•œ ê²°ê³¼ê°’ì´ì•¼. ì•„ë«ë¶€ë¶„ì˜ Cond. No. ë¼ê³  ì“°ì—¬ì ¸ ìˆëŠ” ë¶€ë¶„ì¸ë° ì¡°ê±´ìˆ˜(conditional number)ëŠ” ê°€ì¥ í° ê³ ìœ ì¹˜ì™€ ê°€ì¥ ì‘ì€ ê³ ìœ ì¹˜ì˜ ë¹„ìœ¨ì„ ëœ»í•´.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows Ã— 14 columns</p>
</div>



<pre><code>ì´ê²ƒì€ ì¼ë¶€ëŸ¬ TAXë³€ìˆ˜ë¥¼ í¬ê²Œ ë§Œë“¤ì–´ ì¡°ê±´ìˆ˜ë¥¼ ì¦í­ì‹œì¼œë³¸ ë°ì´í„°ì•¼</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">dfX2 = dfX.copy()</span><br><span class="line">dfX2[<span class="string">"TAX"</span>] *= <span class="number">1e13</span></span><br><span class="line">df2 = pd.concat([dfX2, dfy], axis=<span class="number">1</span>)</span><br><span class="line">model2 = sm.OLS.from_formula(<span class="string">"MEDV ~ "</span> + <span class="string">"+"</span>.join(boston.feature_names), data=df2)</span><br><span class="line">result2 = model2.fit()</span><br><span class="line">print(result2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.333
Model:                            OLS   Adj. R-squared:                  0.329
Method:                 Least Squares   F-statistic:                     83.39
Date:                Wed, 13 May 2020   Prob (F-statistic):           8.62e-44
Time:                        16:03:11   Log-Likelihood:                -1737.9
No. Observations:                 506   AIC:                             3484.
Df Residuals:                     502   BIC:                             3501.
Df Model:                           3                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept     -0.0038      0.000     -8.543      0.000      -0.005      -0.003
CRIM          -0.1567      0.046     -3.376      0.001      -0.248      -0.066
ZN             0.1273      0.016      7.752      0.000       0.095       0.160
INDUS         -0.1971      0.019    -10.433      0.000      -0.234      -0.160
CHAS           0.0034      0.000     12.430      0.000       0.003       0.004
NOX           -0.0023      0.000     -9.285      0.000      -0.003      -0.002
RM             0.0267      0.002     14.132      0.000       0.023       0.030
AGE            0.1410      0.017      8.443      0.000       0.108       0.174
DIS           -0.0286      0.004     -7.531      0.000      -0.036      -0.021
RAD            0.1094      0.018      6.163      0.000       0.075       0.144
TAX         1.077e-15   2.66e-16      4.051      0.000    5.55e-16     1.6e-15
PTRATIO       -0.1124      0.011    -10.390      0.000      -0.134      -0.091
B              0.0516      0.003     19.916      0.000       0.046       0.057
LSTAT         -0.6569      0.056    -11.790      0.000      -0.766      -0.547
==============================================================================
Omnibus:                       39.447   Durbin-Watson:                   0.863
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               46.611
Skew:                           0.704   Prob(JB):                     7.56e-11
Kurtosis:                       3.479   Cond. No.                     1.19e+17
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.19e+17. This might indicate that there are
strong multicollinearity or other numerical problems.


ì¡°ê±´ìˆ˜(Conditional No.)ê°€ 1000ì¡° ìˆ˜ì¤€ìœ¼ë¡œ ì¦ê°€í•œ ê²ƒì„ ë³¼ ìˆ˜ ìˆì§€? ì˜¤ë¥¸ìª½ ì œì¼ ìƒë‹¨ì— ë³´ì´ëŠ” R-squaredë¼ëŠ” ê°’ìœ¼ë¡œ í‘œì‹œë˜ëŠ” ì„±ëŠ¥ì§€í‘œë„ í¬ê²Œ ê°ì†Œí•œê²ƒì„ ë³¼ ìˆ˜ ìˆì–´. R-squared ëŠ” ì´ ëª¨ë¸ ì„±ëŠ¥ì— ëŒ€í•´ ëª‡ì ì¸ì§€ë¥¼ ì•Œë ¤ì£¼ëŠ” ê¸°ëŠ¥ì´ë¼ê³  ë³´ë©´ ë˜(0.333ìœ¼ë¡œ ë‚˜ì™”ìœ¼ë‹ˆ 100ì  ë§Œì ì— 33.3ì ì´ë¼ëŠ” ì†Œë¦¬ì•¼)

statsmodelsì—ì„œëŠ”  scale() ì´ë¼ëŠ” ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¤ì¼€ì¼ë§ì„ í•  ìˆ˜ ìˆëŠ”ë°, ì´ ë°©ì‹ìœ¼ë¡œ ìŠ¤ì¼€ì¼ì„ í•˜ë©´ ìŠ¤ì¼€ì¼ë§ì— ì‚¬ìš©ëœ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì €ì¥í•˜ì˜€ë‹¤ê°€ ë‚˜ì¤‘ì— predict() ë¼ëŠ” ëª…ë ¹ì„ ì‚¬ìš©í•  ë•Œë„ ê°™ì€ ìŠ¤ì¼€ì¼ì„ ì‚¬ìš©í•˜ê¸° ë•Œë¬¸ì— í¸ë¦¬í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆì–´. ë‹¤ë§Œ! ìŠ¤ì¼€ì¼ë§ì„ í•  ë•Œì—ëŠ” ì¹´í…Œê³ ë¦¬ ë³€ìˆ˜, ì¦‰ ë²”ì£¼í˜• ë°ì´í„°ëŠ” ìŠ¤ì¼€ì¼ë§ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤ëŠ” ê²ƒì— ì£¼ì˜ í•´ì£¼ë©´ ë˜.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">feature_names = list(boston.feature_names)</span><br><span class="line">feature_names.remove(<span class="string">"CHAS"</span>) </span><br><span class="line">feature_names = [<span class="string">'scale(&#123;&#125;)'</span>.format(name) <span class="keyword">for</span> name <span class="keyword">in</span> feature_names] + [<span class="string">'CHAS'</span>]</span><br><span class="line">model3 = sm.OLS.from_formula(<span class="string">"MEDV ~ "</span> + <span class="string">"+"</span>.join(feature_names), data=df2)</span><br><span class="line">result3 = model3.fit()</span><br><span class="line">print(result3.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.741
Model:                            OLS   Adj. R-squared:                  0.734
Method:                 Least Squares   F-statistic:                     108.1
Date:                Wed, 13 May 2020   Prob (F-statistic):          6.72e-135
Time:                        16:11:05   Log-Likelihood:                -1498.8
No. Observations:                 506   AIC:                             3026.
Df Residuals:                     492   BIC:                             3085.
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         22.3470      0.219    101.943      0.000      21.916      22.778
scale(CRIM)       -0.9281      0.282     -3.287      0.001      -1.483      -0.373
scale(ZN)          1.0816      0.320      3.382      0.001       0.453       1.710
scale(INDUS)       0.1409      0.421      0.334      0.738      -0.687       0.969
scale(NOX)        -2.0567      0.442     -4.651      0.000      -2.926      -1.188
scale(RM)          2.6742      0.293      9.116      0.000       2.098       3.251
scale(AGE)         0.0195      0.371      0.052      0.958      -0.710       0.749
scale(DIS)        -3.1040      0.420     -7.398      0.000      -3.928      -2.280
scale(RAD)         2.6622      0.577      4.613      0.000       1.528       3.796
scale(TAX)        -2.0768      0.633     -3.280      0.001      -3.321      -0.833
scale(PTRATIO)    -2.0606      0.283     -7.283      0.000      -2.617      -1.505
scale(B)           0.8493      0.245      3.467      0.001       0.368       1.331
scale(LSTAT)      -3.7436      0.362    -10.347      0.000      -4.454      -3.033
CHAS               2.6867      0.862      3.118      0.002       0.994       4.380
==============================================================================
Omnibus:                      178.041   Durbin-Watson:                   1.078
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126
Skew:                           1.521   Prob(JB):                    8.84e-171
Kurtosis:                       8.281   Cond. No.                         10.6
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


ë…ë¦½ë³€ìˆ˜ ë°ì´í„°ë¥¼ ìŠ¤ì¼€ì¼ë§í•œê²ƒë§Œìœ¼ë¡œ ì¡°ê±´ìˆ˜ì˜ ìˆ˜ì¹˜ê°€ í™• ë‚´ë ¤ê°„ ê²ƒì„ ë³¼ ìˆ˜ ìˆì–´. ì–´ë•Œ? ì‰½ì§€?

ì¡°ê±´ìˆ˜ë¥¼ ë  ìˆ˜ ìˆìœ¼ë©´ ë‚®ì¶°ì£¼ëŠ”ê²Œ ê° ë…ë¦½ë³€ìˆ˜ì˜ ì˜¤ì°¨ë²”ìœ„ë¥¼ ì¤„ì—¬ì¤„ ìˆ˜ ìˆë‹¤ê³  í•´. ê·¸ë˜ì„œ í° ê°’ì˜ ë°ì´í„°ë“¤ì€ ìŠ¤ì¼€ì¼ë§ì„ í†µí•´ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì—¬ì£¼ëŠ” ê±°ì§€.</code></pre><h5 id="ë²”ì£¼í˜•-ë…ë¦½ë³€ìˆ˜ì˜-íšŒê·€ë¶„ì„"><a href="#ë²”ì£¼í˜•-ë…ë¦½ë³€ìˆ˜ì˜-íšŒê·€ë¶„ì„" class="headerlink" title="ë²”ì£¼í˜• ë…ë¦½ë³€ìˆ˜ì˜ íšŒê·€ë¶„ì„"></a>ë²”ì£¼í˜• ë…ë¦½ë³€ìˆ˜ì˜ íšŒê·€ë¶„ì„</h5><pre><code>ì´ë²ˆì—ëŠ” ì—°ì†í˜• ë°ì´í„°ê°€ ì•„ë‹Œ ë²”ì£¼í˜• ë°ì´í„°ì˜ íšŒê·€ë¶„ì„ì„ í•˜ëŠ” ë°©ë²•ì— ëŒ€í•´ ì•Œì•„ë³´ì! ë²”ì£¼í˜• ë°ì´í„°ëŠ” ì¸¡ì • ê²°ê³¼ê°€ ëª‡ ê°œì˜ ë²”ì£¼ ë˜ëŠ” í–¥ëª©ì˜ í˜•íƒœë¡œ ë‚˜íƒ€ë‚˜ëŠ” ìë£Œë¥¼ ë§í•˜ëŠ”ë° ê·¸ê²ƒì„ ìˆ«ìë¡œ í‘œí˜„í•œ ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆì–´. ì˜ˆë¥¼ ë“¤ë©´ ë‚¨ìëŠ” 1 ì—¬ìëŠ” 0 ì´ëŸ°ì‹ì´ì§€!

ì•„ë¬´íŠ¼..

ì—¬ê¸°ì„œ ë‹¤ë£° í•™ìŠµì€ ê·¸ëŸ¬í•œ ë²”ì£¼í˜• ë…ë¦½ë³€ìˆ˜(ë°ì´í„°)ì˜ íšŒê·€ë¶„ì„ ëª¨ë¸ë§ ì‹œ ì—ëŠ” ì•ì„œ ë°°ìš´ ë”ë¯¸ë³€ìˆ˜í™”ê°€ í•„ìˆ˜ë¼ëŠ” ê±°ì•¼. í’€ë­í¬(full-rank) ë°©ì‹ê³¼ ì¶•ì†Œë­í¬(reduced-rank) ë°©ì‹ì´ ìˆëŠ”ë° í’€ë­í¬ë°©ì‹ì—ì„œëŠ” ë”ë¯¸ë³€ìˆ˜ì˜ ê°’ì„ ì›í•«ì¸ì½”ë”©(one-hot-encoding) ë°©ì‹ìœ¼ë¡œ ì§€ì •ì„ í•˜ëŠ”ê±°ì•¼

ì˜ˆë¥¼ ë“¤ì–´ì„œ..

ë‚¨ìëŠ” 1 ì´ê³  ì—¬ìëŠ” 0 ì´ë©´ 
ë‚¨ì : d1=1, d2=0
ì—¬ì : d1=0, d2=1 ì´ëŸ°ì‹ìœ¼ë¡œ ì“´ë‹¤ëŠ” ê±°ì§€

ì¶•ì†Œë­í¬ ë°©ì‹ì—ì„œëŠ” íŠ¹ì •í•œ í•˜ë‚˜ì˜ ë²”ì£¼ê°’ì„ ê¸°ì¤€ê°’(reference, baseline)ìœ¼ë¡œ í•˜ê³  ê¸°ì¤€ê°’ì— ëŒ€ì‘í•˜ëŠ” ë”ë¯¸ë³€ìˆ˜ì˜ ê°€ì¤‘ì¹˜ëŠ” í•­ìƒ 1ìœ¼ë¡œ ë†“ì•„ ê³„ì‚° í•˜ëŠ” ë°©ë²•ì´ì§€

ë¬´ìŠ¨ ë§ì¸ì§€ ì–´ë µì§€? ê·¸ëŸ¼ ì‹¤ ë°ì´í„°ë¡œ ì˜ˆë¥¼ ë“¤ì–´ë³´ë„ë¡ í• ê²Œ.

ì•„ë˜ì˜ ë°ì´í„°ëŠ” 1920ë…„ë¶€í„° 1939ë…„ê¹Œì§€ ì˜êµ­ ë…¸íŒ…í—˜ ì§€ì—­ì˜ ê¸°ì˜¨ì„ ë‚˜íƒ€ë‚¸ ë°ì´í„°ì•¼. ì´ ë°ì´í„°ì—ì„œ ë…ë¦½ ë³€ìˆ˜ëŠ” ì›”(monath)ì´ë©° ë²”ì£¼ê°’ìœ¼ë¡œ ì²˜ë¦¬ë¥¼ í• ê±°ì•¼ ê·¸ë¦¬ê³  valueë¡œ í‘œê¸°ëœ ê°’ì´ ì¢…ì†ë³€ìˆ˜ì¸ í•´ë‹¹ ì›”ì˜ í‰ê·  ê¸°ì˜¨ì´ë¼ê³  í•  ìˆ˜ ìˆì§€. ë¶„ì„ì˜ ëª©ì ì€ ë…ë¦½ë³€ìˆ˜ì¸ ì›” ê°’ì„ ì´ìš©í•˜ì—¬ ì¢…ì†ë³€ìˆ˜ì¸ ì›” í‰ê·  ê¸°ì˜¨ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì´ì•¼.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">from</span> calendar <span class="keyword">import</span> isleap</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_partial_year</span><span class="params">(number)</span>:</span></span><br><span class="line">   <span class="comment">#ì—° ë‹¨ìœ„ ìˆ«ìì—ì„œ ë‚ ì§œë¥¼ ê³„ì‚°í•˜ëŠ” ì½”ë“œ</span></span><br><span class="line">    year = int(number)</span><br><span class="line">    d = datetime.timedelta(days=(number - year) * (<span class="number">365</span> + isleap(year)))</span><br><span class="line">    day_one = datetime.datetime(year, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    date = d + day_one</span><br><span class="line">    <span class="keyword">return</span> date</span><br><span class="line"></span><br><span class="line">df_nottem = sm.datasets.get_rdataset(<span class="string">"nottem"</span>).data</span><br><span class="line"></span><br><span class="line">df_nottem[<span class="string">"date0"</span>] = df_nottem[[<span class="string">"time"</span>]].applymap(convert_partial_year)</span><br><span class="line">df_nottem[<span class="string">"date"</span>] = pd.DatetimeIndex(df_nottem[<span class="string">"date0"</span>]).round(<span class="string">'60min'</span>) + datetime.timedelta(seconds=<span class="number">3600</span>*<span class="number">24</span>)</span><br><span class="line">df_nottem[<span class="string">"month"</span>] = df_nottem[<span class="string">"date"</span>].dt.strftime(<span class="string">"%m"</span>).astype(<span class="string">'category'</span>)</span><br><span class="line"><span class="keyword">del</span> df_nottem[<span class="string">"date0"</span>], df_nottem[<span class="string">"date"</span>]</span><br><span class="line">df_nottem</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>time</th>
      <th>value</th>
      <th>month</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1920.000000</td>
      <td>40.6</td>
      <td>01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1920.083333</td>
      <td>40.8</td>
      <td>02</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1920.166667</td>
      <td>44.4</td>
      <td>03</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1920.250000</td>
      <td>46.7</td>
      <td>04</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1920.333333</td>
      <td>54.1</td>
      <td>05</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>235</th>
      <td>1939.583333</td>
      <td>61.8</td>
      <td>08</td>
    </tr>
    <tr>
      <th>236</th>
      <td>1939.666667</td>
      <td>58.2</td>
      <td>09</td>
    </tr>
    <tr>
      <th>237</th>
      <td>1939.750000</td>
      <td>46.7</td>
      <td>10</td>
    </tr>
    <tr>
      <th>238</th>
      <td>1939.833333</td>
      <td>46.6</td>
      <td>11</td>
    </tr>
    <tr>
      <th>239</th>
      <td>1939.916667</td>
      <td>37.8</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
<p>240 rows Ã— 3 columns</p>
</div>



<pre><code>ë°•ìŠ¤í”Œë¡¯ì„ í†µí•´ í•´ë‹¹ ì›”ì— ì¢…ì†ë³€ìˆ˜ë°ì´í„°ê°€ ì–´ë””ì— ì£¼ë¡œ ëª¨ì—¬ìˆëŠ”ì§€ í™•ì¸ì„ í•´ë³´ëŠ”ê±°ì•¼</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_nottem.boxplot(<span class="string">"value"</span>, <span class="string">"month"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="382" alt="output_14_0" src="https://user-images.githubusercontent.com/59719711/81795405-0a861f00-9547-11ea-8d19-a3c30dfdf966.png">


<pre><code>%% ë²”ì£¼í˜• ë…ë¦½ë³€ìˆ˜ì˜ ê²½ìš° ì•ì„œ ì‹œí–‰í•œ íšŒê·€ë¶„ì„ì—ì„œ ì¶”ê°€í•´ì¤€ ìƒìˆ˜í•­(add_constant)ì„ ì¶”ê°€í•˜ì§€ ì•Šì•„.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># í’€ë­í¬ ë°©ì‹</span></span><br><span class="line">model = sm.OLS.from_formula(<span class="string">"value ~ C(month) + 0"</span>, df_nottem)</span><br><span class="line">result = model.fit()</span><br><span class="line">print(result.summary())</span><br><span class="line"></span><br><span class="line"><span class="comment"># C()ë¡œ ì¹´í…Œê³ ë¦¬ë¡œ ì²˜ë¦¬</span></span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  value   R-squared:                       0.930
Model:                            OLS   Adj. R-squared:                  0.927
Method:                 Least Squares   F-statistic:                     277.3
Date:                Wed, 13 May 2020   Prob (F-statistic):          2.96e-125
Time:                        16:28:22   Log-Likelihood:                -535.82
No. Observations:                 240   AIC:                             1096.
Df Residuals:                     228   BIC:                             1137.
Df Model:                          11                                         
Covariance Type:            nonrobust                                         
================================================================================
                   coef    std err          t      P&gt;|t|      [0.025      0.975]
--------------------------------------------------------------------------------
C(month)[01]    39.6950      0.518     76.691      0.000      38.675      40.715
C(month)[02]    39.1900      0.518     75.716      0.000      38.170      40.210
C(month)[03]    42.1950      0.518     81.521      0.000      41.175      43.215
C(month)[04]    46.2900      0.518     89.433      0.000      45.270      47.310
C(month)[05]    52.5600      0.518    101.547      0.000      51.540      53.580
C(month)[06]    58.0400      0.518    112.134      0.000      57.020      59.060
C(month)[07]    61.9000      0.518    119.592      0.000      60.880      62.920
C(month)[08]    60.5200      0.518    116.926      0.000      59.500      61.540
C(month)[09]    56.4800      0.518    109.120      0.000      55.460      57.500
C(month)[10]    49.4950      0.518     95.625      0.000      48.475      50.515
C(month)[11]    42.5800      0.518     82.265      0.000      41.560      43.600
C(month)[12]    39.5300      0.518     76.373      0.000      38.510      40.550
==============================================================================
Omnibus:                        5.430   Durbin-Watson:                   1.529
Prob(Omnibus):                  0.066   Jarque-Bera (JB):                5.299
Skew:                          -0.281   Prob(JB):                       0.0707
Kurtosis:                       3.463   Cond. No.                         1.00
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS.from_formula(<span class="string">"value ~ C(month)"</span>, df_nottem)</span><br><span class="line">result = model.fit()</span><br><span class="line">print(result.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  value   R-squared:                       0.930
Model:                            OLS   Adj. R-squared:                  0.927
Method:                 Least Squares   F-statistic:                     277.3
Date:                Wed, 13 May 2020   Prob (F-statistic):          2.96e-125
Time:                        16:32:20   Log-Likelihood:                -535.82
No. Observations:                 240   AIC:                             1096.
Df Residuals:                     228   BIC:                             1137.
Df Model:                          11                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept         39.6950      0.518     76.691      0.000      38.675      40.715
C(month)[T.02]    -0.5050      0.732     -0.690      0.491      -1.947       0.937
C(month)[T.03]     2.5000      0.732      3.415      0.001       1.058       3.942
C(month)[T.04]     6.5950      0.732      9.010      0.000       5.153       8.037
C(month)[T.05]    12.8650      0.732     17.575      0.000      11.423      14.307
C(month)[T.06]    18.3450      0.732     25.062      0.000      16.903      19.787
C(month)[T.07]    22.2050      0.732     30.335      0.000      20.763      23.647
C(month)[T.08]    20.8250      0.732     28.450      0.000      19.383      22.267
C(month)[T.09]    16.7850      0.732     22.931      0.000      15.343      18.227
C(month)[T.10]     9.8000      0.732     13.388      0.000       8.358      11.242
C(month)[T.11]     2.8850      0.732      3.941      0.000       1.443       4.327
C(month)[T.12]    -0.1650      0.732     -0.225      0.822      -1.607       1.277
==============================================================================
Omnibus:                        5.430   Durbin-Watson:                   1.529
Prob(Omnibus):                  0.066   Jarque-Bera (JB):                5.299
Skew:                          -0.281   Prob(JB):                       0.0707
Kurtosis:                       3.463   Cond. No.                         12.9
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


ì¶•ì†Œë­í¬ ë°©ì‹ ( +0 ì œê±°) - &apos;ê¸°ì¤€ì´ ë˜ëŠ” ë°ì´í„° ê°’ì—ì„œ  ë‹¤ë¥¸ ë²”ì£¼í˜• ë°ì´í„° ê°’ì´ ì–¼ë§ˆë‚˜ ë‹¤ë¥´ëƒ&apos; ì˜ ì˜ë¯¸ë¡œ ë³´ë©´ ë¨, ì¦‰ 1ì›”ì„ ê¸°ì¤€ìœ¼ë¡œ 2ì›”ì—ëŠ” ì°¨ì´ê°€ ì–¼ë§ˆë‚˜ ìˆëŠëƒ ë¥¼ ë‚˜íƒ€ë‚´ëŠ”ê±°ì•¼. í’€ë­í¬ ë°©ì‹ê³¼ ì¶•ì†Œë­í¬ ë°©ì‹ì˜ ì°¨ì´ë¥¼ ì¡°ê¸ˆì€ ì•Œ ìˆ˜ ìˆê²Œëœê±°ê°™ì•„.

ì´ ì´ìƒì€ ë‚´ê°€ ì´í•´ë¥¼ ëª»í–ˆê¸° ë•Œë¬¸ì— ë„˜ì–´ê°€ë„ë¡ í• ê²Œ.</code></pre><h5 id="ë¶€ë¶„íšŒê·€"><a href="#ë¶€ë¶„íšŒê·€" class="headerlink" title="ë¶€ë¶„íšŒê·€"></a>ë¶€ë¶„íšŒê·€</h5><pre><code>ë§Œì•½ íšŒê·€ë¶„ì„ì„ í•œ í›„ì— ìƒˆë¡œìš´ ë…ë¦½ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ ë‹¤ì‹œ íšŒê·€ë¶„ì„ì„ í•œë‹¤ë©´ ê·¸ ì „ì— íšŒê·€ë¶„ì„ìœ¼ë¡œ êµ¬í–ˆë˜ ê°€ì¤‘ì¹˜ì˜ ê°’ì€ ë³€í• ê¹Œ ë³€í•˜ì§€ ì•Šì„ê¹Œ? ì˜ˆë¥¼ ë“¤ì–´  ğ‘¥1 ì´ë¼ëŠ” ë…ë¦½ë³€ìˆ˜ë§Œìœ¼ë¡œ íšŒê·€ë¶„ì„í•œ ê²°ê³¼ê°€ ë‹¤ìŒê³¼ ê°™ë‹¤ê³  í•˜ì.</code></pre><img width="202" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-05-13 á„‹á…©á„’á…® 4 49 48" src="https://user-images.githubusercontent.com/59719711/81795180-cdba2800-9546-11ea-9243-aeeca5cda269.png">

<pre><code>ì´ ë•Œ ìƒˆë¡œìš´ ë…ë¦½ë³€ìˆ˜  ğ‘¥2 ë¥¼ ì¶”ê°€í•˜ì—¬ íšŒê·€ë¶„ì„ì„ í•˜ê²Œ ë˜ë©´ ì´ ë•Œ ë‚˜ì˜¤ëŠ”  ğ‘¥1 ì— ëŒ€í•œ ê°€ì¤‘ì¹˜  ğ‘¤â€²1 ê°€ ì›ë˜ì˜  ğ‘¤1 ê³¼ ê°™ì„ê¹Œ ë‹¤ë¥¼ê¹Œ?</code></pre><img width="307" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-05-13 á„‹á…©á„’á…® 4 49 52" src="https://user-images.githubusercontent.com/59719711/81795240-de6a9e00-9546-11ea-9ef1-5bd349d3ec8a.png">

<pre><code>ë‹µë¶€í„° ë§í•˜ìë©´

ì¼ë°˜ì ìœ¼ë¡œ  ğ‘¤â€²1 ì˜ ê°’ì€ ì›ë˜ì˜  ğ‘¤1 ì˜ ê°’ê³¼ ë‹¤ë¥´ë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfX0 = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfX = sm.add_constant(dfX0)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfX, dfy], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model_boston = sm.OLS(dfy, dfX)</span><br><span class="line">result_boston = model_boston.fit()</span><br><span class="line">print(result_boston.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.741
Model:                            OLS   Adj. R-squared:                  0.734
Method:                 Least Squares   F-statistic:                     108.1
Date:                Wed, 13 May 2020   Prob (F-statistic):          6.72e-135
Time:                        18:01:08   Log-Likelihood:                -1498.8
No. Observations:                 506   AIC:                             3026.
Df Residuals:                     492   BIC:                             3085.
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         36.4595      5.103      7.144      0.000      26.432      46.487
CRIM          -0.1080      0.033     -3.287      0.001      -0.173      -0.043
ZN             0.0464      0.014      3.382      0.001       0.019       0.073
INDUS          0.0206      0.061      0.334      0.738      -0.100       0.141
CHAS           2.6867      0.862      3.118      0.002       0.994       4.380
NOX          -17.7666      3.820     -4.651      0.000     -25.272     -10.262
RM             3.8099      0.418      9.116      0.000       2.989       4.631
AGE            0.0007      0.013      0.052      0.958      -0.025       0.027
DIS           -1.4756      0.199     -7.398      0.000      -1.867      -1.084
RAD            0.3060      0.066      4.613      0.000       0.176       0.436
TAX           -0.0123      0.004     -3.280      0.001      -0.020      -0.005
PTRATIO       -0.9527      0.131     -7.283      0.000      -1.210      -0.696
B              0.0093      0.003      3.467      0.001       0.004       0.015
LSTAT         -0.5248      0.051    -10.347      0.000      -0.624      -0.425
==============================================================================
Omnibus:                      178.041   Durbin-Watson:                   1.078
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              783.126
Skew:                           1.521   Prob(JB):                    8.84e-171
Kurtosis:                       8.281   Cond. No.                     1.51e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.51e+04. This might indicate that there are
strong multicollinearity or other numerical problems.


ì´ë ‡ê²Œ ë³´ë©´ AGEëŠ” ì§‘ê°’ì„ ê²°ì •í•˜ëŠ”ë° ìŒì˜ ìƒê´€ê´€ê³„ë¥¼ ê°€ì§„ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤ê³  í•  ìˆ˜ ìˆì–´</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.regplot(x=<span class="string">"AGE"</span>, y=<span class="string">"MEDV"</span>, data=df)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="389" alt="output_25_0" src="https://user-images.githubusercontent.com/59719711/81795459-1c67c200-9547-11ea-9580-72d65bfab466.png">


<pre><code>plot_partregress(endog, exog_i, exog_others, data=None, obs_labels=True, ret_coords=False)

endog: ì¢…ì†ë³€ìˆ˜ ë¬¸ìì—´
exog_i: ë¶„ì„ ëŒ€ìƒì´ ë˜ëŠ” ë…ë¦½ë³€ìˆ˜ ë¬¸ìì—´
exog_others: ë‚˜ë¨¸ì§€ ë…ë¦½ë³€ìˆ˜ ë¬¸ìì—´ì˜ ë¦¬ìŠ¤íŠ¸
data: ëª¨ë“  ë°ì´í„°ê°€ ìˆëŠ” ë°ì´í„°í”„ë ˆì„
obs_labels: ë°ì´í„° ë¼ë²¨ë§ ì—¬ë¶€
ret_coords: ì”ì°¨ ë°ì´í„° ë°˜í™˜ ì—¬ë¶€

í•˜ì§€ë§Œ! ë‹¤ë¥¸ ë…ë¦½ë³€ìˆ˜ì— ì˜í–¥ì„ ë°›ì€ AGEê°€ ì§‘ê°’ì— ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ì§€ì— ëŒ€í•œ ë¶€ë¶„ì„ í™•ì¸í•´ë³´ë©´ ê·¸ë˜í”„ëŠ” ë‹¤ìŒê³¼ ê°™ì•„.
AGE ë°ì´í„°ì— ëŒ€í•œ ë¶€ë¶„íšŒê·€ì¸ì…ˆì´ì§€.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">others = list(set(df.columns).difference(set([<span class="string">"MEDV"</span>, <span class="string">"AGE"</span>])))</span><br><span class="line">p, resids = sm.graphics.plot_partregress(</span><br><span class="line">    <span class="string">"MEDV"</span>, <span class="string">"AGE"</span>, others, data=df, obs_labels=<span class="literal">False</span>, ret_coords=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># í¬ê²Œ ìƒê´€ì´ ì—†ë‹¤ëŠ” ê±°ë¡œ ë‚˜ì˜¤ê²Œ ë˜</span></span><br></pre></td></tr></table></figure>

<img width="395" alt="output_29_0" src="https://user-images.githubusercontent.com/59719711/81795521-2be70b00-9547-11ea-9d31-c7d0f66eedab.png">


<pre><code>sm.graphics.plot_partregress_grid ëª…ë ¹ì„ ì“°ë©´ ì „ì²´ ë°ì´í„°ì— ëŒ€í•´ í•œë²ˆì— ë¶€ë¶„íšŒê·€ í”Œë¡¯ì„ ê·¸ë¦´ ìˆ˜ ìˆì–´.

plot_partregress_grid(result, fig)

result: íšŒê·€ë¶„ì„ ê²°ê³¼ ê°ì²´
fig: plt.figure ê°ì²´</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">20</span>))</span><br><span class="line">sm.graphics.plot_partregress_grid(result_boston, fig=fig)</span><br><span class="line">fig.suptitle(<span class="string">""</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img width="563" alt="output_32_0" src="https://user-images.githubusercontent.com/59719711/81795567-399c9080-9547-11ea-8128-fc56699f56a0.png">


<pre><code>CCPR í”Œë¡¯
CCPR(Component-Component plus Residual) í”Œë¡¯ë„ ë¶€ë¶„íšŒê·€ í”Œë¡¯ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ íŠ¹ì •í•œ í•˜ë‚˜ì˜ ë³€ìˆ˜ì˜ ì˜í–¥ì„ ì‚´í´ë³´ê¸° ìœ„í•œ ê²ƒì´ì•¼

ë¶€ë¶„íšŒê·€ë¶„ì„ê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ ë‹¤ë¥¸ì ì´ í•˜ë‚˜ ìˆëŠ”ë° ê·¸ê²ƒì€ ìœ„ì—ì„œ ì–¸ê¸‰í•œ ë‹¤ë¥¸ ë³€ìˆ˜ì— ì˜í–¥ì„ ë°›ì€ AGEê°€ ì•„ë‹ˆë¼ AGE ë°ì´í„° ê·¸ ìì²´ì™€ ì§‘ê°’ì˜ ìƒê´€ê´€ê³„ë¥¼ ë³´ê¸°ìœ„í•œ ë°©ë²•ì´ë¼ê³  ë³´ë©´ ë˜</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sm.graphics.plot_ccpr(result_boston, <span class="string">"AGE"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img width="395" alt="output_34_0" src="https://user-images.githubusercontent.com/59719711/81795631-49b47000-9547-11ea-9b2d-70d08594dd10.png">


<pre><code>CCPR í”Œë¡¯ì—ì„œëŠ” ë¶€ë¶„íšŒê·€ í”Œë¡¯ê³¼ ë‹¬ë¦¬ ë…ë¦½ë³€ìˆ˜ê°€ ì›ë˜ì˜ ê°’ ê·¸ëŒ€ë¡œ ë‚˜íƒ€ë‚œë‹¤ëŠ” ì ì„ ë‹¤ì‹œ í•œë²ˆ ìƒê¸° ì‹œì¼œì¤„ê²Œ</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">fig = plt.figure(figsize=(<span class="number">8</span>, <span class="number">15</span>))</span><br><span class="line">sm.graphics.plot_ccpr_grid(result_boston, fig=fig)</span><br><span class="line">fig.suptitle(<span class="string">""</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<img width="564" alt="output_36_0" src="https://user-images.githubusercontent.com/59719711/81795667-533dd800-9547-11ea-8b7d-5ca07cf8a5ed.png">


<pre><code>plot_regress_exog(result, exog_idx)

result: íšŒê·€ë¶„ì„ ê²°ê³¼ ê°ì²´
exog_idx: ë¶„ì„ ëŒ€ìƒì´ ë˜ëŠ” ë…ë¦½ë³€ìˆ˜ ë¬¸ìì—´</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fig = sm.graphics.plot_regress_exog(result_boston, <span class="string">"AGE"</span>)</span><br><span class="line">plt.tight_layout(pad=<span class="number">4</span>, h_pad=<span class="number">0.5</span>, w_pad=<span class="number">0.5</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="356" alt="output_38_0" src="https://user-images.githubusercontent.com/59719711/81795721-62248a80-9547-11ea-9e1f-12d645504968.png">
</div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://user-images.githubusercontent.com/59719711/85970198-ab9c3c80-ba04-11ea-8990-4bdec6914e3c.jpeg" alt="wglee87"></figure><p class="title is-size-4 is-block line-height-inherit">wglee87</p><p class="is-size-6 is-block">Data has a better idea</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hwasung, KR</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wglee87" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wglee87"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://Instagram.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-12T12:06:35.000Z">2020-08-12</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/12/%E1%84%80%E1%85%AE%E1%84%80%E1%85%B3%E1%86%AF-%E1%84%8C%E1%85%B5%E1%84%8B%E1%85%A9%E1%84%8F%E1%85%A9%E1%84%83%E1%85%B5%E1%86%BC-API-%E1%84%8F%E1%85%B5-%E1%84%87%E1%85%A1%E1%86%AF%E1%84%80%E1%85%B3%E1%86%B8-%E1%84%87%E1%85%A1%E1%86%AE%E1%84%82%E1%85%B3%E1%86%AB-%E1%84%87%E1%85%A1%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8-How-to-be-issued-the-Geocoding-API-key-from-Google/">êµ¬ê¸€ ì§€ì˜¤ì½”ë”© API í‚¤ ë°œê¸‰ ë°›ëŠ” ë°©ë²• (How to be issued the Geocoding API key from Google)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-24T05:54:01.000Z">2020-07-24</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/24/MySQL-Ubuntu%EC%97%90%EC%84%9C-MySQL-%EC%99%84%EC%A0%84-%EC%82%AD%EC%A0%9C%ED%95%98%EA%B8%B0/">[MySQL] Ubuntuì—ì„œ MySQL ì™„ì „ ì‚­ì œí•˜ê¸°</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-23T10:24:00.000Z">2020-07-23</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/23/MySQL-workbench%E1%84%8B%E1%85%A6%E1%84%89%E1%85%A5-ERD%E1%84%90%E1%85%AE%E1%86%AF-%E1%84%89%E1%85%A1%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5-Database-Modeling/">[mysql] workbenchì—ì„œ ERDíˆ´ ì‚¬ìš©í•˜ê¸° (Database Modeling)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-22T13:58:24.000Z">2020-07-22</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/22/MySQL-Storage-Engine-InnoDB-vs-MyISAM/">[MySQL] Storage Engine (InnoDB vs MyISAM)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-19T09:25:05.000Z">2020-07-19</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/19/Python-SQLAlchemy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">[Python] SQLAlchemy ì‚¬ìš©í•˜ê¸°</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/fastcampus/"><span class="tag">fastcampus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/" alt="Geony&#039;s Tech Blog" height="28"></a><p class="size-small"><span>&copy; 2020 WGLee87</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://wglee87.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>