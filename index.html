<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Geony&#039;s Tech Blog</title><meta description="Data Analyst&amp;#39;s blog"><meta property="og:type" content="blog"><meta property="og:title" content="Geony&#039;s Tech Blog"><meta property="og:url" content="http://wglee87.github.io/"><meta property="og:site_name" content="Geony&#039;s Tech Blog"><meta property="og:description" content="Data Analyst&amp;#39;s blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://wglee87.github.io/img/og_image.png"><meta property="article:author" content="wglee87"><meta property="article:tag" content="data_analysis"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://wglee87.github.io"},"headline":"Geony's Tech Blog","image":["http://wglee87.github.io/img/og_image.png"],"author":{"@type":"Person","name":"WGLee87"},"description":"Data Analyst&#39;s blog"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/" alt="Geony&#039;s Tech Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="/null">Download on GitHub</a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-26T10:14:02.000Z" title="2020-08-26T10:14:02.000Z">2020-08-26</time><span class="level-item">17 minutes read (About 2590 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/26/Model-sava-and-load-in-tensorflow/">Model sava and load in tensorflow</a></h1><div class="content"><h6 id="ì„¤ì •"><a href="#ì„¤ì •" class="headerlink" title="ì„¤ì •"></a>ì„¤ì •</h6><pre><code>í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ê³  í…ì„œí”Œë¡œë¥¼ ì„í¬íŠ¸(import)í•©ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -q pyyaml h5py  <span class="comment"># HDF5 í¬ë§·ìœ¼ë¡œ ëª¨ë¸ì„ ì €ì¥í•˜ê¸° ìœ„í•´ì„œ í•„ìš”í•©ë‹ˆë‹¤</span></span><br></pre></td></tr></table></figure>

<pre><code>Note: you may need to restart the kernel to use updated packages.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>2.4.0-dev20200724


ì˜ˆì œ ë°ì´í„°ì…‹ ë°›ê¸°</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">train_labels = train_labels[:<span class="number">1000</span>]</span><br><span class="line">test_labels = test_labels[:<span class="number">1000</span>]</span><br><span class="line"></span><br><span class="line">train_images = train_images[:<span class="number">1000</span>].reshape(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>) / <span class="number">255.0</span></span><br><span class="line">test_images = test_images[:<span class="number">1000</span>].reshape(<span class="number">-1</span>, <span class="number">28</span> * <span class="number">28</span>) / <span class="number">255.0</span></span><br></pre></td></tr></table></figure>

<pre><code>ëª¨ë¸ë§ ì‘ì—…</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Sequential ëª¨ë¸ ì •ì˜</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = tf.keras.models.Sequential([</span><br><span class="line">        keras.layers.Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>, input_shape=(<span class="number">784</span>,)),</span><br><span class="line">        keras.layers.Dropout(<span class="number">0.2</span>),</span><br><span class="line">        keras.layers.Dense(<span class="number">10</span>)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">                  metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ ê°ì²´ ìƒì„±</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì¶œë ¥</span></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_8&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_16 (Dense)             (None, 512)               401920    
_________________________________________________________________
dropout_8 (Dropout)          (None, 512)               0         
_________________________________________________________________
dense_17 (Dense)             (None, 10)                5130      
=================================================================
Total params: 407,050
Trainable params: 407,050
Non-trainable params: 0
_________________________________________________________________


í›ˆë ¨í•˜ëŠ” ë™ì•ˆ ì²´í¬í¬ì¸íŠ¸ ì €ì¥í•˜ê¸°
í›ˆë ¨ ì¤‘ê°„ê³¼ í›ˆë ¨ ë§ˆì§€ë§‰ì— ì²´í¬í¬ì¸íŠ¸(checkpoint)ë¥¼ ìë™ìœ¼ë¡œ ì €ì¥í•˜ë„ë¡ í•˜ëŠ” ê²ƒì´ ë§ì´ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì…ë‹ˆë‹¤. ë‹¤ì‹œ í›ˆë ¨í•˜ì§€ ì•Šê³  ëª¨ë¸ì„ ì¬ì‚¬ìš©í•˜ê±°ë‚˜ í›ˆë ¨ ê³¼ì •ì´ ì¤‘ì§€ëœ ê²½ìš° ì´ì–´ì„œ í›ˆë ¨ì„ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. tf.keras.callbacks.ModelCheckpointì€ ì´ëŸ° ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì½œë°±(callback)ì…ë‹ˆë‹¤. ì´ ì½œë°±ì€ ì²´í¬í¬ì¸íŠ¸ ì‘ì—…ì„ ì¡°ì •í•  ìˆ˜ ìˆë„ë¡ ì—¬ëŸ¬ê°€ì§€ ë§¤ê°œë³€ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">checkpoint_path = <span class="string">"training_1/cp.ckpt"</span></span><br><span class="line">checkpoint_dir = os.path.dirname(checkpoint_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•˜ëŠ” ì½œë°± ë§Œë“¤ê¸°</span></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,</span><br><span class="line">                                                 save_weights_only=<span class="literal">True</span>,</span><br><span class="line">                                                 verbose=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ìƒˆë¡œìš´ ì½œë°±ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨í•˜ê¸°</span></span><br><span class="line">model.fit(train_images, </span><br><span class="line">          train_labels,  </span><br><span class="line">          epochs=<span class="number">10</span>,</span><br><span class="line">          validation_data=(test_images,test_labels),</span><br><span class="line">          callbacks=[cp_callback])  <span class="comment"># ì½œë°±ì„ í›ˆë ¨ì— ì „ë‹¬í•©ë‹ˆë‹¤</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ì˜µí‹°ë§ˆì´ì €ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” ê²ƒê³¼ ê´€ë ¨ë˜ì–´ ê²½ê³ ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</span></span><br><span class="line"><span class="comment"># ì´ ê²½ê³ ëŠ” (ê·¸ë¦¬ê³  ì´ ë…¸íŠ¸ë¶ì˜ ë‹¤ë¥¸ ë¹„ìŠ·í•œ ê²½ê³ ëŠ”) ì´ì „ ì‚¬ìš© ë°©ì‹ì„ ê¶Œì¥í•˜ì§€ ì•Šê¸° ìœ„í•¨ì´ë©° ë¬´ì‹œí•´ë„ ì¢‹ìŠµë‹ˆë‹¤.</span></span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:Automatic model reloading for interrupted job was removed from the `ModelCheckpoint` callback in multi-worker mode, please use the `keras.callbacks.experimental.BackupAndRestore` callback instead. See this tutorial for details: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#backupandrestore_callback.
Epoch 1/10
16/32 [==============&gt;...............] - ETA: 0s - loss: 1.8756 - accuracy: 0.3736 
Epoch 00001: saving model to training_1/cp.ckpt
32/32 [==============================] - 1s 30ms/step - loss: 1.5677 - accuracy: 0.5056 - val_loss: 0.6899 - val_accuracy: 0.7870
Epoch 2/10
31/32 [============================&gt;.] - ETA: 0s - loss: 0.4283 - accuracy: 0.8845
Epoch 00002: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 8ms/step - loss: 0.4276 - accuracy: 0.8844 - val_loss: 0.5193 - val_accuracy: 0.8380
Epoch 3/10
20/32 [=================&gt;............] - ETA: 0s - loss: 0.2892 - accuracy: 0.9208
Epoch 00003: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 6ms/step - loss: 0.2828 - accuracy: 0.9232 - val_loss: 0.4733 - val_accuracy: 0.8510
Epoch 4/10
19/32 [================&gt;.............] - ETA: 0s - loss: 0.1721 - accuracy: 0.9687
Epoch 00004: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 6ms/step - loss: 0.1836 - accuracy: 0.9622 - val_loss: 0.4489 - val_accuracy: 0.8490
Epoch 5/10
17/32 [==============&gt;...............] - ETA: 0s - loss: 0.1666 - accuracy: 0.9582
Epoch 00005: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9605 - val_loss: 0.4112 - val_accuracy: 0.8580
Epoch 6/10
30/32 [===========================&gt;..] - ETA: 0s - loss: 0.1015 - accuracy: 0.9851
Epoch 00006: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 7ms/step - loss: 0.1023 - accuracy: 0.9846 - val_loss: 0.4088 - val_accuracy: 0.8650
Epoch 7/10
17/32 [==============&gt;...............] - ETA: 0s - loss: 0.0798 - accuracy: 0.9883
Epoch 00007: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 6ms/step - loss: 0.0828 - accuracy: 0.9870 - val_loss: 0.4074 - val_accuracy: 0.8680
Epoch 8/10
32/32 [==============================] - ETA: 0s - loss: 0.0718 - accuracy: 0.9899
Epoch 00008: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9900 - val_loss: 0.4204 - val_accuracy: 0.8590
Epoch 9/10
28/32 [=========================&gt;....] - ETA: 0s - loss: 0.0588 - accuracy: 0.9915
Epoch 00009: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 7ms/step - loss: 0.0574 - accuracy: 0.9920 - val_loss: 0.4110 - val_accuracy: 0.8640
Epoch 10/10
31/32 [============================&gt;.] - ETA: 0s - loss: 0.0325 - accuracy: 0.9978
Epoch 00010: saving model to training_1/cp.ckpt
32/32 [==============================] - 0s 6ms/step - loss: 0.0328 - accuracy: 0.9978 - val_loss: 0.3962 - val_accuracy: 0.8660





&lt;tensorflow.python.keras.callbacks.History at 0x7fd0f59b3f10&gt;



ì´ ì½”ë“œëŠ” tensorflow ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì„ ë§Œë“¤ê³  ì—í¬í¬ê°€ ì¢…ë£Œë  ë•Œë§ˆë‹¤ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤:</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls &#123;checkpoint_dir&#125;</span><br></pre></td></tr></table></figure>

<pre><code>checkpoint                   cp.ckpt.index
cp.ckpt.data-00000-of-00001</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ìƒˆë¡œìš´ ëª¨ë¸ ìƒì„±</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line">loss, acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"í›ˆë ¨ë˜ì§€ ì•Šì€ ëª¨ë¸ì˜ ì •í™•ë„: &#123;:5.2f&#125;%"</span>.format(<span class="number">100</span>*acc))</span><br></pre></td></tr></table></figure>

<pre><code>32/32 - 0s - loss: 2.3409 - accuracy: 0.1250
í›ˆë ¨ë˜ì§€ ì•Šì€ ëª¨ë¸ì˜ ì •í™•ë„: 12.50%


ì €ì¥í–ˆë˜ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ë‹¤ì‹œ í‰ê°€í•´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ê°€ì¤‘ì¹˜ ë¡œë“œ</span></span><br><span class="line">model.load_weights(checkpoint_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ ì¬í‰ê°€</span></span><br><span class="line">loss, acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: &#123;:5.2f&#125;%"</span>.format(<span class="number">100</span>*acc))</span><br></pre></td></tr></table></figure>

<pre><code>32/32 - 0s - loss: 0.3962 - accuracy: 0.8660
ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: 86.60%


ì²´í¬í¬ì¸íŠ¸ ì½œë°± ë§¤ê°œë³€ìˆ˜</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># íŒŒì¼ ì´ë¦„ì— ì—í¬í¬ ë²ˆí˜¸ë¥¼ í¬í•¨ì‹œí‚µë‹ˆë‹¤(`str.format` í¬ë§·)</span></span><br><span class="line">checkpoint_path = <span class="string">"training_2/cp-&#123;epoch:04d&#125;.ckpt"</span></span><br><span class="line">checkpoint_dir = os.path.dirname(checkpoint_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ë‹¤ì„¯ ë²ˆì§¸ ì—í¬í¬ë§ˆë‹¤ ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ì½œë°±ì„ ë§Œë“­ë‹ˆë‹¤</span></span><br><span class="line">cp_callback = tf.keras.callbacks.ModelCheckpoint(</span><br><span class="line">    filepath=checkpoint_path, </span><br><span class="line">    verbose=<span class="number">1</span>, </span><br><span class="line">    save_weights_only=<span class="literal">True</span>,</span><br><span class="line">    period=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ìƒˆë¡œìš´ ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># `checkpoint_path` í¬ë§·ì„ ì‚¬ìš©í•˜ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤</span></span><br><span class="line">model.save_weights(checkpoint_path.format(epoch=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ìƒˆë¡œìš´ ì½œë°±ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤</span></span><br><span class="line">model.fit(train_images, </span><br><span class="line">          train_labels,</span><br><span class="line">          epochs=<span class="number">50</span>, </span><br><span class="line">          callbacks=[cp_callback],</span><br><span class="line">          validation_data=(test_images,test_labels),</span><br><span class="line">          verbose=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
WARNING:tensorflow:Automatic model reloading for interrupted job was removed from the `ModelCheckpoint` callback in multi-worker mode, please use the `keras.callbacks.experimental.BackupAndRestore` callback instead. See this tutorial for details: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#backupandrestore_callback.

Epoch 00005: saving model to training_2/cp-0005.ckpt

Epoch 00010: saving model to training_2/cp-0010.ckpt

Epoch 00015: saving model to training_2/cp-0015.ckpt

Epoch 00020: saving model to training_2/cp-0020.ckpt

Epoch 00025: saving model to training_2/cp-0025.ckpt

Epoch 00030: saving model to training_2/cp-0030.ckpt

Epoch 00035: saving model to training_2/cp-0035.ckpt

Epoch 00040: saving model to training_2/cp-0040.ckpt

Epoch 00045: saving model to training_2/cp-0045.ckpt

Epoch 00050: saving model to training_2/cp-0050.ckpt





&lt;tensorflow.python.keras.callbacks.History at 0x7fd0f1d481d0&gt;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls &#123;checkpoint_dir&#125;</span><br></pre></td></tr></table></figure>

<pre><code>checkpoint                        cp-0025.ckpt.index
cp-0000.ckpt.data-00000-of-00001  cp-0030.ckpt.data-00000-of-00001
cp-0000.ckpt.index                cp-0030.ckpt.index
cp-0005.ckpt.data-00000-of-00001  cp-0035.ckpt.data-00000-of-00001
cp-0005.ckpt.index                cp-0035.ckpt.index
cp-0010.ckpt.data-00000-of-00001  cp-0040.ckpt.data-00000-of-00001
cp-0010.ckpt.index                cp-0040.ckpt.index
cp-0015.ckpt.data-00000-of-00001  cp-0045.ckpt.data-00000-of-00001
cp-0015.ckpt.index                cp-0045.ckpt.index
cp-0020.ckpt.data-00000-of-00001  cp-0050.ckpt.data-00000-of-00001
cp-0020.ckpt.index                cp-0050.ckpt.index
cp-0025.ckpt.data-00000-of-00001</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">latest = tf.train.latest_checkpoint(checkpoint_dir)</span><br><span class="line">latest</span><br></pre></td></tr></table></figure>




<pre><code>&apos;training_2/cp-0050.ckpt&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ëª¨ë¸ ì´ˆê¸°í™” ë° ìƒì„±</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ ë¡œë“œ</span></span><br><span class="line">model.load_weights(latest)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ ë³µì›, í‰ê°€</span></span><br><span class="line">loss, acc = model.evaluate(test_images, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: &#123;:5.2f&#125;%"</span>.format(<span class="number">100</span>*acc))</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
32/32 - 0s - loss: 0.4795 - accuracy: 0.8720
ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: 87.20%


ìˆ˜ë™ìœ¼ë¡œ ê°€ì¤‘ì¹˜ ì €ì¥í•˜ê¸°</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ê°€ì¤‘ì¹˜ë¥¼ ì €ì¥í•©ë‹ˆë‹¤</span></span><br><span class="line">model.save_weights(<span class="string">'./checkpoints/my_checkpoint'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ìƒˆë¡œìš´ ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤</span></span><br><span class="line">model = create_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ê°€ì¤‘ì¹˜ë¥¼ ë³µì›í•©ë‹ˆë‹¤</span></span><br><span class="line">model.load_weights(<span class="string">'./checkpoints/my_checkpoint'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤</span></span><br><span class="line">loss,acc = model.evaluate(test_images,  test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: &#123;:5.2f&#125;%"</span>.format(<span class="number">100</span>*acc))</span><br></pre></td></tr></table></figure>

<pre><code>32/32 - 0s - loss: 0.4795 - accuracy: 0.8720
ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: 87.20%</code></pre><h6 id="ì „ì²´-ëª¨ë¸-ì €ì¥í•˜ê¸°"><a href="#ì „ì²´-ëª¨ë¸-ì €ì¥í•˜ê¸°" class="headerlink" title="ì „ì²´ ëª¨ë¸ ì €ì¥í•˜ê¸°"></a>ì „ì²´ ëª¨ë¸ ì €ì¥í•˜ê¸°</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ìƒˆë¡œìš´ ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“¤ê³  í›ˆë ¨í•©ë‹ˆë‹¤</span></span><br><span class="line">model = create_model()</span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># SavedModelë¡œ ì „ì²´ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤</span></span><br><span class="line">!mkdir -p saved_model</span><br><span class="line">model.save(<span class="string">'saved_model/my_model'</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
32/32 [==============================] - 0s 15ms/step - loss: 1.6664 - accuracy: 0.4644
Epoch 2/10
32/32 [==============================] - 0s 3ms/step - loss: 0.4997 - accuracy: 0.8490
Epoch 3/10
32/32 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.9225
Epoch 4/10
32/32 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9644
Epoch 5/10
32/32 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9746
Epoch 6/10
32/32 [==============================] - 0s 4ms/step - loss: 0.1240 - accuracy: 0.9736
Epoch 7/10
32/32 [==============================] - 0s 4ms/step - loss: 0.0863 - accuracy: 0.9785
Epoch 8/10
32/32 [==============================] - 0s 3ms/step - loss: 0.0603 - accuracy: 0.9967
Epoch 9/10
32/32 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9974
Epoch 10/10
32/32 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9988
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
INFO:tensorflow:Assets written to: saved_model/my_model/assets</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># my_model ë””ë ‰í† ë¦¬</span></span><br><span class="line">!ls saved_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># assests í´ë”, saved_model.pb, variables í´ë”</span></span><br><span class="line">!ls saved_model/my_model</span><br></pre></td></tr></table></figure>

<pre><code>[34mmy_model[m[m
[34massets[m[m         saved_model.pb [34mvariables[m[m</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">new_model = tf.keras.models.load_model(<span class="string">'saved_model/my_model'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ êµ¬ì¡°ë¥¼ í™•ì¸í•©ë‹ˆë‹¤</span></span><br><span class="line">new_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_23&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_46 (Dense)             (None, 512)               401920    
_________________________________________________________________
dropout_23 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_47 (Dense)             (None, 10)                5130      
=================================================================
Total params: 407,050
Trainable params: 407,050
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ë³µì›ëœ ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤</span></span><br><span class="line">loss, acc = new_model.evaluate(test_images,  test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: &#123;:5.2f&#125;%'</span>.format(<span class="number">100</span>*acc))</span><br><span class="line"></span><br><span class="line">print(new_model.predict(test_images).shape)</span><br></pre></td></tr></table></figure>

<pre><code>32/32 - 0s - loss: 0.4205 - accuracy: 0.0880
ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„:  8.80%
(1000, 10)</code></pre><h6 id="HDF5-íŒŒì¼ë¡œ-ì €ì¥í•˜ê¸°"><a href="#HDF5-íŒŒì¼ë¡œ-ì €ì¥í•˜ê¸°" class="headerlink" title="HDF5 íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°"></a>HDF5 íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ìƒˆë¡œìš´ ëª¨ë¸ ê°ì²´ë¥¼ ë§Œë“¤ê³  í›ˆë ¨í•©ë‹ˆë‹¤</span></span><br><span class="line">model = create_model()</span><br><span class="line">model.fit(train_images, train_labels, epochs=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ì „ì²´ ëª¨ë¸ì„ HDF5 íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤</span></span><br><span class="line"><span class="comment"># '.h5' í™•ì¥ìëŠ” ì´ ëª¨ë¸ì´ HDF5ë¡œ ì €ì¥ë˜ì—ˆë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤</span></span><br><span class="line">model.save(<span class="string">'my_model.h5'</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/10
32/32 [==============================] - 0s 14ms/step - loss: 1.6326 - accuracy: 0.5135
Epoch 2/10
32/32 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8959
Epoch 3/10
32/32 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.9177
Epoch 4/10
32/32 [==============================] - 0s 3ms/step - loss: 0.2427 - accuracy: 0.9320
Epoch 5/10
32/32 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9757
Epoch 6/10
32/32 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9879
Epoch 7/10
32/32 [==============================] - 0s 3ms/step - loss: 0.0840 - accuracy: 0.9864
Epoch 8/10
32/32 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9946
Epoch 9/10
32/32 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9925
Epoch 10/10
32/32 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9994</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ê°€ì¤‘ì¹˜ì™€ ì˜µí‹°ë§ˆì´ì €ë¥¼ í¬í•¨í•˜ì—¬ ì •í™•íˆ ë™ì¼í•œ ëª¨ë¸ì„ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤</span></span><br><span class="line">new_model = tf.keras.models.load_model(<span class="string">'my_model.h5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ëª¨ë¸ êµ¬ì¡°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤</span></span><br><span class="line">new_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_25&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_50 (Dense)             (None, 512)               401920    
_________________________________________________________________
dropout_25 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_51 (Dense)             (None, 10)                5130      
=================================================================
Total params: 407,050
Trainable params: 407,050
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loss, acc = new_model.evaluate(test_images,  test_labels, verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">'ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„: &#123;:5.2f&#125;%'</span>.format(<span class="number">100</span>*acc))</span><br></pre></td></tr></table></figure>

<pre><code>32/32 - 0s - loss: 0.4255 - accuracy: 0.0890
ë³µì›ëœ ëª¨ë¸ì˜ ì •í™•ë„:  8.90%</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-25T11:21:43.000Z" title="2020-08-25T11:21:43.000Z">2020-08-25</time><span class="level-item">19 minutes read (About 2880 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/25/%EA%B3%BC%EB%8C%80%EC%A0%81%ED%95%A9-Overfitting-%EA%B3%BC-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-Underfitting/">ê³¼ëŒ€ì í•©(Overfitting)ê³¼ ê³¼ì†Œì í•©(Underfitting)</a></h1><div class="content"><h6 id="ê³¼ëŒ€ì í•©-Overfitting-ê³¼-ê³¼ì†Œì í•©-Underfitting"><a href="#ê³¼ëŒ€ì í•©-Overfitting-ê³¼-ê³¼ì†Œì í•©-Underfitting" class="headerlink" title="ê³¼ëŒ€ì í•©(Overfitting)ê³¼ ê³¼ì†Œì í•©(Underfitting)"></a>ê³¼ëŒ€ì í•©(Overfitting)ê³¼ ê³¼ì†Œì í•©(Underfitting)</h6><pre><code>ì¼ì • ì—í¬í¬ ë™ì•ˆ í›ˆë ¨ì„ ì‹œí‚¤ë©´ ê²€ì¦ì„¸íŠ¸ì—ì„œ ëª¨ë¸ ì„±ëŠ¥ì´ ìµœê³ ì ì— ë„ë‹¬í•œ ë‹¤ìŒ ê°ì†Œí•˜ê¸° ì‹œì‘í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ë†’ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆì§€ë§Œ ì§„ì§œ ì›í•˜ëŠ” ê²ƒì€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸(ë˜ëŠ” ì´ì „ì— ë³¸ ì  ì—†ëŠ” ë°ì´í„°)ì— ì˜ ì¼ë°˜í™”ë˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.

ê³¼ì†Œì í•©ì´ë€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì„±ëŠ¥ì´ í–¥ìƒë  ì—¬ì§€ê°€ ì•„ì§ ìˆì„ ë•Œ ì¼ì–´ë‚©ë‹ˆë‹¤. ë°œìƒí•˜ëŠ” ì›ì¸ì€ ì—¬ëŸ¬ê°€ì§€ì…ë‹ˆë‹¤. ëª¨ë¸ì´ ë„ˆë¬´ ë‹¨ìˆœí•˜ê±°ë‚˜, ê·œì œê°€ ë„ˆë¬´ ë§ê±°ë‚˜, ê·¸ëƒ¥ ë‹¨ìˆœíˆ ì¶©ë¶„íˆ ì˜¤ë˜ í›ˆë ¨í•˜ì§€ ì•ŠëŠ” ê²½ìš°ì…ë‹ˆë‹¤. ì¦‰ ë„¤íŠ¸ì›Œí¬ê°€ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ ì ì ˆí•œ íŒ¨í„´ì„ í•™ìŠµí•˜ì§€ ëª»í–ˆë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.

ëª¨ë¸ì„ ë„ˆë¬´ ì˜¤ë˜ í›ˆë ¨í•˜ë©´ ê³¼ëŒ€ì í•©ë˜ê¸° ì‹œì‘í•˜ê³  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì¼ë°˜í™”ë˜ì§€ ëª»í•˜ëŠ” íŒ¨í„´ì„ í›ˆë ¨ ì„¸íŠ¸ì—ì„œ í•™ìŠµí•©ë‹ˆë‹¤. ê³¼ëŒ€ì í•©ê³¼ ê³¼ì†Œì í•© ì‚¬ì´ì—ì„œ ê· í˜•ì„ ì¡ì•„ì•¼ í•©ë‹ˆë‹¤.

ê· í˜•ì„ ì˜ ì¡ê³  ê³¼ëŒ€ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ 2ê°€ì§€ ê·œì œë°©ë²•ì„ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>2.4.0-dev20200724


ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œë¥¼ ë°›ê³  ì›í•« ì¸ì½”ë”©ìœ¼ë¡œ ë³€í™˜í•˜ì!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">NUM_WORDS = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_hot_sequences</span><span class="params">(sequences, dimension)</span>:</span></span><br><span class="line">    <span class="comment"># 0ìœ¼ë¡œ ì±„ì›Œì§„ (len(sequences), dimension) í¬ê¸°ì˜ í–‰ë ¬ì„ ë§Œë“­ë‹ˆë‹¤</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, word_indices <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, word_indices] = <span class="number">1.0</span>  <span class="comment"># results[i]ì˜ íŠ¹ì • ì¸ë±ìŠ¤ë§Œ 1ë¡œ ì„¤ì •í•©ë‹ˆë‹¤</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)</span><br><span class="line">test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(train_data[<span class="number">0</span>])</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="374" alt="output_4_0" src="https://user-images.githubusercontent.com/59719711/91168503-b4fa0a80-e710-11ea-9844-30bd30bac3a6.png">


<pre><code>ê¸°ì¤€ ëª¨ë¸ì„ ë§Œë“¤ì–´ ê¸°ì¤€ë³´ë‹¤ ìœ ë‹›ì˜ ìˆ˜ê°€ í¬ê±°ë‚˜ ì‘ì€ ëª¨ë¸ê³¼ ë¹„êµë¥¼ í•´ë³´ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">base_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">base_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">base_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 16)                16016     
_________________________________________________________________
dense_12 (Dense)             (None, 16)                272       
_________________________________________________________________
dense_13 (Dense)             (None, 1)                 17        
=================================================================
Total params: 16,305
Trainable params: 16,305
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">base_history = base_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 0s - loss: 0.2555 - accuracy: 0.8971 - binary_crossentropy: 0.2555 - val_loss: 0.3410 - val_accuracy: 0.8558 - val_binary_crossentropy: 0.3410
Epoch 2/20
49/49 - 0s - loss: 0.2436 - accuracy: 0.9030 - binary_crossentropy: 0.2436 - val_loss: 0.3454 - val_accuracy: 0.8540 - val_binary_crossentropy: 0.3454
Epoch 3/20
49/49 - 0s - loss: 0.2356 - accuracy: 0.9068 - binary_crossentropy: 0.2356 - val_loss: 0.3525 - val_accuracy: 0.8508 - val_binary_crossentropy: 0.3525
Epoch 4/20
49/49 - 0s - loss: 0.2259 - accuracy: 0.9102 - binary_crossentropy: 0.2259 - val_loss: 0.3638 - val_accuracy: 0.8482 - val_binary_crossentropy: 0.3638
Epoch 5/20
49/49 - 0s - loss: 0.2178 - accuracy: 0.9142 - binary_crossentropy: 0.2178 - val_loss: 0.3701 - val_accuracy: 0.8487 - val_binary_crossentropy: 0.3701
Epoch 6/20
49/49 - 0s - loss: 0.2093 - accuracy: 0.9188 - binary_crossentropy: 0.2093 - val_loss: 0.3809 - val_accuracy: 0.8469 - val_binary_crossentropy: 0.3809
Epoch 7/20
49/49 - 0s - loss: 0.2026 - accuracy: 0.9208 - binary_crossentropy: 0.2026 - val_loss: 0.3854 - val_accuracy: 0.8465 - val_binary_crossentropy: 0.3854
Epoch 8/20
49/49 - 0s - loss: 0.1963 - accuracy: 0.9240 - binary_crossentropy: 0.1963 - val_loss: 0.3996 - val_accuracy: 0.8430 - val_binary_crossentropy: 0.3996
Epoch 9/20
49/49 - 0s - loss: 0.1905 - accuracy: 0.9254 - binary_crossentropy: 0.1905 - val_loss: 0.4014 - val_accuracy: 0.8421 - val_binary_crossentropy: 0.4014
Epoch 10/20
49/49 - 0s - loss: 0.1846 - accuracy: 0.9307 - binary_crossentropy: 0.1846 - val_loss: 0.4143 - val_accuracy: 0.8418 - val_binary_crossentropy: 0.4143
Epoch 11/20
49/49 - 0s - loss: 0.1787 - accuracy: 0.9322 - binary_crossentropy: 0.1787 - val_loss: 0.4300 - val_accuracy: 0.8382 - val_binary_crossentropy: 0.4300
Epoch 12/20
49/49 - 0s - loss: 0.1739 - accuracy: 0.9329 - binary_crossentropy: 0.1739 - val_loss: 0.4402 - val_accuracy: 0.8372 - val_binary_crossentropy: 0.4402
Epoch 13/20
49/49 - 0s - loss: 0.1663 - accuracy: 0.9373 - binary_crossentropy: 0.1663 - val_loss: 0.4508 - val_accuracy: 0.8358 - val_binary_crossentropy: 0.4508
Epoch 14/20
49/49 - 0s - loss: 0.1613 - accuracy: 0.9396 - binary_crossentropy: 0.1613 - val_loss: 0.4584 - val_accuracy: 0.8364 - val_binary_crossentropy: 0.4584
Epoch 15/20
49/49 - 0s - loss: 0.1581 - accuracy: 0.9400 - binary_crossentropy: 0.1581 - val_loss: 0.4805 - val_accuracy: 0.8356 - val_binary_crossentropy: 0.4805
Epoch 16/20
49/49 - 0s - loss: 0.1534 - accuracy: 0.9419 - binary_crossentropy: 0.1534 - val_loss: 0.4836 - val_accuracy: 0.8343 - val_binary_crossentropy: 0.4836
Epoch 17/20
49/49 - 0s - loss: 0.1477 - accuracy: 0.9454 - binary_crossentropy: 0.1477 - val_loss: 0.5082 - val_accuracy: 0.8330 - val_binary_crossentropy: 0.5082
Epoch 18/20
49/49 - 0s - loss: 0.1440 - accuracy: 0.9458 - binary_crossentropy: 0.1440 - val_loss: 0.5069 - val_accuracy: 0.8342 - val_binary_crossentropy: 0.5069
Epoch 19/20
49/49 - 0s - loss: 0.1382 - accuracy: 0.9489 - binary_crossentropy: 0.1382 - val_loss: 0.5187 - val_accuracy: 0.8323 - val_binary_crossentropy: 0.5187
Epoch 20/20
49/49 - 0s - loss: 0.1339 - accuracy: 0.9520 - binary_crossentropy: 0.1339 - val_loss: 0.5385 - val_accuracy: 0.8310 - val_binary_crossentropy: 0.5385


ì‘ì€ ëª¨ë¸ì„ ë§Œë“¤ì–´ë³´ì</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">small_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">6</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">6</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">small_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">small_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_18 (Dense)             (None, 6)                 6006      
_________________________________________________________________
dense_19 (Dense)             (None, 6)                 42        
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 7         
=================================================================
Total params: 6,055
Trainable params: 6,055
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">small_history = small_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 0s - loss: 0.2994 - accuracy: 0.8785 - binary_crossentropy: 0.2994 - val_loss: 0.3305 - val_accuracy: 0.8593 - val_binary_crossentropy: 0.3305
Epoch 2/20
49/49 - 0s - loss: 0.2972 - accuracy: 0.8790 - binary_crossentropy: 0.2972 - val_loss: 0.3306 - val_accuracy: 0.8599 - val_binary_crossentropy: 0.3306
Epoch 3/20
49/49 - 0s - loss: 0.2970 - accuracy: 0.8782 - binary_crossentropy: 0.2970 - val_loss: 0.3343 - val_accuracy: 0.8581 - val_binary_crossentropy: 0.3343
Epoch 4/20
49/49 - 0s - loss: 0.2965 - accuracy: 0.8777 - binary_crossentropy: 0.2965 - val_loss: 0.3312 - val_accuracy: 0.8590 - val_binary_crossentropy: 0.3312
Epoch 5/20
49/49 - 0s - loss: 0.2960 - accuracy: 0.8794 - binary_crossentropy: 0.2960 - val_loss: 0.3314 - val_accuracy: 0.8592 - val_binary_crossentropy: 0.3314
Epoch 6/20
49/49 - 0s - loss: 0.2957 - accuracy: 0.8783 - binary_crossentropy: 0.2957 - val_loss: 0.3320 - val_accuracy: 0.8590 - val_binary_crossentropy: 0.3320
Epoch 7/20
49/49 - 0s - loss: 0.2968 - accuracy: 0.8768 - binary_crossentropy: 0.2968 - val_loss: 0.3321 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3321
Epoch 8/20
49/49 - 0s - loss: 0.2960 - accuracy: 0.8790 - binary_crossentropy: 0.2960 - val_loss: 0.3323 - val_accuracy: 0.8594 - val_binary_crossentropy: 0.3323
Epoch 9/20
49/49 - 0s - loss: 0.2960 - accuracy: 0.8787 - binary_crossentropy: 0.2960 - val_loss: 0.3323 - val_accuracy: 0.8582 - val_binary_crossentropy: 0.3323
Epoch 10/20
49/49 - 0s - loss: 0.2959 - accuracy: 0.8784 - binary_crossentropy: 0.2959 - val_loss: 0.3327 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3327
Epoch 11/20
49/49 - 0s - loss: 0.2953 - accuracy: 0.8789 - binary_crossentropy: 0.2953 - val_loss: 0.3334 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3334
Epoch 12/20
49/49 - 0s - loss: 0.2970 - accuracy: 0.8775 - binary_crossentropy: 0.2970 - val_loss: 0.3334 - val_accuracy: 0.8578 - val_binary_crossentropy: 0.3334
Epoch 13/20
49/49 - 0s - loss: 0.2951 - accuracy: 0.8798 - binary_crossentropy: 0.2951 - val_loss: 0.3341 - val_accuracy: 0.8581 - val_binary_crossentropy: 0.3341
Epoch 14/20
49/49 - 0s - loss: 0.2950 - accuracy: 0.8786 - binary_crossentropy: 0.2950 - val_loss: 0.3323 - val_accuracy: 0.8590 - val_binary_crossentropy: 0.3323
Epoch 15/20
49/49 - 0s - loss: 0.2950 - accuracy: 0.8786 - binary_crossentropy: 0.2950 - val_loss: 0.3324 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3324
Epoch 16/20
49/49 - 0s - loss: 0.2949 - accuracy: 0.8790 - binary_crossentropy: 0.2949 - val_loss: 0.3330 - val_accuracy: 0.8593 - val_binary_crossentropy: 0.3330
Epoch 17/20
49/49 - 0s - loss: 0.2946 - accuracy: 0.8784 - binary_crossentropy: 0.2946 - val_loss: 0.3324 - val_accuracy: 0.8585 - val_binary_crossentropy: 0.3324
Epoch 18/20
49/49 - 0s - loss: 0.2952 - accuracy: 0.8784 - binary_crossentropy: 0.2952 - val_loss: 0.3329 - val_accuracy: 0.8585 - val_binary_crossentropy: 0.3329
Epoch 19/20
49/49 - 0s - loss: 0.2943 - accuracy: 0.8794 - binary_crossentropy: 0.2943 - val_loss: 0.3330 - val_accuracy: 0.8588 - val_binary_crossentropy: 0.3330
Epoch 20/20
49/49 - 0s - loss: 0.2949 - accuracy: 0.8789 - binary_crossentropy: 0.2949 - val_loss: 0.3329 - val_accuracy: 0.8583 - val_binary_crossentropy: 0.3329


í° ëª¨ë¸ ë§Œë“¤ê¸°</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">big_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">big_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">big_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_21 (Dense)             (None, 128)               128128    
_________________________________________________________________
dense_22 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 129       
=================================================================
Total params: 144,769
Trainable params: 144,769
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">big_history = big_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 0s - loss: 0.0047 - accuracy: 0.9999 - binary_crossentropy: 0.0047 - val_loss: 0.6867 - val_accuracy: 0.8388 - val_binary_crossentropy: 0.6867
Epoch 2/20
49/49 - 0s - loss: 0.0029 - accuracy: 1.0000 - binary_crossentropy: 0.0029 - val_loss: 0.7205 - val_accuracy: 0.8382 - val_binary_crossentropy: 0.7205
Epoch 3/20
49/49 - 0s - loss: 0.0019 - accuracy: 1.0000 - binary_crossentropy: 0.0019 - val_loss: 0.7533 - val_accuracy: 0.8388 - val_binary_crossentropy: 0.7533
Epoch 4/20
49/49 - 0s - loss: 0.0014 - accuracy: 1.0000 - binary_crossentropy: 0.0014 - val_loss: 0.7802 - val_accuracy: 0.8383 - val_binary_crossentropy: 0.7802
Epoch 5/20
49/49 - 0s - loss: 0.0010 - accuracy: 1.0000 - binary_crossentropy: 0.0010 - val_loss: 0.8079 - val_accuracy: 0.8392 - val_binary_crossentropy: 0.8079
Epoch 6/20
49/49 - 0s - loss: 8.0437e-04 - accuracy: 1.0000 - binary_crossentropy: 8.0437e-04 - val_loss: 0.8324 - val_accuracy: 0.8392 - val_binary_crossentropy: 0.8324
Epoch 7/20
49/49 - 0s - loss: 6.4169e-04 - accuracy: 1.0000 - binary_crossentropy: 6.4169e-04 - val_loss: 0.8510 - val_accuracy: 0.8397 - val_binary_crossentropy: 0.8510
Epoch 8/20
49/49 - 0s - loss: 5.2259e-04 - accuracy: 1.0000 - binary_crossentropy: 5.2259e-04 - val_loss: 0.8707 - val_accuracy: 0.8397 - val_binary_crossentropy: 0.8707
Epoch 9/20
49/49 - 0s - loss: 4.3499e-04 - accuracy: 1.0000 - binary_crossentropy: 4.3499e-04 - val_loss: 0.8885 - val_accuracy: 0.8395 - val_binary_crossentropy: 0.8885
Epoch 10/20
49/49 - 0s - loss: 3.6612e-04 - accuracy: 1.0000 - binary_crossentropy: 3.6612e-04 - val_loss: 0.9055 - val_accuracy: 0.8397 - val_binary_crossentropy: 0.9055
Epoch 11/20
49/49 - 0s - loss: 3.1179e-04 - accuracy: 1.0000 - binary_crossentropy: 3.1179e-04 - val_loss: 0.9202 - val_accuracy: 0.8396 - val_binary_crossentropy: 0.9202
Epoch 12/20
49/49 - 0s - loss: 2.6851e-04 - accuracy: 1.0000 - binary_crossentropy: 2.6851e-04 - val_loss: 0.9358 - val_accuracy: 0.8396 - val_binary_crossentropy: 0.9358
Epoch 13/20
49/49 - 0s - loss: 2.3418e-04 - accuracy: 1.0000 - binary_crossentropy: 2.3418e-04 - val_loss: 0.9482 - val_accuracy: 0.8399 - val_binary_crossentropy: 0.9482
Epoch 14/20
49/49 - 0s - loss: 2.0480e-04 - accuracy: 1.0000 - binary_crossentropy: 2.0480e-04 - val_loss: 0.9615 - val_accuracy: 0.8400 - val_binary_crossentropy: 0.9615
Epoch 15/20
49/49 - 0s - loss: 1.8099e-04 - accuracy: 1.0000 - binary_crossentropy: 1.8099e-04 - val_loss: 0.9732 - val_accuracy: 0.8396 - val_binary_crossentropy: 0.9732
Epoch 16/20
49/49 - 0s - loss: 1.6065e-04 - accuracy: 1.0000 - binary_crossentropy: 1.6065e-04 - val_loss: 0.9851 - val_accuracy: 0.8400 - val_binary_crossentropy: 0.9851
Epoch 17/20
49/49 - 0s - loss: 1.4336e-04 - accuracy: 1.0000 - binary_crossentropy: 1.4336e-04 - val_loss: 0.9966 - val_accuracy: 0.8401 - val_binary_crossentropy: 0.9966
Epoch 18/20
49/49 - 0s - loss: 1.2880e-04 - accuracy: 1.0000 - binary_crossentropy: 1.2880e-04 - val_loss: 1.0070 - val_accuracy: 0.8399 - val_binary_crossentropy: 1.0070
Epoch 19/20
49/49 - 0s - loss: 1.1636e-04 - accuracy: 1.0000 - binary_crossentropy: 1.1636e-04 - val_loss: 1.0171 - val_accuracy: 0.8398 - val_binary_crossentropy: 1.0171
Epoch 20/20
49/49 - 0s - loss: 1.0553e-04 - accuracy: 1.0000 - binary_crossentropy: 1.0553e-04 - val_loss: 1.0270 - val_accuracy: 0.8398 - val_binary_crossentropy: 1.0270</code></pre><p>training datasetì˜ loss(ì†ì‹¤)ê°’ê³¼ test datasetì˜ loss(ì†ì‹¤)ê°’ ì‹œê°í™”</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_history</span><span class="params">(histories, key=<span class="string">'binary_crossentropy'</span>)</span>:</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> name, history <span class="keyword">in</span> histories:</span><br><span class="line">        val = plt.plot(history.epoch, history.history[<span class="string">'val_'</span> + key],</span><br><span class="line">                      <span class="string">'--'</span>, label=name.title()+<span class="string">' Val'</span>)</span><br><span class="line">        plt.plot(history.epoch, history.history[key], color=val[<span class="number">0</span>].get_color(),</span><br><span class="line">                label=name.title()+<span class="string">'Train'</span>)</span><br><span class="line">                       </span><br><span class="line">    plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">    plt.ylabel(key.replace(<span class="string">'-'</span>, <span class="string">' '</span>).title())</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    plt.xlim([<span class="number">0</span>, max(history.epoch)])</span><br><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'smaller'</span>, small_history),</span><br><span class="line">              (<span class="string">'bigger'</span>, big_history)])</span><br></pre></td></tr></table></figure>



<img width="947" alt="output_15_0" src="https://user-images.githubusercontent.com/59719711/91168509-b6c3ce00-e710-11ea-9ccf-2e3a684d81c9.png">



<p>big modelì˜ ê²½ìš° ì—í¬í¬ê°€ ì‹œì‘í•˜ìë§ˆì ê³¼ëŒ€ì í•©(Overfitting)ì´ ì¼ì–´ë‚˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆê³  ìƒê°ë³´ë‹¤ ì‹¬í•˜ê²Œ ì´ë¤„ì§‘ë‹ˆë‹¤. ëª¨ë¸ ë„¤íŠ¸ì›Œí¬ì˜ ìš©ëŸ‰ì´ ë§ì„ìˆ˜ë¡ ê³¼ëŒ€ì í•©ì´ ë  í™•ë¥ ì´ ì»¤ì§‘ë‹ˆë‹¤.(í›ˆë ¨ lossê°’ê³¼ ê²€ì¦ lossê°’ ì‚¬ì´ì— í° ì°¨ì´ê°€ ë°œìƒ)</p>
<p>ê³¼ëŒ€ì í•©(Overfitting)ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì „ëµ</p>
<pre><code>- ê°€ì¤‘ì¹˜ ê·œì œí•˜ê¸°
    1. í›ˆë ¨ ë°ì´í„°ì™€ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ, ë°ì´í„°ë¥¼ ì„¤ëª…í•  ìˆ˜ ìˆëŠ” ê°€ì¤‘ì¹˜ì˜ ì¡°í•©ì„ ê°„ë‹¨í•˜ê²Œ!
    2. ëª¨ë¸ íŒŒë¼ë¯¸í„°ì˜ ë¶„í¬ë¥¼ ë´¤ì„ ë•Œ ì—”íŠ¸ë¡œí”¼ê°€ ì‘ì€ ëª¨ë¸(ì ì€ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§€ëŠ” ëª¨ë¸), ì¦‰ ê³¼ëŒ€ì í•©ì„ ì™„í™”ì‹œí‚¤ëŠ” ì¼ë°˜ì ì¸ ë°©ë²•ì€ ê°€ì¤‘ì¹˜ê°€ ì‘ì€ ê°’ì„ ê°€ì§€ë„ë¡ ë„¤íŠ¸ì›Œí¬ì˜ ë³µì¡ë„ì— ì œì•½ì„ ê°€í•˜ëŠ” ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. &apos;ê°€ì¤‘ì¹˜ ê·œì œ(Weight regularization)
        * L1 ê·œì œëŠ” ê°€ì¤‘ì¹˜ì˜ ì ˆëŒ“ê°’ì— ë¹„ë¡€í•˜ëŠ” ë¹„ìš©ì´ ì¶”ê°€
        * L2 ê·œì œëŠ” ê°€ì¤‘ì¹˜ì˜ ì œê³±ì— ë¹„ë¡€í•˜ëŠ” ë¹„ìš©ì´ ì¶”ê°€, ì‹ ê²½ë§ì—ì„œëŠ” L2ê·œì œë¥¼ ê°€ì¤‘ì¹˜ ê°ì‡ (weight decay)ë¼ê³ ë„ í•©ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">l2_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>),</span><br><span class="line">                       activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>),</span><br><span class="line">                       activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">l2_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">l2_history = l2_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 1s - loss: 0.6362 - accuracy: 0.6929 - binary_crossentropy: 0.5927 - val_loss: 0.4927 - val_accuracy: 0.8113 - val_binary_crossentropy: 0.4513
Epoch 2/20
49/49 - 0s - loss: 0.4164 - accuracy: 0.8462 - binary_crossentropy: 0.3749 - val_loss: 0.3873 - val_accuracy: 0.8545 - val_binary_crossentropy: 0.3460
Epoch 3/20
49/49 - 0s - loss: 0.3636 - accuracy: 0.8669 - binary_crossentropy: 0.3230 - val_loss: 0.3708 - val_accuracy: 0.8598 - val_binary_crossentropy: 0.3312
Epoch 4/20
49/49 - 0s - loss: 0.3498 - accuracy: 0.8721 - binary_crossentropy: 0.3113 - val_loss: 0.3687 - val_accuracy: 0.8596 - val_binary_crossentropy: 0.3312
Epoch 5/20
49/49 - 0s - loss: 0.3440 - accuracy: 0.8726 - binary_crossentropy: 0.3073 - val_loss: 0.3640 - val_accuracy: 0.8602 - val_binary_crossentropy: 0.3283
Epoch 6/20
49/49 - 0s - loss: 0.3393 - accuracy: 0.8760 - binary_crossentropy: 0.3044 - val_loss: 0.3622 - val_accuracy: 0.8598 - val_binary_crossentropy: 0.3281
Epoch 7/20
49/49 - 0s - loss: 0.3369 - accuracy: 0.8749 - binary_crossentropy: 0.3034 - val_loss: 0.3604 - val_accuracy: 0.8603 - val_binary_crossentropy: 0.3276
Epoch 8/20
49/49 - 0s - loss: 0.3349 - accuracy: 0.8754 - binary_crossentropy: 0.3027 - val_loss: 0.3595 - val_accuracy: 0.8595 - val_binary_crossentropy: 0.3281
Epoch 9/20
49/49 - 0s - loss: 0.3325 - accuracy: 0.8746 - binary_crossentropy: 0.3015 - val_loss: 0.3608 - val_accuracy: 0.8592 - val_binary_crossentropy: 0.3304
Epoch 10/20
49/49 - 0s - loss: 0.3332 - accuracy: 0.8744 - binary_crossentropy: 0.3031 - val_loss: 0.3599 - val_accuracy: 0.8587 - val_binary_crossentropy: 0.3304
Epoch 11/20
49/49 - 0s - loss: 0.3305 - accuracy: 0.8750 - binary_crossentropy: 0.3012 - val_loss: 0.3563 - val_accuracy: 0.8592 - val_binary_crossentropy: 0.3274
Epoch 12/20
49/49 - 0s - loss: 0.3290 - accuracy: 0.8748 - binary_crossentropy: 0.3004 - val_loss: 0.3554 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3272
Epoch 13/20
49/49 - 0s - loss: 0.3272 - accuracy: 0.8752 - binary_crossentropy: 0.2991 - val_loss: 0.3526 - val_accuracy: 0.8604 - val_binary_crossentropy: 0.3247
Epoch 14/20
49/49 - 0s - loss: 0.3251 - accuracy: 0.8760 - binary_crossentropy: 0.2972 - val_loss: 0.3522 - val_accuracy: 0.8596 - val_binary_crossentropy: 0.3243
Epoch 15/20
49/49 - 0s - loss: 0.3232 - accuracy: 0.8759 - binary_crossentropy: 0.2953 - val_loss: 0.3547 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3268
Epoch 16/20
49/49 - 0s - loss: 0.3214 - accuracy: 0.8770 - binary_crossentropy: 0.2936 - val_loss: 0.3522 - val_accuracy: 0.8601 - val_binary_crossentropy: 0.3246
Epoch 17/20
49/49 - 0s - loss: 0.3201 - accuracy: 0.8781 - binary_crossentropy: 0.2926 - val_loss: 0.3512 - val_accuracy: 0.8600 - val_binary_crossentropy: 0.3238
Epoch 18/20
49/49 - 0s - loss: 0.3194 - accuracy: 0.8766 - binary_crossentropy: 0.2921 - val_loss: 0.3544 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3271
Epoch 19/20
49/49 - 0s - loss: 0.3180 - accuracy: 0.8772 - binary_crossentropy: 0.2908 - val_loss: 0.3509 - val_accuracy: 0.8603 - val_binary_crossentropy: 0.3238
Epoch 20/20
49/49 - 0s - loss: 0.3167 - accuracy: 0.8768 - binary_crossentropy: 0.2896 - val_loss: 0.3491 - val_accuracy: 0.8608 - val_binary_crossentropy: 0.3221</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'L2'</span>, l2_history)</span><br><span class="line">             ])</span><br></pre></td></tr></table></figure>


<img width="947" alt="output_20_0" src="https://user-images.githubusercontent.com/59719711/91168556-cb07cb00-e710-11ea-88ae-600d0836acfe.png">



<p>ê²°ê³¼ì—ì„œ ë³´ë“¯ì´ ëª¨ë¸ íŒŒë¼ë¯¸í„°ì˜ ê°œìˆ˜ëŠ” ë˜‘ê°™ì§€ë§Œ L2ê·œì œë¥¼ ì ìš©í•œ ëª¨ë¸ì´ base modelë³´ë‹¤ ê³¼ëŒ€ì í•©ì— í›¨ì”¬ ì˜ ê²¬ë””ê³  ìˆëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<pre><code>- dropout ì¶”ê°€í•˜ê¸°
    * ì‹ ê²½ë§ì—ì„œ ì“°ì´ëŠ” ê°€ì¥ íš¨ê³¼ì ì´ê³  ë„ë¦¬ ì‚¬ìš©í•˜ëŠ” ê·œì œ ê¸°ë²•ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.
    * dropoutì€ ì¸µì„ ì´ìš©í•´ ë„¤íŠ¸ì›Œí¬ì— ì¶”ê°€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ë‘ ê°œì˜ ì¸µì— dropout ê·œì œë¥¼ ì¶”ê°€í•˜ì—¬ ê³¼ëŒ€ì í•©ì´ ì–¼ë§ˆë‚˜ ê°ì†Œí•˜ëŠ”ì§€ ì•Œì•„ ë³´ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dpt_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">dpt_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">dpt_history = dpt_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 1s - loss: 0.6841 - accuracy: 0.5583 - binary_crossentropy: 0.6841 - val_loss: 0.6280 - val_accuracy: 0.7269 - val_binary_crossentropy: 0.6280
Epoch 2/20
49/49 - 0s - loss: 0.5848 - accuracy: 0.6974 - binary_crossentropy: 0.5848 - val_loss: 0.4655 - val_accuracy: 0.8180 - val_binary_crossentropy: 0.4655
Epoch 3/20
49/49 - 0s - loss: 0.4784 - accuracy: 0.7861 - binary_crossentropy: 0.4784 - val_loss: 0.3797 - val_accuracy: 0.8453 - val_binary_crossentropy: 0.3797
Epoch 4/20
49/49 - 0s - loss: 0.4250 - accuracy: 0.8195 - binary_crossentropy: 0.4250 - val_loss: 0.3453 - val_accuracy: 0.8510 - val_binary_crossentropy: 0.3453
Epoch 5/20
49/49 - 0s - loss: 0.3931 - accuracy: 0.8381 - binary_crossentropy: 0.3931 - val_loss: 0.3338 - val_accuracy: 0.8548 - val_binary_crossentropy: 0.3338
Epoch 6/20
49/49 - 0s - loss: 0.3758 - accuracy: 0.8480 - binary_crossentropy: 0.3758 - val_loss: 0.3299 - val_accuracy: 0.8587 - val_binary_crossentropy: 0.3299
Epoch 7/20
49/49 - 0s - loss: 0.3600 - accuracy: 0.8544 - binary_crossentropy: 0.3600 - val_loss: 0.3224 - val_accuracy: 0.8612 - val_binary_crossentropy: 0.3224
Epoch 8/20
49/49 - 0s - loss: 0.3493 - accuracy: 0.8607 - binary_crossentropy: 0.3493 - val_loss: 0.3227 - val_accuracy: 0.8600 - val_binary_crossentropy: 0.3227
Epoch 9/20
49/49 - 0s - loss: 0.3442 - accuracy: 0.8605 - binary_crossentropy: 0.3442 - val_loss: 0.3226 - val_accuracy: 0.8618 - val_binary_crossentropy: 0.3226
Epoch 10/20
49/49 - 0s - loss: 0.3317 - accuracy: 0.8674 - binary_crossentropy: 0.3317 - val_loss: 0.3230 - val_accuracy: 0.8597 - val_binary_crossentropy: 0.3230
Epoch 11/20
49/49 - 0s - loss: 0.3267 - accuracy: 0.8691 - binary_crossentropy: 0.3267 - val_loss: 0.3247 - val_accuracy: 0.8604 - val_binary_crossentropy: 0.3247
Epoch 12/20
49/49 - 0s - loss: 0.3242 - accuracy: 0.8695 - binary_crossentropy: 0.3242 - val_loss: 0.3261 - val_accuracy: 0.8597 - val_binary_crossentropy: 0.3261
Epoch 13/20
49/49 - 0s - loss: 0.3153 - accuracy: 0.8721 - binary_crossentropy: 0.3153 - val_loss: 0.3289 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3289
Epoch 14/20
49/49 - 0s - loss: 0.3092 - accuracy: 0.8742 - binary_crossentropy: 0.3092 - val_loss: 0.3294 - val_accuracy: 0.8573 - val_binary_crossentropy: 0.3294
Epoch 15/20
49/49 - 0s - loss: 0.3103 - accuracy: 0.8772 - binary_crossentropy: 0.3103 - val_loss: 0.3312 - val_accuracy: 0.8576 - val_binary_crossentropy: 0.3312
Epoch 16/20
49/49 - 0s - loss: 0.3010 - accuracy: 0.8815 - binary_crossentropy: 0.3010 - val_loss: 0.3363 - val_accuracy: 0.8583 - val_binary_crossentropy: 0.3363
Epoch 17/20
49/49 - 0s - loss: 0.3010 - accuracy: 0.8788 - binary_crossentropy: 0.3010 - val_loss: 0.3338 - val_accuracy: 0.8570 - val_binary_crossentropy: 0.3338
Epoch 18/20
49/49 - 0s - loss: 0.2975 - accuracy: 0.8824 - binary_crossentropy: 0.2975 - val_loss: 0.3343 - val_accuracy: 0.8564 - val_binary_crossentropy: 0.3343
Epoch 19/20
49/49 - 0s - loss: 0.2923 - accuracy: 0.8823 - binary_crossentropy: 0.2923 - val_loss: 0.3417 - val_accuracy: 0.8556 - val_binary_crossentropy: 0.3417
Epoch 20/20
49/49 - 0s - loss: 0.2910 - accuracy: 0.8830 - binary_crossentropy: 0.2910 - val_loss: 0.3452 - val_accuracy: 0.8560 - val_binary_crossentropy: 0.3452</code></pre><p>ê²€ì¦ ê³ ê³ </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'dropout'</span>, dpt_history)</span><br><span class="line">             ])</span><br></pre></td></tr></table></figure>


<img width="947" alt="output_25_0" src="https://user-images.githubusercontent.com/59719711/91168597-db1faa80-e710-11ea-832a-55d34038d224.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'dropout'</span>, dpt_history),</span><br><span class="line">              (<span class="string">'L2'</span>, l2_history)</span><br><span class="line">             ])</span><br></pre></td></tr></table></figure>


<img width="947" alt="output_26_0" src="https://user-images.githubusercontent.com/59719711/91168603-dd820480-e710-11ea-8916-4ba873e21636.png">


<h6 id="ê³¼ëŒ€ì í•©ì„-ë°©ì§€í•˜ê¸°-ìœ„í•œ-ê²°ë¡ "><a href="#ê³¼ëŒ€ì í•©ì„-ë°©ì§€í•˜ê¸°-ìœ„í•œ-ê²°ë¡ " class="headerlink" title="ê³¼ëŒ€ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²°ë¡ "></a>ê³¼ëŒ€ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ê²°ë¡ </h6><pre><code>1. ë” ë§ì€ í›ˆë ¨ ë°ì´í„°ë¥¼ í•™ìŠµì‹œí‚¨ë‹¤.
2. ë„¤íŠ¸ì›Œí¬ì˜ ìš©ëŸ‰ì„ ì¤„ì¸ë‹¤. (ex. Dense(16 ..)
3. ê°€ì¤‘ì¹˜ ê·œì œë¥¼ ì¶”ê°€í•œë‹¤. (L2)
4. ë“œë¡­ì•„ì›ƒì„ ì¶”ê°€í•œë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-21T06:29:24.000Z" title="2020-08-21T06:29:24.000Z">2020-08-21</time><span class="level-item">9 minutes read (About 1383 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/21/Tensorflow%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8%EB%A7%81/">Tensorflowë¥¼ í™œìš©í•œ íšŒê·€ ëª¨ë¸ë§</a></h1><div class="content"><h6 id="ìë™ì°¨-ì—°ë¹„-ì˜ˆì¸¡í•˜ê¸°"><a href="#ìë™ì°¨-ì—°ë¹„-ì˜ˆì¸¡í•˜ê¸°" class="headerlink" title="ìë™ì°¨ ì—°ë¹„ ì˜ˆì¸¡í•˜ê¸°"></a>ìë™ì°¨ ì—°ë¹„ ì˜ˆì¸¡í•˜ê¸°</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pathlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"></span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>2.4.0-dev20200724</code></pre><h6 id="Auto-MPG-ë°ì´í„°ì…‹"><a href="#Auto-MPG-ë°ì´í„°ì…‹" class="headerlink" title="Auto MPG ë°ì´í„°ì…‹"></a>Auto MPG ë°ì´í„°ì…‹</h6><pre><code>UCI ë¨¸ì‹ ëŸ¬ë‹ ì €ì¥ì†Œì—ì„œ ë‹¤ìš´ë¡œë“œë¥¼ ë°›ì!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dataset_path = keras.utils.get_file(<span class="string">"auto-mpg.data"</span>, <span class="string">"http://archive.ics.uci.edu/ml/\</span></span><br><span class="line"><span class="string">                                    machine-learning-databases/auto-mpg/auto-mpg.data"</span>)</span><br><span class="line">dataset_path</span><br></pre></td></tr></table></figure>




<pre><code>&apos;/Users/wglee/.keras/datasets/auto-mpg.data&apos;</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°</span></span><br><span class="line">column_names = [<span class="string">'MPG'</span>, <span class="string">'Cylinders'</span>, <span class="string">'Displacement'</span>, <span class="string">'Horsepwer'</span>, <span class="string">'Weight'</span>, <span class="string">'Acceleration'</span>,\</span><br><span class="line">               <span class="string">'Model_year'</span>, <span class="string">'Origin'</span>]</span><br><span class="line"></span><br><span class="line">dataset = pd.read_csv(dataset_path, names=column_names, na_values=<span class="string">'?'</span>, comment=<span class="string">'\t'</span>, sep=<span class="string">' '</span>,\</span><br><span class="line">                     skipinitialspace=<span class="literal">True</span>)</span><br><span class="line">df = dataset.copy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.tail(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MPG</th>
      <th>Cylinders</th>
      <th>Displacement</th>
      <th>Horsepwer</th>
      <th>Weight</th>
      <th>Acceleration</th>
      <th>Model_year</th>
      <th>Origin</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>396</th>
      <td>28.0</td>
      <td>4</td>
      <td>120.0</td>
      <td>79.0</td>
      <td>2625.0</td>
      <td>18.6</td>
      <td>82</td>
      <td>1</td>
    </tr>
    <tr>
      <th>397</th>
      <td>31.0</td>
      <td>4</td>
      <td>119.0</td>
      <td>82.0</td>
      <td>2720.0</td>
      <td>19.4</td>
      <td>82</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'Origin'</span>].unique()</span><br></pre></td></tr></table></figure>




<pre><code>array([1, 3, 2])



nullê°’ í™•ì¸ ê²°ê³¼ 6ê°œì˜ ë°ì´í„°ê°€ ëˆ„ë½ëœ ê²ƒì„ í™•ì¸í•˜ì˜€ê³  ì œê±° ì •ì œ ì‘ì—…ì„ í•˜ì˜€ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.isnull().sum()</span><br></pre></td></tr></table></figure>




<pre><code>MPG             0
Cylinders       0
Displacement    0
Horsepwer       6
Weight          0
Acceleration    0
Model_year      0
Origin          0
dtype: int64</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.dropna(inplace=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> missingno <span class="keyword">as</span> msno</span><br><span class="line">msno.matrix(df, figsize=(<span class="number">8</span>, <span class="number">2</span>))</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7faaa5864f10&gt;</code></pre><img width="512" alt="output_10_1" src="https://user-images.githubusercontent.com/59719711/90860004-345fa500-e3c4-11ea-955f-87703c4be123.png">


<pre><code>&quot;Origin&quot; ì—´ì€ ìˆ˜ì¹˜í˜•ì´ ì•„ë‹ˆê³  ë²”ì£¼í˜•ì´ë¯€ë¡œ ì›-í•« ì¸ì½”ë”©(one-hot encoding)ìœ¼ë¡œ ë³€í™˜</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">origin = df.pop(<span class="string">'Origin'</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df[<span class="string">'USA'</span>] = (origin == <span class="number">1</span>) * <span class="number">1.0</span></span><br><span class="line">df[<span class="string">'Europe'</span>] = (origin == <span class="number">2</span>) * <span class="number">2.0</span></span><br><span class="line">df[<span class="string">'Japan'</span>] = (origin == <span class="number">3</span>) * <span class="number">3.0</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.tail(<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MPG</th>
      <th>Cylinders</th>
      <th>Displacement</th>
      <th>Horsepwer</th>
      <th>Weight</th>
      <th>Acceleration</th>
      <th>Model_year</th>
      <th>USA</th>
      <th>Europe</th>
      <th>Japan</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>396</th>
      <td>28.0</td>
      <td>4</td>
      <td>120.0</td>
      <td>79.0</td>
      <td>2625.0</td>
      <td>18.6</td>
      <td>82</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>397</th>
      <td>31.0</td>
      <td>4</td>
      <td>119.0</td>
      <td>82.0</td>
      <td>2720.0</td>
      <td>19.4</td>
      <td>82</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>ë°ì´í„°ì…‹ ë¶„ë¦¬ (train, test)</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_df = df.sample(frac=<span class="number">0.7</span>, random_state=<span class="number">0</span>)</span><br><span class="line">test_df = df.drop(train_df.index)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(train_df)</span><br></pre></td></tr></table></figure>




<pre><code>274



ë°ì´í„° EDAë¥¼ í†µí•´ ë°ì´í„°ì˜ ë¶„í¬ ë° í†µê³„ì¹˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.pairplot(train_df[[<span class="string">'MPG'</span>,<span class="string">'Cylinders'</span>,<span class="string">'Displacement'</span>,<span class="string">'Weight'</span>]], diag_kind=<span class="string">'kde'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>



<img width="746" alt="output_19_0" src="https://user-images.githubusercontent.com/59719711/90860062-50634680-e3c4-11ea-8688-798c5f6557e7.png">





<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">train_stats = train_df.describe()</span><br><span class="line"><span class="comment"># train_stats.pop("MPG")</span></span><br><span class="line">train_stats = train_stats.T <span class="comment">#transpose</span></span><br><span class="line">train_stats</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>count</th>
      <th>mean</th>
      <th>std</th>
      <th>min</th>
      <th>25%</th>
      <th>50%</th>
      <th>75%</th>
      <th>max</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MPG</th>
      <td>274.0</td>
      <td>23.323358</td>
      <td>7.643458</td>
      <td>10.0</td>
      <td>17.0</td>
      <td>22.0</td>
      <td>29.000</td>
      <td>46.6</td>
    </tr>
    <tr>
      <th>Cylinders</th>
      <td>274.0</td>
      <td>5.467153</td>
      <td>1.690530</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>8.000</td>
      <td>8.0</td>
    </tr>
    <tr>
      <th>Displacement</th>
      <td>274.0</td>
      <td>193.846715</td>
      <td>102.402201</td>
      <td>68.0</td>
      <td>105.0</td>
      <td>151.0</td>
      <td>260.000</td>
      <td>455.0</td>
    </tr>
    <tr>
      <th>Horsepwer</th>
      <td>274.0</td>
      <td>104.135036</td>
      <td>37.281034</td>
      <td>46.0</td>
      <td>76.0</td>
      <td>93.0</td>
      <td>128.000</td>
      <td>225.0</td>
    </tr>
    <tr>
      <th>Weight</th>
      <td>274.0</td>
      <td>2976.879562</td>
      <td>829.860536</td>
      <td>1649.0</td>
      <td>2250.5</td>
      <td>2822.5</td>
      <td>3573.000</td>
      <td>4997.0</td>
    </tr>
    <tr>
      <th>Acceleration</th>
      <td>274.0</td>
      <td>15.590876</td>
      <td>2.714719</td>
      <td>8.0</td>
      <td>14.0</td>
      <td>15.5</td>
      <td>17.275</td>
      <td>24.8</td>
    </tr>
    <tr>
      <th>Model_year</th>
      <td>274.0</td>
      <td>75.934307</td>
      <td>3.685839</td>
      <td>70.0</td>
      <td>73.0</td>
      <td>76.0</td>
      <td>79.000</td>
      <td>82.0</td>
    </tr>
    <tr>
      <th>USA</th>
      <td>274.0</td>
      <td>0.635036</td>
      <td>0.482301</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>1.000</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>Europe</th>
      <td>274.0</td>
      <td>0.335766</td>
      <td>0.748893</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>Japan</th>
      <td>274.0</td>
      <td>0.591241</td>
      <td>1.195564</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.000</td>
      <td>3.0</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>ì´ë²ˆì—ëŠ” train, test ë¶„ë¦¬ê°€ ì•„ë‹ˆë¼ featureì™€ labelë¥¼ ë¶„ë¦¬ì‹œì¼œ ì¤ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_labels = train_df[<span class="string">'MPG'</span>]</span><br><span class="line">test_labels = test_df[<span class="string">'MPG'</span>]</span><br></pre></td></tr></table></figure>

<h6 id="ë°ì´í„°-ì •ê·œí™”"><a href="#ë°ì´í„°-ì •ê·œí™”" class="headerlink" title="ë°ì´í„° ì •ê·œí™”"></a>ë°ì´í„° ì •ê·œí™”</h6><pre><code>featureì˜ í¬ê¸°ì™€ ë²”ìœ„ê°€ ë‹¤ë¥´ë©´ ì •ê·œí™”(normalization)ë¥¼ í•˜ëŠ” ê²ƒì´ ê¶Œì¥ë©ë‹ˆë‹¤. ì •ê·œí™”ë¥¼ í•˜ì§€ ì•Šì•„ë„ ëª¨ë¸ë§ì´ ê°€ëŠ¥í•˜ì§€ë§Œ í›ˆë ¨ì‹œí‚¤ê¸° ì–´ë µê³  ì…ë ¥ ë‹¨ìœ„ì— ì˜ì¡´ì ì¸ ëª¨ë¸ì´ ë§Œë“¤ì–´ì§€ê²Œ ë©ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># # ë°ì´í„° ì •ê·œí™”</span></span><br><span class="line"><span class="comment"># from sklearn.preprocessing import StandardScaler</span></span><br><span class="line"><span class="comment"># scaler = StandardScaler()</span></span><br><span class="line"><span class="comment"># train_df = scaler.fit_transform(train_df)</span></span><br><span class="line"><span class="comment"># test_df = scaler.fit_transform(test_df)</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">norm</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> (x - train_stats[<span class="string">'mean'</span>]) / train_stats[<span class="string">'std'</span>]</span><br><span class="line">normed_train_data = norm(train_df)</span><br><span class="line">normed_test_data = norm(test_df)</span><br></pre></td></tr></table></figure>

<h6 id="ëª¨ë¸ë§"><a href="#ëª¨ë¸ë§" class="headerlink" title="ëª¨ë¸ë§"></a>ëª¨ë¸ë§</h6><pre><code>ëª¨ë¸ì„ êµ¬ì„±í•´ ë³´ì£ . ì—¬ê¸°ì—ì„œëŠ” ë‘ ê°œì˜ ì™„ì „ ì—°ê²°(densely connected) ì€ë‹‰ì¸µìœ¼ë¡œ Sequential ëª¨ë¸ì„ ë§Œë“¤ê² ìŠµë‹ˆë‹¤. ì¶œë ¥ ì¸µì€ í•˜ë‚˜ì˜ ì—°ì†ì ì¸ ê°’ì„ ë°˜í™˜í•©ë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‘ ë²ˆì§¸ ëª¨ë¸ì„ ë§Œë“¤ê¸° ì‰½ë„ë¡ build_model í•¨ìˆ˜ë¡œ ëª¨ë¸ êµ¬ì„± ë‹¨ê³„ë¥¼ ê°ì‹¸ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ëª¨ë¸ë§</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_model</span><span class="params">()</span>:</span></span><br><span class="line">    model = keras.Sequential([</span><br><span class="line">        layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>, input_shape=[len(train_df.keys())]),</span><br><span class="line">        layers.Dense(<span class="number">64</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">        layers.Dense(<span class="number">1</span>)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    optimizer = tf.keras.optimizers.RMSprop(<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    model.compile(loss=<span class="string">'mse'</span>,</span><br><span class="line">                optimizer=optimizer,</span><br><span class="line">                metrics=[<span class="string">'mae'</span>, <span class="string">'mse'</span>])</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = build_model()</span><br></pre></td></tr></table></figure>

<h6 id="ëª¨ë¸-í™•ì¸"><a href="#ëª¨ë¸-í™•ì¸" class="headerlink" title="ëª¨ë¸ í™•ì¸"></a>ëª¨ë¸ í™•ì¸</h6><pre><code>.summary() ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì˜ ê°„ë‹¨í•œ ì •ë³´ë¥¼ ì¶œë ¥í•´ì¤ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(model.summary())</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_15&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_45 (Dense)             (None, 128)               1408      
_________________________________________________________________
dense_46 (Dense)             (None, 64)                8256      
_________________________________________________________________
dense_47 (Dense)             (None, 1)                 65        
=================================================================
Total params: 9,729
Trainable params: 9,729
Non-trainable params: 0
_________________________________________________________________
None


ëª¨ë¸ì„ í•œë²ˆ ì‹¤í–‰í•´ ë³´ì£ . training ì„¸íŠ¸ì—ì„œ 10ê°œì˜ ìƒ˜í”Œì„ í•˜ë‚˜ì˜ ë°°ì¹˜ë¡œ ë§Œë“¤ì–´ model_predict ë©”ì„œë“œë¥¼ í˜¸ì¶œí•´ ë³´ê² ìŠµë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">example_batch = normed_train_data[:<span class="number">10</span>]</span><br><span class="line">example_result = model.predict(example_batch)</span><br><span class="line">example_result</span><br></pre></td></tr></table></figure>

<pre><code>WARNING:tensorflow:5 out of the last 15 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x7faa9a8f0200&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.





array([[-0.03285253],
       [-0.01362434],
       [-0.48285854],
       [ 0.01581845],
       [ 0.08219826],
       [ 0.08362657],
       [ 0.15519306],
       [ 0.28581452],
       [ 0.07680693],
       [ 0.01200353]], dtype=float32)</code></pre><h6 id="ëª¨ë¸-í›ˆë ¨"><a href="#ëª¨ë¸-í›ˆë ¨" class="headerlink" title="ëª¨ë¸ í›ˆë ¨"></a>ëª¨ë¸ í›ˆë ¨</h6><pre><code>ì—í¬í¬ê°€ ëë‚  ë•Œë§ˆë‹¤ ì (.)ì„ ì¶œë ¥í•´ í›ˆë ¨ ì§„í–‰ ê³¼ì •ì„ í‘œì‹œí•©ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrintDot</span><span class="params">(keras.callbacks.Callback)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_epoch_end</span><span class="params">(self, epoch, logs)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>: print(<span class="string">''</span>)</span><br><span class="line">        print(<span class="string">'.'</span>, end=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">EPOCHS = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">history = model.fit(</span><br><span class="line">  normed_train_data, train_labels,</span><br><span class="line">  epochs=EPOCHS, validation_split = <span class="number">0.2</span>, verbose=<span class="number">0</span>,</span><br><span class="line">  callbacks=[PrintDot()])</span><br></pre></td></tr></table></figure>


<pre><code>....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................
....................................................................................................

acc : í›ˆë ¨ ì •í™•ë„
loss : í›ˆë ¨ ì†ì‹¤ê°’
val_acc : ê²€ì¦ ì •í™•ë„
val_loss : ê²€ì¦ ì†ì‹¤ê°’</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hist = pd.DataFrame(history.history)</span><br><span class="line">hist[<span class="string">'epoch'</span>] = history.epoch</span><br><span class="line">hist.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>loss</th>
      <th>mae</th>
      <th>mse</th>
      <th>accuracy</th>
      <th>val_loss</th>
      <th>val_mae</th>
      <th>val_mse</th>
      <th>val_accuracy</th>
      <th>epoch</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>995</th>
      <td>0.102436</td>
      <td>0.234032</td>
      <td>0.102436</td>
      <td>0.0</td>
      <td>0.165683</td>
      <td>0.324213</td>
      <td>0.165683</td>
      <td>0.0</td>
      <td>995</td>
    </tr>
    <tr>
      <th>996</th>
      <td>0.124358</td>
      <td>0.292103</td>
      <td>0.124358</td>
      <td>0.0</td>
      <td>0.263786</td>
      <td>0.404004</td>
      <td>0.263786</td>
      <td>0.0</td>
      <td>996</td>
    </tr>
    <tr>
      <th>997</th>
      <td>0.130789</td>
      <td>0.295300</td>
      <td>0.130789</td>
      <td>0.0</td>
      <td>0.212862</td>
      <td>0.362374</td>
      <td>0.212862</td>
      <td>0.0</td>
      <td>997</td>
    </tr>
    <tr>
      <th>998</th>
      <td>0.116644</td>
      <td>0.275093</td>
      <td>0.116644</td>
      <td>0.0</td>
      <td>0.054454</td>
      <td>0.196261</td>
      <td>0.054454</td>
      <td>0.0</td>
      <td>998</td>
    </tr>
    <tr>
      <th>999</th>
      <td>0.106241</td>
      <td>0.280440</td>
      <td>0.106241</td>
      <td>0.0</td>
      <td>0.121306</td>
      <td>0.281089</td>
      <td>0.121306</td>
      <td>0.0</td>
      <td>999</td>
    </tr>
  </tbody>
</table>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_history</span><span class="params">(history)</span>:</span></span><br><span class="line">       </span><br><span class="line">    hist = pd.DataFrame(history.history)</span><br><span class="line">    hist[<span class="string">'epoch'</span>] = history.epoch</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">8</span>,<span class="number">8</span>))</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">1</span>)</span><br><span class="line">    plt.plot(hist[<span class="string">'epoch'</span>], hist[<span class="string">'mae'</span>], label=<span class="string">'Train Error'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Mean Abs Error [MPG]'</span>)</span><br><span class="line">    plt.plot(hist[<span class="string">'epoch'</span>], hist[<span class="string">'val_mae'</span>],</span><br><span class="line">             label = <span class="string">'Val Error'</span>)</span><br><span class="line">    plt.ylim([<span class="number">0</span>,<span class="number">5</span>])</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    plt.subplot(<span class="number">2</span>,<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Epoch'</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Mean Square Error [$MPG^2$]'</span>)</span><br><span class="line">    plt.plot(hist[<span class="string">'epoch'</span>], hist[<span class="string">'mse'</span>],</span><br><span class="line">             label=<span class="string">'Train Error'</span>)</span><br><span class="line">    plt.plot(hist[<span class="string">'epoch'</span>], hist[<span class="string">'val_mse'</span>],</span><br><span class="line">             label = <span class="string">'Val Error'</span>)</span><br><span class="line">    plt.ylim([<span class="number">0</span>,<span class="number">20</span>])</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line">plot_history(history)</span><br></pre></td></tr></table></figure>


<img width="512" alt="output_37_0" src="https://user-images.githubusercontent.com/59719711/90860211-94eee200-e3c4-11ea-8673-4330f5325b81.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">model = build_model()</span><br><span class="line"></span><br><span class="line"><span class="comment"># patience ë§¤ê°œë³€ìˆ˜ëŠ” ì„±ëŠ¥ í–¥ìƒì„ ì²´í¬í•  ì—í¬í¬ íšŸìˆ˜ì…ë‹ˆë‹¤</span></span><br><span class="line">early_stop = keras.callbacks.EarlyStopping(monitor=<span class="string">'val_loss'</span>, patience=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,</span><br><span class="line">                    validation_split = <span class="number">0.2</span>, verbose=<span class="number">0</span>, callbacks=[early_stop, PrintDot()])</span><br><span class="line"></span><br><span class="line">plot_history(history)</span><br></pre></td></tr></table></figure>


<pre><code>......................................................................................</code></pre><img width="512" alt="output_38_1" src="https://user-images.githubusercontent.com/59719711/90860253-a33cfe00-e3c4-11ea-8a43-e8074c908d64.png">


<h6 id="ëª¨ë¸-ê²€ì¦"><a href="#ëª¨ë¸-ê²€ì¦" class="headerlink" title="ëª¨ë¸ ê²€ì¦"></a>ëª¨ë¸ ê²€ì¦</h6><pre><code>í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ëª¨ë¸ ì„±ëŠ¥ì„ í™•ì¸</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨: &#123;:5.2f&#125; MPG"</span>.format(mae))</span><br></pre></td></tr></table></figure>

<pre><code>4/4 - 0s - loss: 0.4875 - mae: 0.5579 - mse: 0.4875
í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨:  0.56 MPG</code></pre><h6 id="ì˜ˆì¸¡"><a href="#ì˜ˆì¸¡" class="headerlink" title="ì˜ˆì¸¡"></a>ì˜ˆì¸¡</h6><pre><code>í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ìˆëŠ” ìƒ˜í”Œì„ ì´ìš©í•´ MPG ê°’ ì˜ˆì¸¡</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">test_predictions = model.predict(normed_test_data).flatten()</span><br><span class="line"></span><br><span class="line">plt.scatter(test_labels, test_predictions)</span><br><span class="line">plt.xlabel(<span class="string">'True Values [MPG]'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'Predictions [MPG]'</span>)</span><br><span class="line">plt.axis(<span class="string">'equal'</span>)</span><br><span class="line">plt.axis(<span class="string">'square'</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>,plt.xlim()[<span class="number">1</span>]])</span><br><span class="line">plt.ylim([<span class="number">0</span>,plt.ylim()[<span class="number">1</span>]])</span><br><span class="line">_ = plt.plot([<span class="number">-100</span>, <span class="number">100</span>], [<span class="number">-100</span>, <span class="number">100</span>])</span><br></pre></td></tr></table></figure>


<img width="260" alt="output_42_0" src="https://user-images.githubusercontent.com/59719711/90860297-b780fb00-e3c4-11ea-8c8a-709eb6725538.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">error = test_predictions - test_labels</span><br><span class="line">plt.hist(error, bins = <span class="number">25</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Prediction Error [MPG]"</span>)</span><br><span class="line">_ = plt.ylabel(<span class="string">"Count"</span>)</span><br></pre></td></tr></table></figure>


<img width="386" alt="output_43_0" src="https://user-images.githubusercontent.com/59719711/90860330-c5368080-e3c4-11ea-9a6c-79c1fd8fd89c.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-12T12:06:35.000Z" title="2020-08-12T12:06:35.000Z">2020-08-12</time><span class="level-item">4 minutes read (About 530 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/08/12/%E1%84%80%E1%85%AE%E1%84%80%E1%85%B3%E1%86%AF-%E1%84%8C%E1%85%B5%E1%84%8B%E1%85%A9%E1%84%8F%E1%85%A9%E1%84%83%E1%85%B5%E1%86%BC-API-%E1%84%8F%E1%85%B5-%E1%84%87%E1%85%A1%E1%86%AF%E1%84%80%E1%85%B3%E1%86%B8-%E1%84%87%E1%85%A1%E1%86%AE%E1%84%82%E1%85%B3%E1%86%AB-%E1%84%87%E1%85%A1%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8-How-to-be-issued-the-Geocoding-API-key-from-Google/">êµ¬ê¸€ ì§€ì˜¤ì½”ë”© API í‚¤ ë°œê¸‰ ë°›ëŠ” ë°©ë²• (How to be issued the Geocoding API key from Google)</a></h1><div class="content"><pre><code>ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ì€ êµ¬ê¸€ ë§µ ìœ„, ìœ„ì¹˜ì— ë§ˆì»¤ë¥¼ ì°ì–´ ì§€ë„ ìƒ ìœ„ì¹˜ë¥¼ í•œëˆˆì— ì‰½ê²Œ ì•Œì•„ë³´ê¸° ìœ„í•œ GPS ì¢Œí‘œì— ëŒ€í•œ ë¶€ë¶„ì„ ì•Œì•„ë³´ë ¤ê³  í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì“°ì´ëŠ” ì£¼ì†Œ(ì„œìš¸íŠ¹ë³„ì‹œ ì¢…ë¡œêµ¬ ....)ì™€ GPS ì¢Œí‘œë¥¼ ì„œë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ êµ¬ê¸€ì—ì„œ Geocoding APIë¥¼ ì œê³µí•˜ê³  ìˆìŠµë‹ˆë‹¤. 

Geocoding API ì‚¬ìš© ì„¤ì •ê³¼ API í‚¤ ë°œê¸‰ ê³¼ì •ì— ëŒ€í•´ì„œ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤. ê³¼ì •ì€ ì¡°ê¸ˆ ë³µì¡í•  ìˆ˜ë„ ìˆê¸°ì§€ë§Œ ì‰½ê²Œ ë”°ë¼ í•˜ì‹¤ ìˆ˜ ìˆë„ë¡ ìì„¸íˆ ì„¤ëª…í•´ë³´ê² ìŠµë‹ˆë‹¤.</code></pre><h6 id="1-êµ¬ê¸€-í´ë¼ìš°ë“œ-ì½˜ì†”-ì‚¬ì´íŠ¸ì—-ë°©ë¬¸"><a href="#1-êµ¬ê¸€-í´ë¼ìš°ë“œ-ì½˜ì†”-ì‚¬ì´íŠ¸ì—-ë°©ë¬¸" class="headerlink" title="1. êµ¬ê¸€ í´ë¼ìš°ë“œ ì½˜ì†” ì‚¬ì´íŠ¸ì— ë°©ë¬¸"></a>1. êµ¬ê¸€ í´ë¼ìš°ë“œ ì½˜ì†” ì‚¬ì´íŠ¸ì— ë°©ë¬¸</h6><pre><code>ì•„ë˜ ë§í¬ë¥¼ í´ë¦­í•´ êµ¬ê¸€ ì§€ë„ í”Œë«í¼ ì‚¬ì´íŠ¸ë¡œ ì ‘ì†í•´ì£¼ì„¸ìš”.

https://cloud.google.com/maps-platform/

êµ¬ê¸€ ì§€ë„ í”Œë«í¼ ì‚¬ì´íŠ¸ì—ì„œ â€œì‹œì‘í•˜ê¸°â€ í˜¹ì€ â€œì½˜ì†”â€ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê³„ì† ì§„í–‰í•´ì£¼ì„¸ìš”.</code></pre><h6 id="2-ìƒˆ-í”„ë¡œì íŠ¸ë¥¼-ë§Œë“¤ê¸°"><a href="#2-ìƒˆ-í”„ë¡œì íŠ¸ë¥¼-ë§Œë“¤ê¸°" class="headerlink" title="2. ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ê¸°"></a>2. ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ë§Œë“¤ê¸°</h6><pre><code>í”„ë¡œì íŠ¸ ì„ íƒ -&gt; ìƒˆ í”„ë¡œì íŠ¸ ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”.</code></pre><img width="821" alt="1á„‡á…¥á†«" src="https://user-images.githubusercontent.com/59719711/90012853-208ab380-dcdf-11ea-854c-3ffe24075d9a.png">

<h6 id="3-API-ì‚¬ìš©-ì„¤ì •í•˜ê¸°"><a href="#3-API-ì‚¬ìš©-ì„¤ì •í•˜ê¸°" class="headerlink" title="3. API ì‚¬ìš© ì„¤ì •í•˜ê¸°"></a>3. API ì‚¬ìš© ì„¤ì •í•˜ê¸°</h6><pre><code>í”„ë¡œì íŠ¸ë¥¼ ë§Œë“  í›„ ì´ì œ ì‚¬ìš©í•  APIë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.

êµ¬ê¸€ í´ë¼ìš°ë“œ í”Œë«í¼ì˜ API ë° ì„œë¹„ìŠ¤ -&gt; ë¼ì´ë¸ŒëŸ¬ë¦¬ ë©”ë‰´ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.</code></pre><img width="818" alt="3á„‡á…¥á†«" src="https://user-images.githubusercontent.com/59719711/90012912-3e581880-dcdf-11ea-8a99-4b0074cf833a.png">

<pre><code>ê²€ìƒ‰ì°½ì— â€œGeocoding APIâ€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.

í´ë¦­!!!!!</code></pre><img width="824" alt="4á„‡á…¥á†«" src="https://user-images.githubusercontent.com/59719711/90012963-4fa12500-dcdf-11ea-8901-07c4aa5e08d1.png">

<pre><code>Geocoding APIì˜ â€œì‚¬ìš© ì„¤ì •â€ ë²„íŠ¼ì„ í´ë¦­í•´ì£¼ì„¸ìš”.</code></pre><img width="816" alt="5á„‡á…¥á†«" src="https://user-images.githubusercontent.com/59719711/90012987-5a5bba00-dcdf-11ea-8d42-e748d9d8d6dc.png">

<h6 id="4-ì‚¬ìš©ì-ì¸ì¦-ì •ë³´-ë§Œë“¤ê¸°"><a href="#4-ì‚¬ìš©ì-ì¸ì¦-ì •ë³´-ë§Œë“¤ê¸°" class="headerlink" title="4. ì‚¬ìš©ì ì¸ì¦ ì •ë³´ ë§Œë“¤ê¸°"></a>4. ì‚¬ìš©ì ì¸ì¦ ì •ë³´ ë§Œë“¤ê¸°</h6><pre><code>ì´ì œ ìì‹ ì˜ API í‚¤ë¥¼ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

êµ¬ê¸€ í´ë¼ìš°ë“œ í”Œë«í¼ì˜ API ë° ì„œë¹„ìŠ¤ -&gt; ì‚¬ìš©ì ì¸ì¦ ì •ë³´ ë©”ë‰´ë¡œ ì´ë™í•´ì£¼ì„¸ìš”.</code></pre><img width="821" alt="6á„‡á…¥á†«" src="https://user-images.githubusercontent.com/59719711/90013001-647db880-dcdf-11ea-9bb0-d9c45b430473.png">

<pre><code>ì‚¬ìš©ì ì¸ì¦ ì •ë³´ ë§Œë“¤ê¸° -&gt; API í‚¤ ì„ íƒ</code></pre><p>6ë²ˆ</p>
<h6 id="5-API-í‚¤-ë°œê¸‰-ì™„ë£Œ"><a href="#5-API-í‚¤-ë°œê¸‰-ì™„ë£Œ" class="headerlink" title="5. API í‚¤ ë°œê¸‰ ì™„ë£Œ"></a>5. API í‚¤ ë°œê¸‰ ì™„ë£Œ</h6><pre><code>ì´ì œ API í‚¤ë¥¼ ë³µì‚¬í•´ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</code></pre><ul>
<li>í‚¤ ì œí•œì˜ ê²½ìš° ì†Œì¤‘í•œ ìì‹ ì˜ API KEYë¥¼ ì•„ë¬´ë‚˜ í•¨ë¶€ë¡œ ì“¸ ìˆ˜ ì—†ë„ë¡ í•˜ëŠ” ì„¤ì •ì…ë‹ˆë‹¤. ì„¤ì •ì„ ì•ˆí•´ë„ KEYëŠ” ì„¤ì •ì´ ê°€ëŠ¥í•˜ì§€ë§Œ ì œí•œì„ ê±°ëŠ” ê²ƒì„ ì¶”ì²œë“œë¦½ë‹ˆë‹¤.</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-07-24T05:54:01.000Z" title="2020-07-24T05:54:01.000Z">2020-07-24</time><span class="level-item">a minute read (About 151 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/07/24/MySQL-Ubuntu%EC%97%90%EC%84%9C-MySQL-%EC%99%84%EC%A0%84-%EC%82%AD%EC%A0%9C%ED%95%98%EA%B8%B0/">[MySQL] Ubuntuì—ì„œ MySQL ì™„ì „ ì‚­ì œí•˜ê¸°</a></h1><div class="content"><pre><code>MySQL Workbenchë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ í™˜ê²½ì„ ì„¤ì •í•˜ê³  ì‘ì—… ê³¼ì •ì—ì„œ ì‹œìŠ¤í…œ ê³„ì •ì„ ì‚­ì œí•˜ëŠ”(?) ì•„ì£¼ í° ë¬¸ì œê°€ ìƒê²¨ì„œ ì‚¬ìš©ì ìƒì„± ë“± ë‹¤ì–‘í•œ ì‹œë„ë¥¼ í•´ë´¤ì§€ë§Œ ë­”ê°€ ê¼¬ì¸ê²ƒ ê°™ì€ ëŠë‚Œì´ ë“¤ì—ˆë‹¤.


Mysqlì„ ì‚­ì œí•˜ê³  ì¬ì„¤ì¹˜ê°€ í•„ìš”í• ë“¯ í•˜ì—¬ ì¬ì„¤ì¹˜ ë°©ë²•ì„ í¬ìŠ¤íŒ… í•˜ê³ ì í•œë‹¤.


ì•„ë˜ì˜ ëª…ë ¹ì–´ë¥¼ ì°¸ê³ í•˜ì.</code></pre><h6 id="Mysql"><a href="#Mysql" class="headerlink" title="[Mysql]"></a>[Mysql]</h6><pre><code>sudo apt-get purge mysql-server
sudo apt-get purge mysql-common


sudo rm -rf /var/log/mysql
sudo rm -rf /var/log/mysql.*
sudo rm -rf /var/lib/mysql
sudo rm -rf /etc/mysql</code></pre></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-07-23T10:24:00.000Z" title="2020-07-23T10:24:00.000Z">2020-07-23</time><span class="level-item">4 minutes read (About 604 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/07/23/MySQL-workbench%E1%84%8B%E1%85%A6%E1%84%89%E1%85%A5-ERD%E1%84%90%E1%85%AE%E1%86%AF-%E1%84%89%E1%85%A1%E1%84%8B%E1%85%AD%E1%86%BC%E1%84%92%E1%85%A1%E1%84%80%E1%85%B5-Database-Modeling/">[mysql] workbenchì—ì„œ ERDíˆ´ ì‚¬ìš©í•˜ê¸° (Database Modeling)</a></h1><div class="content"><h6 id="ë°ì´í„°ë² ì´ìŠ¤-ëª¨ë¸ë§-Database-Modeling"><a href="#ë°ì´í„°ë² ì´ìŠ¤-ëª¨ë¸ë§-Database-Modeling" class="headerlink" title="ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ë§ (Database Modeling)"></a>ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ë§ (Database Modeling)</h6><p>ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ë§(ë˜ëŠ” ë°ì´í„° ëª¨ë¸ë§)ì´ë€ í˜„ì‹¤ ì„¸ê³„ì—ì„œ ì‚¬ìš©ë˜ëŠ” ì‘ì—…ì´ë‚˜ ì‚¬ë¬¼ë“¤ì„ DBMSì˜ ë°ì´í„°ë² ì´ìŠ¤ ê°œì²´ë¡œ ì˜®ê¸°ê¸° ìœ„í•œ ê³¼ì •ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë¸ë§ì€ ëª¨ë¸ë§ì„ í•˜ëŠ” ì‚¬ëŒì´ ì–´ë–¤ ì‚¬ëŒì´ëƒì— ë”°ë¼ì„œ ê°ê¸° ë‹¤ë¥¸ ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ë°–ì— ì—†ê³  â€˜ë§ì€ ì‹¤ë¬´ ê²½í—˜ê³¼ ì§€ì‹ì„ ê°€ì§„ ì‚¬ëŒì´ ë” ì¢‹ì€ ëª¨ë¸ë§ì„ í•œë‹¤â€™ ë¼ê³  í•©ë‹ˆë‹¤.</p>
<p>3ê°€ì§€ì˜ ëª¨ë¸ë§ ë°©ì‹ì´ ìˆë‹¤.<br>    - ê°œë…ì  ëª¨ë¸ë§<br>    - ë…¼ë¦¬ì  ëª¨ë¸ë§<br>    - ë¬¼ë¦¬ì  ëª¨ë¸ë§</p>
<p>ê°œë…ì  ëª¨ë¸ë§ì€ ì£¼ë¡œ ì—…ë¬´ ë¶„ì„ ë‹¨ê³„ì—ì„œ ì§„í–‰ë˜ë©° ë…¼ë¦¬ì  ëª¨ë¸ë§ì€ ì—…ë¬´ ë¶„ì„ì˜ í›„ë°˜ë¶€ì™€ ì‹œìŠ¤í…œ ì„¤ê³„ë¥¼ í•˜ëŠ” ë¶€ë¶„ì— ê±¸ì³ì„œ ì§„í–‰ëœë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ë¬¼ë¦¬ì  ëª¨ë¸ë§ì€ ì‹œìŠ¤í…œ ì„¤ê³„ ë‹¨ê³„ì˜ í›„ë°˜ë¶€ì—ì„œ ì£¼ë¡œ ì§„í–‰ë©ë‹ˆë‹¤.</p>
<p>ê·¸ëŸ¬ë‚˜ ëª¨ë‘ ì ˆëŒ€ì ì¸ ê²ƒì€ ì•„ë‹ˆë©° ì‚¬ëŒì— ë”°ë¼ ì¡°ê¸ˆì”© ì°¨ì´ë¥¼ ë³´ì´ê¸°ë„ í•©ë‹ˆë‹¤.</p>
<p>ì›Œí¬ë²¤ì¹˜ëŠ” ì´ ëª¨ë¸ë§ íˆ´ì„ ì œê³µí•´ì£¼ëŠ”ë° ê·¸ê²ƒì´ ë°”ë¡œ ERDíˆ´ì…ë‹ˆë‹¤.</p>
<h6 id="ERDë€"><a href="#ERDë€" class="headerlink" title="ERDë€?"></a>ERDë€?</h6><p>Entity Relationship Diagramì˜ ì•½ìë¡œ, ê°œì²´ê´€ê³„ë„ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤</p>
<h6 id="ì¥ì "><a href="#ì¥ì " class="headerlink" title="ì¥ì "></a>ì¥ì </h6><ol>
<li>ë§Œë“¤ê³ ì í•˜ëŠ” ë°”ë¥¼ ë” ëª…í™•í•˜ê²Œ ì•Œ ìˆ˜ ìˆë‹¤.</li>
<li>ì´í•´í•˜ê³  ì†Œí†µí•˜ê¸°ì— í¸ë¦¬í•˜ë‹¤.</li>
<li>RDBMS ë°ì´í„° ì„¤ê³„ê°€ ì‰¬ì›Œì§„ë‹¤.</li>
</ol>
<h6 id="ë°ì´í„°ë² ì´ìŠ¤"><a href="#ë°ì´í„°ë² ì´ìŠ¤" class="headerlink" title="ë°ì´í„°ë² ì´ìŠ¤"></a>ë°ì´í„°ë² ì´ìŠ¤</h6><p>ëª¨ë¸ë§ì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ë¥¼ Schemaë¼ê³  ë¶€ë¦…ë‹ˆë‹¤.</p>
<p>ì‹¤ìŠµì„ í•´ë³´ê¸° ì „ì— ERDì— ëŒ€í•´ ì†Œê°œë¥¼ í•˜ì˜€ìŠµë‹ˆë‹¤. ì‹¤ìŠµì€ ì›Œí¬ë²¤ì¹˜ë¥¼ ì‚¬ìš©í•˜ì˜€ê³ . MySQL workbenchëŠ” ì•½ 10ë…„ ì •ë„ ìƒì—…ìš©ìœ¼ë¡œ ê°œë°œë˜ì–´ íŒë§¤ë˜ë‹¤ê°€, MySQLì—ì„œ workbenchë¥¼ ì¸ìˆ˜í•˜ì—¬ ì˜¤í”ˆì†ŒìŠ¤ë¡œ í’€ì—ˆë‹¤ê³  í•©ë‹ˆë‹¤.</p>
<h6 id="ì‹¤ìŠµê³¼ì •"><a href="#ì‹¤ìŠµê³¼ì •" class="headerlink" title="ì‹¤ìŠµê³¼ì •"></a>ì‹¤ìŠµê³¼ì •</h6><ol>
<li>FILE &gt; New Model í´ë¦­<img width="693" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-07-23 á„‹á…©á„’á…® 7 34 11" src="https://user-images.githubusercontent.com/59719711/88279718-80fd8500-cd1f-11ea-8ba7-7a070f7fba37.png">


</li>
</ol>
<ol start="2">
<li>Modelì˜ ì´ë¦„ ì„¤ì •(ì•ˆí•´ë„ ë¨)<img width="1578" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-07-23 á„‹á…©á„’á…® 7 35 06" src="https://user-images.githubusercontent.com/59719711/88279754-8ce94700-cd1f-11ea-9e9f-e443e5efbc2a.png">


</li>
</ol>
<ol start="3">
<li>í…Œì´ë¸” ìƒì„± &gt; í° ë°”íƒ•ì— í´ë¦­ &gt; ì»¬ëŸ¼ ìƒì„±</li>
<li>PKì™€ FK ì„¤ì • (ì„¤ì • ì‹œ place a relationship using existing columns ì„ íƒ &gt; ìì‹í…Œì´ë¸”ì˜ í•´ë‹¹ ì»¬ëŸ¼ ì—´ì„ ë¨¼ì € í´ë¦­ í›„ ë¶€ëª¨í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì—´ í´ë¦­)</li>
<li>ê´€ê³„ ìƒì„±<img width="1567" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-07-23 á„‹á…©á„’á…® 7 36 52" src="https://user-images.githubusercontent.com/59719711/88279797-983c7280-cd1f-11ea-9c2a-17459fb75dfc.png">


</li>
</ol>
<ol start="6">
<li>ì €ì¥ &gt; databaseì˜ forward engineer ì„ íƒ &gt; continue <img width="1147" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2020-07-23 á„‹á…©á„’á…® 7 37 55" src="https://user-images.githubusercontent.com/59719711/88279865-b86c3180-cd1f-11ea-9148-a8040d01949e.png">


</li>
</ol>
<p>ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ë§ì´ ë˜ì–´ ìˆëŠ” dbì™€ table ìƒì„±(refresh all)</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-07-22T13:58:24.000Z" title="2020-07-22T13:58:24.000Z">2020-07-22</time><span class="level-item">8 minutes read (About 1203 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/07/22/MySQL-Storage-Engine-InnoDB-vs-MyISAM/">[MySQL] Storage Engine (InnoDB vs MyISAM)</a></h1><div class="content"><p>ìƒê°ì—†ì´ Engineì„ InnoDBë§Œ ì‚¬ìš©í–ˆì§€ ì™œ ì´ê²ƒì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ì§€ ê³ ë¯¼í•´ë³¸ ì ì´ ì—†ì—ˆë‹¤.</p>
<p>í•˜ì§€ë§Œ ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ì ì¬í•˜ë©´ ë°ì´í„°ì˜ ìˆ˜ê°€ ë§¤ìš° ë§ê±°ë‚˜ columnì˜ ê°¯ìˆ˜ê°€ ë§ì•„ì§€ë©´ ê³µê°„ë¶€ì¡± í˜„ìƒì´ ë‚˜íƒ€ë‚˜ê²Œ ë˜ê³ , ê·¸ë¡œ ì¸í•´ ì—”ì§„ì— ëŒ€í•´ ê³ ë¯¼í•˜ê¸° ì‹œì‘í•˜ì˜€ë‹¤.</p>
<p>ëŒ€ëµ 500ê°œì— ë‹¬í•˜ëŠ” ì¹¼ëŸ¼ì´ í•„ìš”í•œ ìƒí™©ì´ì˜€ë‹¤. ê·¸ë˜ì„œ ì–´ë–»ê²Œ í…Œì´ë¸”ì— ì ì¬í•´ì•¼ íš¨ìœ¨ì ì¸ì§€ ê³ ë¯¼ì´ í•„ìš”í–ˆë‹¤.</p>
<p>ë˜í•œ InnoDB í…Œì´ë¸”ì— ë§ì€ ì¹¼ëŸ¼ì„ ì¶”ê°€í•˜ë‹ˆ Row size too large. ë¼ëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí•´ì„œ Engineì„ ë³€ê²½í•˜ëŠ” ë°©ë²•ì„ ìƒê°í•˜ê²Œ ë˜ì—ˆë‹¤.</p>
<p>ìš°ì„  ê° Stroage Engineì— ëŒ€í•´ ì•Œì•„ë³´ì•˜ë‹¤.</p>
<p>Mysql Storage Engineì€ ë¬¼ë¦¬ì  ì €ì¥ì¥ì¹˜ì—ì„œ ë°ì´í„°ë¥¼ ì–´ë–¤ ì‹ìœ¼ë¡œ êµ¬ì„±í•˜ê³  ì½ì–´ì˜¬ì§€ë¥¼ ê²°ì •í•˜ëŠ” ì—­í• ì„ í•œë‹¤.</p>
<p>ê¸°ë³¸ì ìœ¼ë¡œ 8ê°€ì§€ì˜ ìŠ¤í† ë¦¬ì§€ ì—”ì§„ì´ íƒ‘ì¬ë˜ì–´ ìˆìœ¼ë©° CREATE TABLEë¬¸ì„ ì‚¬ìš©í•˜ì—¬ í…Œì´ë¸”ì„ ìƒì„±í•  ë•Œ ì—”ì§„ ì´ë¦„ì„ ì¶”ê°€í•¨ìœ¼ë¡œì¨ ê°„ë‹¨í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.</p>
<p>ê·¸ ì¤‘ ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ì—”ì§„ì€ InnoDB, MyISAM, Archive 3ê°€ì§€ì´ë‹¤.</p>
<h6 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h6><p>í…Œì´ë¸” ìƒì„± ì‹œ, ë”°ë¡œ ìŠ¤í† ë¦¬ì§€ ì—”ì§„ì„ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ defaultë¡œ ì„¤ì •ë˜ëŠ” ìŠ¤í† ë¦¬ì§€ ì—”ì§„ì´ë‹¤.</p>
<p>InnoDBëŠ” íŠ¸ëœì­ì…˜(tranjection)ì„ ì§€ì›í•˜ê³ , ì»¤ë°‹(commit)ê³¼ ë¡¤ë°±(roll-back) ê·¸ë¦¬ê³  ë°ì´í„° ë³µêµ¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ë¯€ë¡œ ë°ì´í„°ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.</p>
<p>InnoDBëŠ” ê¸°ë³¸ì ìœ¼ë¡œ row-level lockingì„ ì œê³µí•˜ë©°, ë˜í•œ ë°ì´í„°ë¥¼ clustered indexì— ì €ì¥í•˜ì—¬ PKê¸°ë°˜ì˜ queryì˜ ë¹„ìš©ì„ ì¤„ì¸ë‹¤.</p>
<p>ë˜í•œ, PK ì œì•½ì„ ì œê³µí•˜ì—¬ ë°ì´í„° ë¬´ê²°ì„±ì„ ë³´ì¥í•œë‹¤.</p>
<p>ì—¬ê¸°ì„œ clustered indexì— ì €ì¥í•œë‹¤ëŠ” ê²ƒì€ ë°ì´í„°ë¥¼ PKìˆœì„œì— ë§ê²Œ ì €ì¥í•œë‹¤ëŠ” ëœ»ì´ë¯€ë¡œ order by ë“± ì¿¼ë¦¬ì— ìœ ë¦¬í•  ìˆ˜ ìˆë‹¤. ë˜í•œ row-level lockingì„ ì œê³µí•œë‹¤ëŠ” ëœ»ì€ í…Œì´ë¸”ì— CRUDí•  ë•Œ, ë¡œìš°ë³„ë¡œ ë½ì„ ì¡ê¸° ë•Œë¬¸ì— multi-threadì— ë³´ë‹¤ íš¨ìœ¨ì ì´ë¼ëŠ” ë§ì´ë‹¤.</p>
<p>ë¬¼ë¡  ì¥ì ë§Œ ìˆëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤. InnoDBëŠ” ë”ìš± ë§ì€ ë©”ëª¨ë¦¬ì™€ ë””ìŠ¤í¬ë¥¼ ì‚¬ìš©í•œë‹¤. ë˜í•œ ë°ì´í„°ê°€ ê¹¨ì¡Œì„ ë•Œ  ë‹¨ìˆœ íŒŒì¼ ë°±ì—…/ë³µêµ¬ë§Œìœ¼ë¡œ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•œ MyISAMê³¼ ë‹¬ë¦¬ InnoDBì˜ ê²½ìš° ë³µêµ¬ ë°©ë²•ì´ ì–´ë µë‹¤. MyISAMì´ë‚˜ Memory ë°©ì‹ì´ ì§€ì›í•˜ì§€ ì•ŠëŠ” FKì˜ ê²½ìš°ë„ í…Œì´ë¸” ê°„ ë°ì´í„° ì²´í¬ë¡œ ì¸í•œ lock, íŠ¹íˆ dead lockì´ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ìˆë‹¤.</p>
<h6 id="InnoDBì˜-ìµœëŒ€-í–‰-ì €ì¥ê³µê°„"><a href="#InnoDBì˜-ìµœëŒ€-í–‰-ì €ì¥ê³µê°„" class="headerlink" title="InnoDBì˜ ìµœëŒ€ í–‰ ì €ì¥ê³µê°„"></a>InnoDBì˜ ìµœëŒ€ í–‰ ì €ì¥ê³µê°„</h6><p>Mysql í…Œì´ë¸”ì˜ í–‰ í¬ê¸°ëŠ” ìŠ¤í† ë¦¬ì§€ ì—”ì§„ì— ì œì•½ì´ ì—†ë‹¤ë©´ ê¸°ë³¸ì ìœ¼ë¡œ ìµœëŒ€ 65535ë°”ì´íŠ¸ì´ë‹¤. í•˜ì§€ë§Œ ìŠ¤í† ë¦¬ì§€ ì—”ì§„ì— ë”°ë¼ ì œì•½ì´ ì¶”ê°€ë˜ì–´ í–‰ í¬ê¸°ëŠ” ì¤„ì–´ë“¤ ìˆ˜ ìˆë‹¤.</p>
<p>BLOB, TEXT ì»¬ëŸ¼ì˜ ë‚´ìš©ì€ í–‰ì˜ ë‚¨ì€ ë¶€ë¶„ì´ ì•„ë‹Œ ë³„ë„ì˜ ê³µê°„ì— ì €ì¥ë˜ê¸° ë•Œë¬¸ì— ê°ê° 9<del>12ë°”ì´íŠ¸ë§Œ ì˜í–¥ì„ ì¤€ë‹¤. (í¬ì¸íŠ¸ ì €ì¥ ê³µê°„ì´ 9</del>12ë°”ì´íŠ¸) ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ê²ƒì€ ìœ„ì˜ ë‚´ìš©ì€ ìŠ¤í† ë¦¬ì§€ ì—”ì§„ì— ìƒê´€ì—†ì´ ê¸°ë³¸ì ìœ¼ë¡œ ì´ë ‡ë‹¤ëŠ” ê²ƒì´ë‹¤.</p>
<h6 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h6><p>íŠ¸ëœì­ì…˜(tranjection)ì„ ì§€ì›í•˜ì§€ ì•Šê³  table-level lockingì„ ì œê³µí•œë‹¤.</p>
<p>ë”°ë¼ì„œ 1ê°œì˜ ROWì„ READí•˜ë”ë¼ë„ í…Œì´ë¸” ì „ì²´ì— ë½ì„ ì¡ê¸° ë•Œë¬¸ì— multi-thread í™˜ê²½ì—ì„œ ì„±ëŠ¥ì´ ì €í•˜ë  ìˆ˜ ìˆë‹¤.</p>
<p>í•˜ì§€ë§Œ InnoDBì— ë¹„í•´ ê¸°ëŠ¥ì ìœ¼ë¡œ ë‹¨ìˆœí•˜ë¯€ë¡œ ëŒ€ë¶€ë¶„ì˜ ì‘ì—…ì€ InnoDBë³´ë‹¤ ì†ë„ë©´ì—ì„œ ìš°ì›”í•˜ë‹¤.</p>
<p>ë‹¨ìˆœí•œ ì¡°íšŒì˜ ê²½ìš° MyISAMì´ InnoDBë³´ë‹¤ ë¹ ë¥´ì§€ë§Œ, Order Byë“± ì •ë ¬ë“¤ì˜ êµ¬ë¬¸ì´ ë“¤ì–´ê°„ë‹¤ë©´ InnoDBë³´ë‹¤ ëŠë¦¬ë‹¤.</p>
<p>ì™œëƒí•˜ë©´ InnoDBëŠ” í´ëŸ¬ìŠ¤í„°ë§ ì¸ë±ìŠ¤ì— ì €ì¥í•˜ê¸° ë•Œë¬¸ì— PKì— ë”°ë¼ ë°ì´í„° íŒŒì¼ì´ ì •ë ¬ë˜ì–´ ìˆì§€ë§Œ, MyISAMì€ ê·¸ë ‡ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤.</p>
<p>Full text searchingì„ ì§€ì›í•œë‹¤.</p>
<p>MyISAM ì—”ì§„ì˜ ê²½ìš° ìµœëŒ€ í–‰ í¬ê¸°ê°€ ê¸°ë³¸ MySQL ì œì•½ì„ ë”°ë¥´ë¯€ë¡œ ìµœëŒ€ í–‰ í¬ê¸°ëŠ” 65535ë°”ì´íŠ¸ê°€ ë  ê²ƒì´ë‹¤.</p>
<h6 id="Archive"><a href="#Archive" class="headerlink" title="Archive"></a>Archive</h6><p>ë¡œê·¸ ìˆ˜ì§‘ì— ì í•©í•œ ì—”ì§„ì´ë‹¤. ë°ì´í„°ê°€ ë©”ëª¨ë¦¬ìƒì—ì„œ ì••ì¶•ë˜ê³  ì••ì¶•ëœ ìƒíƒœë¡œ ë””ìŠ¤í¬ì— ì €ì¥ë˜ê¸° ë•Œë¬¸ì— row-level lockingì´ ê°€ëŠ¥í•˜ë‹¤.</p>
<p>ë‹¤ë§Œ, í•œë²ˆ INSERTëœ ë°ì´í„°ëŠ” UPDATE, DELETEë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìœ¼ë©° ì¸ë±ìŠ¤ë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ê±°ì˜ ê°€ê³µí•˜ì§€ ì•Šì„ ë°ì´í„°ì— ëŒ€í•´ì„œ ê´€ë¦¬í•˜ëŠ”ë°ì— íš¨ìœ¨ì ì¼ ìˆ˜ ìˆê³ , í…Œì´ë¸” íŒŒí‹°ì…”ë‹ë„ ì§€ì›í•œë‹¤. ë‹¤ë§Œ íŠ¸ëœì­ì…˜ì€ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-07-19T09:25:05.000Z" title="2020-07-19T09:25:05.000Z">2020-07-19</time><span class="level-item">2 minutes read (About 349 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/07/19/Python-SQLAlchemy-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/">[Python] SQLAlchemy ì‚¬ìš©í•˜ê¸°</a></h1><div class="content"><pre><code>DataFrameì„ MySQLì— ì €ì¥í•˜ê¸° ìœ„í•´ ë¨¼ì € ì—”ì§„ ì»¤ë„¥í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤. íŒŒì´ì¬3ì—ì„œëŠ” MySQLdbë¥¼ ì§€ì›í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, pymysqlë¡œ ë¶ˆëŸ¬ì™€ì•¼ í•©ë‹ˆë‹¤. ê¼­ pymysqlì´ ì•„ë‹ˆì–´ë„ ìƒê´€ì—†ì§€ë§Œ, ì‚¬ìš©í•´ë³´ë©´ mysql-connector ë³´ë‹¤ ë¹ ë¥´ë‹¤ëŠ”ê±¸ ì²´ê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¨¼ì €, í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•´ì¤ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># python3</span></span><br><span class="line">pip install pymysql</span><br><span class="line">pip install sqlalchemy</span><br></pre></td></tr></table></figure>

<h6 id="SQLAlchemy-Pymysql-MySQLdb"><a href="#SQLAlchemy-Pymysql-MySQLdb" class="headerlink" title="SQLAlchemy, Pymysql, MySQLdb"></a>SQLAlchemy, Pymysql, MySQLdb</h6><pre><code>install_as_MySQLdb() í•¨ìˆ˜ë¥¼ í†µí•´ MySQLdbì™€ í˜¸í™˜ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ì œ sqlalchemyë¥¼ í†µí•´ DBì— ì—°ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì£¼ì†Œì—ì„œ root, passwordëŠ” DBì— ë§ê²Œ ë³€ê²½í•´ì•¼ í•©ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sqlalchemy <span class="keyword">import</span> create_engine</span><br><span class="line"></span><br><span class="line"><span class="comment"># MySQL Connector using pymysql</span></span><br><span class="line">pymysql.install_as_MySQLdb()</span><br><span class="line"><span class="keyword">import</span> MySQLdb</span><br><span class="line"></span><br><span class="line">engine = create_engine(<span class="string">"mysql://root:"</span>+<span class="string">"password"</span>+<span class="string">"@public IP/db_name"</span>, encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">conn = engine.connect()</span><br></pre></td></tr></table></figure>

<h6 id="MySQLì—-ì €ì¥í•˜ê¸°"><a href="#MySQLì—-ì €ì¥í•˜ê¸°" class="headerlink" title="MySQLì— ì €ì¥í•˜ê¸°"></a>MySQLì— ì €ì¥í•˜ê¸°</h6><pre><code>ì´ì œ DataFrameì„ MySQLì— í…Œì´ë¸” í˜•íƒœë¡œ ì €ì¥í•  ì°¨ë¡€ì…ë‹ˆë‹¤. ì•„ë˜ì™€ ê°™ì´ pandasì˜ to_sql() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥í•˜ë©´ ë©ë‹ˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df.to_sql(name=table_name, con=engine, if_exists=<span class="string">'append'</span>)</span><br></pre></td></tr></table></figure>

<pre><code>ìì£¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë‹ˆ í•¨ìˆ˜ë¡œ ë”°ë¡œ ì„¤ì •í•´ì£¼ë©´ ì›í•  ë•Œë§ˆë‹¤ ì‰½ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê² ì£ ? ê·¸ë¦¬ê³  if_existsì˜ ê²½ìš° ë§Œì•½ ë™ì¼ í…Œì´ë¸”ì˜ ì´ë¦„ì´ ì¡´ì¬í•œë‹¤ë©´ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ê² ëŠëƒì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì£¼ëŠ” ê²ƒì¸ë° append ì™¸ì—ë„ replace, delete ë“± ë‹¤ì–‘í•œ ê²ƒì´ ìˆìŠµë‹ˆë‹¤.</code></pre></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-07-13T09:18:42.000Z" title="2020-07-13T09:18:42.000Z">2020-07-13</time><span class="level-item">3 minutes read (About 485 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/07/13/Pandas-%ED%95%9C-%EC%85%80%EC%9D%98-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EC%97%AC%EB%9F%AC-%ED%96%89%EC%9C%BC%EB%A1%9C-%EB%82%98%EB%88%84%EA%B8%B0/">Pandas: í•œ ì…€ì˜ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ í–‰ìœ¼ë¡œ ë‚˜ëˆ„ê¸°</a></h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df = pd.DataFrame(&#123;<span class="string">'alphabet'</span>: [<span class="string">'hello,world,in,python'</span>, <span class="string">'python,is,great'</span>, <span class="string">'data,science'</span>]&#125;)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alphabet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>hello,world,in,python</td>
    </tr>
    <tr>
      <th>1</th>
      <td>python,is,great</td>
    </tr>
    <tr>
      <th>2</th>
      <td>data,science</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>ìœ„ì™€ ê°™ì´ í•œ ì…€ì— ë“¤ì–´ìˆëŠ” ë¬¸ìì—´ì„ ì»´ë§ˆë¡œ êµ¬ë¶„í•´ì„œ í•œ ê¸€ìì”© ì—¬ëŸ¬ í–‰ìœ¼ë¡œ ë‚˜ëˆ„ê³  ì‹¶ë‹¤.

í•´ê²°ì±…:

ë¬¸ìì—´ì„ split í•´ ê° í–‰ì„ ì—¬ëŸ¬ ì»¬ëŸ¼ìœ¼ë¡œ ë‚˜ëˆˆ í›„ ë³‘í•©í•˜ëŠ” ë°©ë²•ìœ¼ë¡œ êµ¬í˜„í•  ìˆ˜ ìˆë‹¤.

ë¨¼ì €, ê° alphabet ì»¬ëŸ¼ì˜ ë¬¸ìì—´ì„ ë°°ì—´ë¡œ ë‚˜ëˆˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = df[<span class="string">'alphabet'</span>].str.split(<span class="string">','</span>)</span><br><span class="line">result</span><br></pre></td></tr></table></figure>




<pre><code>0    [hello, world, in, python]
1           [python, is, great]
2               [data, science]
Name: alphabet, dtype: object



ë°°ì—´ì´ Seriesë¥¼ ë¦¬í„´í•˜ê²Œ applyë¥¼ ì ìš©í•˜ë©´ Series -&gt; DataFrameìœ¼ë¡œ ë³€í™˜í•  ìˆ˜ ìˆë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = result.apply(<span class="keyword">lambda</span> x: pd.Series(x))</span><br><span class="line">result</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>hello</td>
      <td>world</td>
      <td>in</td>
      <td>python</td>
    </tr>
    <tr>
      <th>1</th>
      <td>python</td>
      <td>is</td>
      <td>great</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>data</td>
      <td>science</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>stack()ì„ í™œìš©í•˜ì—¬ ì»¬ëŸ¼ì„ í–‰ìœ¼ë¡œ ë³€í™˜í•œë‹¤.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.stack()</span><br></pre></td></tr></table></figure>




<pre><code>0  0      hello
   1      world
   2         in
   3     python
1  0     python
   1         is
   2      great
2  0       data
   1    science
dtype: object



stack()ì„ ì‹¤í–‰í•˜ë©´, ìœ„ì™€ ê°™ì´ ë©€í‹° ì¸ë±ìŠ¤ë¥¼ ê°€ì§„ Seriesê°€ ëœë‹¤.

ì•ŒíŒŒë²³ ë‚±ìë§Œ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì¸ë±ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³ , ê¸°ì¤€ì´ ëœ ì¸ë±ìŠ¤ë„ ì œê±°í•´ë³´ì.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">result.stack().reset_index(level=<span class="number">1</span>, drop=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>




<pre><code>0      hello
0      world
0         in
0     python
1     python
1         is
1      great
2       data
2    science
dtype: object



ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = result.stack().reset_index(level=<span class="number">1</span>, drop=<span class="literal">True</span>).to_frame(<span class="string">'alphabet_single'</span>)</span><br><span class="line">result</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alphabet_single</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>hello</td>
    </tr>
    <tr>
      <th>0</th>
      <td>world</td>
    </tr>
    <tr>
      <th>0</th>
      <td>in</td>
    </tr>
    <tr>
      <th>0</th>
      <td>python</td>
    </tr>
    <tr>
      <th>1</th>
      <td>python</td>
    </tr>
    <tr>
      <th>1</th>
      <td>is</td>
    </tr>
    <tr>
      <th>1</th>
      <td>great</td>
    </tr>
    <tr>
      <th>2</th>
      <td>data</td>
    </tr>
    <tr>
      <th>2</th>
      <td>science</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>ì›ë³¸ í”„ë ˆì„ê³¼ ìœ„ì˜ í”„ë ˆì„ì„ merge í•´ë³´ì</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">result = df.merge(result, left_index=<span class="literal">True</span>, right_index=<span class="literal">True</span>, how=<span class="string">'left'</span>)</span><br><span class="line">result</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>alphabet</th>
      <th>alphabet_single</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>hello,world,in,python</td>
      <td>hello</td>
    </tr>
    <tr>
      <th>0</th>
      <td>hello,world,in,python</td>
      <td>world</td>
    </tr>
    <tr>
      <th>0</th>
      <td>hello,world,in,python</td>
      <td>in</td>
    </tr>
    <tr>
      <th>0</th>
      <td>hello,world,in,python</td>
      <td>python</td>
    </tr>
    <tr>
      <th>1</th>
      <td>python,is,great</td>
      <td>python</td>
    </tr>
    <tr>
      <th>1</th>
      <td>python,is,great</td>
      <td>is</td>
    </tr>
    <tr>
      <th>1</th>
      <td>python,is,great</td>
      <td>great</td>
    </tr>
    <tr>
      <th>2</th>
      <td>data,science</td>
      <td>data</td>
    </tr>
    <tr>
      <th>2</th>
      <td>data,science</td>
      <td>science</td>
    </tr>
  </tbody>
</table>
</div>


</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-07-10T09:04:08.000Z" title="2020-07-10T09:04:08.000Z">2020-07-10</time><span class="level-item">2 minutes read (About 294 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/07/10/Ubuntu-UTF-8-%EC%84%A4%EC%A0%95%ED%95%98%EA%B8%B0/">Ubuntu UTF-8 ì„¤ì •í•˜ê¸°</a></h1><div class="content"><p>ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ í˜„ì¬ ì„¤ì •ëœ ì–¸ì–´ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>locale</p>
<p>í•œê¸€íŒ©ì„ ì„¤ì¹˜í•´ì¤ë‹ˆë‹¤.</p>
<p>apt-get -y install language-pack-ko</p>
<p>í•œê¸€ utf8 ì–¸ì–´íŒ©ì„ ì„¤ì¹˜í•©ë‹ˆë‹¤.</p>
<p>locale-gen ko_KR.UTF-8</p>
<p>ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì–¸ì–´íŒ©ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.</p>
<p>dpkg-reconfigure locales</p>
<p>â€œko_KR.UTF-8 UTF-8â€ ì— í•´ë‹¹í•˜ëŠ” ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê³  ì—”í„°! (ì €ëŠ” 290ë²ˆì´ì˜€ë„¤ìš”. í˜¹ì‹œ ë‹¤ë¥¼ìˆ˜ ìˆìœ¼ë‹ˆ í™•ì¸í•˜ì„¸ìš”)<br>â€œko_KR.UTF-8â€ ì„ ì„ íƒí•©ë‹ˆë‹¤. (ì €ëŠ” 3ë²ˆê³¼ 4ë²ˆì— ë˜‘ê°™ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ê·¸ëƒ¥ 3ë²ˆ ëˆŒë €ìŠµë‹ˆë‹¤.)</p>
<p>ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì‹œìŠ¤í…œ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•˜ë©´ ì ìš©ë©ë‹ˆë‹¤.<br>update-locale LANG=ko_KR.UTF-8 LC_MESSAGES=POSIX</p>
<p>ë¡œê·¸ì•„ì›ƒ í›„ ë‹¤ì‹œ ë¡œê·¸ì¸í•œ í›„(SSH ì¬ì ‘ì†) ë‹¤ì‹œ locale ëª…ë ¹ì–´ë¥¼ ì…ë ¥í•˜ë©´ ì ìš©ë©ë‹ˆë‹¤!<br>ì €ëŠ” ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.</p>
<p>LANG=ko_KR.UTF-8<br>LANGUAGE=<br>LC_CTYPE=â€ko_KR.UTF-8â€<br>LC_NUMERIC=â€ko_KR.UTF-8â€<br>LC_TIME=â€ko_KR.UTF-8â€<br>LC_COLLATE=â€ko_KR.UTF-8â€<br>LC_MONETARY=â€ko_KR.UTF-8â€<br>LC_MESSAGES=POSIX<br>LC_PAPER=â€ko_KR.UTF-8â€<br>LC_NAME=â€ko_KR.UTF-8â€<br>LC_ADDRESS=â€ko_KR.UTF-8â€<br>LC_TELEPHONE=â€ko_KR.UTF-8â€<br>LC_MEASUREMENT=â€ko_KR.UTF-8â€<br>LC_IDENTIFICATION=â€ko_KR.UTF-8â€<br>LC_ALL=</p>
</div></article></div><nav class="pagination is-centered mt-4" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">Previous</a></div><div class="pagination-next"><a href="/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://user-images.githubusercontent.com/59719711/85970198-ab9c3c80-ba04-11ea-8990-4bdec6914e3c.jpeg" alt="wglee87"></figure><p class="title is-size-4 is-block line-height-inherit">wglee87</p><p class="is-size-6 is-block">Data has a better idea</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hwasung, KR</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">34</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wglee87" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wglee87"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://Instagram.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-26T10:14:02.000Z">2020-08-26</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/26/Model-sava-and-load-in-tensorflow/">Model sava and load in tensorflow</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-25T11:21:43.000Z">2020-08-25</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/25/%EA%B3%BC%EB%8C%80%EC%A0%81%ED%95%A9-Overfitting-%EA%B3%BC-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-Underfitting/">ê³¼ëŒ€ì í•©(Overfitting)ê³¼ ê³¼ì†Œì í•©(Underfitting)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-21T06:29:24.000Z">2020-08-21</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/21/Tensorflow%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8%EB%A7%81/">Tensorflowë¥¼ í™œìš©í•œ íšŒê·€ ëª¨ë¸ë§</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-12T12:06:35.000Z">2020-08-12</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/12/%E1%84%80%E1%85%AE%E1%84%80%E1%85%B3%E1%86%AF-%E1%84%8C%E1%85%B5%E1%84%8B%E1%85%A9%E1%84%8F%E1%85%A9%E1%84%83%E1%85%B5%E1%86%BC-API-%E1%84%8F%E1%85%B5-%E1%84%87%E1%85%A1%E1%86%AF%E1%84%80%E1%85%B3%E1%86%B8-%E1%84%87%E1%85%A1%E1%86%AE%E1%84%82%E1%85%B3%E1%86%AB-%E1%84%87%E1%85%A1%E1%86%BC%E1%84%87%E1%85%A5%E1%86%B8-How-to-be-issued-the-Geocoding-API-key-from-Google/">êµ¬ê¸€ ì§€ì˜¤ì½”ë”© API í‚¤ ë°œê¸‰ ë°›ëŠ” ë°©ë²• (How to be issued the Geocoding API key from Google)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-07-24T05:54:01.000Z">2020-07-24</time></p><p class="title is-6"><a class="link-muted" href="/2020/07/24/MySQL-Ubuntu%EC%97%90%EC%84%9C-MySQL-%EC%99%84%EC%A0%84-%EC%82%AD%EC%A0%9C%ED%95%98%EA%B8%B0/">[MySQL] Ubuntuì—ì„œ MySQL ì™„ì „ ì‚­ì œí•˜ê¸°</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/fastcampus/"><span class="tag">fastcampus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/" alt="Geony&#039;s Tech Blog" height="28"></a><p class="size-small"><span>&copy; 2020 WGLee87</span>Â Â Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>Â &amp;Â <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://wglee87.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">Ã—</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>