<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>과대적합(Overfitting)과 과소적합(Underfitting) - Geony&#039;s Tech Blog</title><meta description="과대적합(Overfitting)과 과소적합(Underfitting)일정 에포크 동안 훈련을 시키면 검증세트에서 모델 성능이 최고점에 도달한 다음 감소하기 시작한 것을 알 수 있습니다. 훈련 세트에서 높은 성능을 얻을 수 있지만 진짜 원하는 것은 테스트 세트(또는 이전에 본 적 없는 데이터)에 잘 일반화되는 모델입니다.  과소적합이란 테스트 세트의 성능이 향"><meta property="og:type" content="blog"><meta property="og:title" content="Geony&#039;s Tech Blog"><meta property="og:url" content="http://wglee87.github.io/2020/08/25/%EA%B3%BC%EB%8C%80%EC%A0%81%ED%95%A9-Overfitting-%EA%B3%BC-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-Underfitting/"><meta property="og:site_name" content="Geony&#039;s Tech Blog"><meta property="og:description" content="과대적합(Overfitting)과 과소적합(Underfitting)일정 에포크 동안 훈련을 시키면 검증세트에서 모델 성능이 최고점에 도달한 다음 감소하기 시작한 것을 알 수 있습니다. 훈련 세트에서 높은 성능을 얻을 수 있지만 진짜 원하는 것은 테스트 세트(또는 이전에 본 적 없는 데이터)에 잘 일반화되는 모델입니다.  과소적합이란 테스트 세트의 성능이 향"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/91168503-b4fa0a80-e710-11ea-9844-30bd30bac3a6.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/91168509-b6c3ce00-e710-11ea-9ccf-2e3a684d81c9.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/91168556-cb07cb00-e710-11ea-88ae-600d0836acfe.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/91168597-db1faa80-e710-11ea-832a-55d34038d224.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/91168603-dd820480-e710-11ea-8916-4ba873e21636.png"><meta property="article:published_time" content="2020-08-25T11:21:43.000Z"><meta property="article:modified_time" content="2020-08-25T11:24:01.097Z"><meta property="article:author" content="wglee87"><meta property="article:tag" content="data_analysis"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://user-images.githubusercontent.com/59719711/91168503-b4fa0a80-e710-11ea-9844-30bd30bac3a6.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://wglee87.github.io/2020/08/25/%EA%B3%BC%EB%8C%80%EC%A0%81%ED%95%A9-Overfitting-%EA%B3%BC-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-Underfitting/"},"headline":"Geony's Tech Blog","image":["https://user-images.githubusercontent.com/59719711/91168503-b4fa0a80-e710-11ea-9844-30bd30bac3a6.png","https://user-images.githubusercontent.com/59719711/91168509-b6c3ce00-e710-11ea-9ccf-2e3a684d81c9.png","https://user-images.githubusercontent.com/59719711/91168556-cb07cb00-e710-11ea-88ae-600d0836acfe.png","https://user-images.githubusercontent.com/59719711/91168597-db1faa80-e710-11ea-832a-55d34038d224.png","https://user-images.githubusercontent.com/59719711/91168603-dd820480-e710-11ea-8916-4ba873e21636.png"],"datePublished":"2020-08-25T11:21:43.000Z","dateModified":"2020-08-25T11:24:01.097Z","author":{"@type":"Person","name":"WGLee87"},"description":"과대적합(Overfitting)과 과소적합(Underfitting)일정 에포크 동안 훈련을 시키면 검증세트에서 모델 성능이 최고점에 도달한 다음 감소하기 시작한 것을 알 수 있습니다. 훈련 세트에서 높은 성능을 얻을 수 있지만 진짜 원하는 것은 테스트 세트(또는 이전에 본 적 없는 데이터)에 잘 일반화되는 모델입니다.  과소적합이란 테스트 세트의 성능이 향"}</script><link rel="canonical" href="http://wglee87.github.io/2020/08/25/%EA%B3%BC%EB%8C%80%EC%A0%81%ED%95%A9-Overfitting-%EA%B3%BC-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-Underfitting/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/" alt="Geony&#039;s Tech Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="/null">Download on GitHub</a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-08-25T11:21:43.000Z" title="2020-08-25T11:21:43.000Z">2020-08-25</time><span class="level-item">19 minutes read (About 2880 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">과대적합(Overfitting)과 과소적합(Underfitting)</h1><div class="content"><h6 id="과대적합-Overfitting-과-과소적합-Underfitting"><a href="#과대적합-Overfitting-과-과소적합-Underfitting" class="headerlink" title="과대적합(Overfitting)과 과소적합(Underfitting)"></a>과대적합(Overfitting)과 과소적합(Underfitting)</h6><pre><code>일정 에포크 동안 훈련을 시키면 검증세트에서 모델 성능이 최고점에 도달한 다음 감소하기 시작한 것을 알 수 있습니다.
훈련 세트에서 높은 성능을 얻을 수 있지만 진짜 원하는 것은 테스트 세트(또는 이전에 본 적 없는 데이터)에 잘 일반화되는 모델입니다.

과소적합이란 테스트 세트의 성능이 향상될 여지가 아직 있을 때 일어납니다. 발생하는 원인은 여러가지입니다. 모델이 너무 단순하거나, 규제가 너무 많거나, 그냥 단순히 충분히 오래 훈련하지 않는 경우입니다. 즉 네트워크가 훈련 세트에서 적절한 패턴을 학습하지 못했다는 뜻입니다.

모델을 너무 오래 훈련하면 과대적합되기 시작하고 테스트 세트에서 일반화되지 못하는 패턴을 훈련 세트에서 학습합니다. 과대적합과 과소적합 사이에서 균형을 잡아야 합니다.

균형을 잘 잡고 과대적합을 방지하기 위한 2가지 규제방법을 알아보도록 하겠습니다</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">print(tf.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>2.4.0-dev20200724


데이터셋 다운로드를 받고 원핫 인코딩으로 변환하자!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">NUM_WORDS = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">(train_data, train_labels), (test_data, test_labels) = keras.datasets.imdb.load_data(num_words=NUM_WORDS)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">multi_hot_sequences</span><span class="params">(sequences, dimension)</span>:</span></span><br><span class="line">    <span class="comment"># 0으로 채워진 (len(sequences), dimension) 크기의 행렬을 만듭니다</span></span><br><span class="line">    results = np.zeros((len(sequences), dimension))</span><br><span class="line">    <span class="keyword">for</span> i, word_indices <span class="keyword">in</span> enumerate(sequences):</span><br><span class="line">        results[i, word_indices] = <span class="number">1.0</span>  <span class="comment"># results[i]의 특정 인덱스만 1로 설정합니다</span></span><br><span class="line">    <span class="keyword">return</span> results</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_data = multi_hot_sequences(train_data, dimension=NUM_WORDS)</span><br><span class="line">test_data = multi_hot_sequences(test_data, dimension=NUM_WORDS)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(train_data[<span class="number">0</span>])</span><br><span class="line">plt.grid(<span class="literal">False</span>)</span><br><span class="line">plt.xticks(rotation=<span class="number">45</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="374" alt="output_4_0" src="https://user-images.githubusercontent.com/59719711/91168503-b4fa0a80-e710-11ea-9844-30bd30bac3a6.png">


<pre><code>기준 모델을 만들어 기준보다 유닛의 수가 크거나 작은 모델과 비교를 해보겠습니다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">base_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">base_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">base_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_2&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_11 (Dense)             (None, 16)                16016     
_________________________________________________________________
dense_12 (Dense)             (None, 16)                272       
_________________________________________________________________
dense_13 (Dense)             (None, 1)                 17        
=================================================================
Total params: 16,305
Trainable params: 16,305
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">base_history = base_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 0s - loss: 0.2555 - accuracy: 0.8971 - binary_crossentropy: 0.2555 - val_loss: 0.3410 - val_accuracy: 0.8558 - val_binary_crossentropy: 0.3410
Epoch 2/20
49/49 - 0s - loss: 0.2436 - accuracy: 0.9030 - binary_crossentropy: 0.2436 - val_loss: 0.3454 - val_accuracy: 0.8540 - val_binary_crossentropy: 0.3454
Epoch 3/20
49/49 - 0s - loss: 0.2356 - accuracy: 0.9068 - binary_crossentropy: 0.2356 - val_loss: 0.3525 - val_accuracy: 0.8508 - val_binary_crossentropy: 0.3525
Epoch 4/20
49/49 - 0s - loss: 0.2259 - accuracy: 0.9102 - binary_crossentropy: 0.2259 - val_loss: 0.3638 - val_accuracy: 0.8482 - val_binary_crossentropy: 0.3638
Epoch 5/20
49/49 - 0s - loss: 0.2178 - accuracy: 0.9142 - binary_crossentropy: 0.2178 - val_loss: 0.3701 - val_accuracy: 0.8487 - val_binary_crossentropy: 0.3701
Epoch 6/20
49/49 - 0s - loss: 0.2093 - accuracy: 0.9188 - binary_crossentropy: 0.2093 - val_loss: 0.3809 - val_accuracy: 0.8469 - val_binary_crossentropy: 0.3809
Epoch 7/20
49/49 - 0s - loss: 0.2026 - accuracy: 0.9208 - binary_crossentropy: 0.2026 - val_loss: 0.3854 - val_accuracy: 0.8465 - val_binary_crossentropy: 0.3854
Epoch 8/20
49/49 - 0s - loss: 0.1963 - accuracy: 0.9240 - binary_crossentropy: 0.1963 - val_loss: 0.3996 - val_accuracy: 0.8430 - val_binary_crossentropy: 0.3996
Epoch 9/20
49/49 - 0s - loss: 0.1905 - accuracy: 0.9254 - binary_crossentropy: 0.1905 - val_loss: 0.4014 - val_accuracy: 0.8421 - val_binary_crossentropy: 0.4014
Epoch 10/20
49/49 - 0s - loss: 0.1846 - accuracy: 0.9307 - binary_crossentropy: 0.1846 - val_loss: 0.4143 - val_accuracy: 0.8418 - val_binary_crossentropy: 0.4143
Epoch 11/20
49/49 - 0s - loss: 0.1787 - accuracy: 0.9322 - binary_crossentropy: 0.1787 - val_loss: 0.4300 - val_accuracy: 0.8382 - val_binary_crossentropy: 0.4300
Epoch 12/20
49/49 - 0s - loss: 0.1739 - accuracy: 0.9329 - binary_crossentropy: 0.1739 - val_loss: 0.4402 - val_accuracy: 0.8372 - val_binary_crossentropy: 0.4402
Epoch 13/20
49/49 - 0s - loss: 0.1663 - accuracy: 0.9373 - binary_crossentropy: 0.1663 - val_loss: 0.4508 - val_accuracy: 0.8358 - val_binary_crossentropy: 0.4508
Epoch 14/20
49/49 - 0s - loss: 0.1613 - accuracy: 0.9396 - binary_crossentropy: 0.1613 - val_loss: 0.4584 - val_accuracy: 0.8364 - val_binary_crossentropy: 0.4584
Epoch 15/20
49/49 - 0s - loss: 0.1581 - accuracy: 0.9400 - binary_crossentropy: 0.1581 - val_loss: 0.4805 - val_accuracy: 0.8356 - val_binary_crossentropy: 0.4805
Epoch 16/20
49/49 - 0s - loss: 0.1534 - accuracy: 0.9419 - binary_crossentropy: 0.1534 - val_loss: 0.4836 - val_accuracy: 0.8343 - val_binary_crossentropy: 0.4836
Epoch 17/20
49/49 - 0s - loss: 0.1477 - accuracy: 0.9454 - binary_crossentropy: 0.1477 - val_loss: 0.5082 - val_accuracy: 0.8330 - val_binary_crossentropy: 0.5082
Epoch 18/20
49/49 - 0s - loss: 0.1440 - accuracy: 0.9458 - binary_crossentropy: 0.1440 - val_loss: 0.5069 - val_accuracy: 0.8342 - val_binary_crossentropy: 0.5069
Epoch 19/20
49/49 - 0s - loss: 0.1382 - accuracy: 0.9489 - binary_crossentropy: 0.1382 - val_loss: 0.5187 - val_accuracy: 0.8323 - val_binary_crossentropy: 0.5187
Epoch 20/20
49/49 - 0s - loss: 0.1339 - accuracy: 0.9520 - binary_crossentropy: 0.1339 - val_loss: 0.5385 - val_accuracy: 0.8310 - val_binary_crossentropy: 0.5385


작은 모델을 만들어보자</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">small_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">6</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">6</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">small_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">small_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_4&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_18 (Dense)             (None, 6)                 6006      
_________________________________________________________________
dense_19 (Dense)             (None, 6)                 42        
_________________________________________________________________
dense_20 (Dense)             (None, 1)                 7         
=================================================================
Total params: 6,055
Trainable params: 6,055
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">small_history = small_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 0s - loss: 0.2994 - accuracy: 0.8785 - binary_crossentropy: 0.2994 - val_loss: 0.3305 - val_accuracy: 0.8593 - val_binary_crossentropy: 0.3305
Epoch 2/20
49/49 - 0s - loss: 0.2972 - accuracy: 0.8790 - binary_crossentropy: 0.2972 - val_loss: 0.3306 - val_accuracy: 0.8599 - val_binary_crossentropy: 0.3306
Epoch 3/20
49/49 - 0s - loss: 0.2970 - accuracy: 0.8782 - binary_crossentropy: 0.2970 - val_loss: 0.3343 - val_accuracy: 0.8581 - val_binary_crossentropy: 0.3343
Epoch 4/20
49/49 - 0s - loss: 0.2965 - accuracy: 0.8777 - binary_crossentropy: 0.2965 - val_loss: 0.3312 - val_accuracy: 0.8590 - val_binary_crossentropy: 0.3312
Epoch 5/20
49/49 - 0s - loss: 0.2960 - accuracy: 0.8794 - binary_crossentropy: 0.2960 - val_loss: 0.3314 - val_accuracy: 0.8592 - val_binary_crossentropy: 0.3314
Epoch 6/20
49/49 - 0s - loss: 0.2957 - accuracy: 0.8783 - binary_crossentropy: 0.2957 - val_loss: 0.3320 - val_accuracy: 0.8590 - val_binary_crossentropy: 0.3320
Epoch 7/20
49/49 - 0s - loss: 0.2968 - accuracy: 0.8768 - binary_crossentropy: 0.2968 - val_loss: 0.3321 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3321
Epoch 8/20
49/49 - 0s - loss: 0.2960 - accuracy: 0.8790 - binary_crossentropy: 0.2960 - val_loss: 0.3323 - val_accuracy: 0.8594 - val_binary_crossentropy: 0.3323
Epoch 9/20
49/49 - 0s - loss: 0.2960 - accuracy: 0.8787 - binary_crossentropy: 0.2960 - val_loss: 0.3323 - val_accuracy: 0.8582 - val_binary_crossentropy: 0.3323
Epoch 10/20
49/49 - 0s - loss: 0.2959 - accuracy: 0.8784 - binary_crossentropy: 0.2959 - val_loss: 0.3327 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3327
Epoch 11/20
49/49 - 0s - loss: 0.2953 - accuracy: 0.8789 - binary_crossentropy: 0.2953 - val_loss: 0.3334 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3334
Epoch 12/20
49/49 - 0s - loss: 0.2970 - accuracy: 0.8775 - binary_crossentropy: 0.2970 - val_loss: 0.3334 - val_accuracy: 0.8578 - val_binary_crossentropy: 0.3334
Epoch 13/20
49/49 - 0s - loss: 0.2951 - accuracy: 0.8798 - binary_crossentropy: 0.2951 - val_loss: 0.3341 - val_accuracy: 0.8581 - val_binary_crossentropy: 0.3341
Epoch 14/20
49/49 - 0s - loss: 0.2950 - accuracy: 0.8786 - binary_crossentropy: 0.2950 - val_loss: 0.3323 - val_accuracy: 0.8590 - val_binary_crossentropy: 0.3323
Epoch 15/20
49/49 - 0s - loss: 0.2950 - accuracy: 0.8786 - binary_crossentropy: 0.2950 - val_loss: 0.3324 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3324
Epoch 16/20
49/49 - 0s - loss: 0.2949 - accuracy: 0.8790 - binary_crossentropy: 0.2949 - val_loss: 0.3330 - val_accuracy: 0.8593 - val_binary_crossentropy: 0.3330
Epoch 17/20
49/49 - 0s - loss: 0.2946 - accuracy: 0.8784 - binary_crossentropy: 0.2946 - val_loss: 0.3324 - val_accuracy: 0.8585 - val_binary_crossentropy: 0.3324
Epoch 18/20
49/49 - 0s - loss: 0.2952 - accuracy: 0.8784 - binary_crossentropy: 0.2952 - val_loss: 0.3329 - val_accuracy: 0.8585 - val_binary_crossentropy: 0.3329
Epoch 19/20
49/49 - 0s - loss: 0.2943 - accuracy: 0.8794 - binary_crossentropy: 0.2943 - val_loss: 0.3330 - val_accuracy: 0.8588 - val_binary_crossentropy: 0.3330
Epoch 20/20
49/49 - 0s - loss: 0.2949 - accuracy: 0.8789 - binary_crossentropy: 0.2949 - val_loss: 0.3329 - val_accuracy: 0.8583 - val_binary_crossentropy: 0.3329


큰 모델 만들기</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">big_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">big_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">big_model.summary()</span><br></pre></td></tr></table></figure>

<pre><code>Model: &quot;sequential_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_21 (Dense)             (None, 128)               128128    
_________________________________________________________________
dense_22 (Dense)             (None, 128)               16512     
_________________________________________________________________
dense_23 (Dense)             (None, 1)                 129       
=================================================================
Total params: 144,769
Trainable params: 144,769
Non-trainable params: 0
_________________________________________________________________</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">big_history = big_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 0s - loss: 0.0047 - accuracy: 0.9999 - binary_crossentropy: 0.0047 - val_loss: 0.6867 - val_accuracy: 0.8388 - val_binary_crossentropy: 0.6867
Epoch 2/20
49/49 - 0s - loss: 0.0029 - accuracy: 1.0000 - binary_crossentropy: 0.0029 - val_loss: 0.7205 - val_accuracy: 0.8382 - val_binary_crossentropy: 0.7205
Epoch 3/20
49/49 - 0s - loss: 0.0019 - accuracy: 1.0000 - binary_crossentropy: 0.0019 - val_loss: 0.7533 - val_accuracy: 0.8388 - val_binary_crossentropy: 0.7533
Epoch 4/20
49/49 - 0s - loss: 0.0014 - accuracy: 1.0000 - binary_crossentropy: 0.0014 - val_loss: 0.7802 - val_accuracy: 0.8383 - val_binary_crossentropy: 0.7802
Epoch 5/20
49/49 - 0s - loss: 0.0010 - accuracy: 1.0000 - binary_crossentropy: 0.0010 - val_loss: 0.8079 - val_accuracy: 0.8392 - val_binary_crossentropy: 0.8079
Epoch 6/20
49/49 - 0s - loss: 8.0437e-04 - accuracy: 1.0000 - binary_crossentropy: 8.0437e-04 - val_loss: 0.8324 - val_accuracy: 0.8392 - val_binary_crossentropy: 0.8324
Epoch 7/20
49/49 - 0s - loss: 6.4169e-04 - accuracy: 1.0000 - binary_crossentropy: 6.4169e-04 - val_loss: 0.8510 - val_accuracy: 0.8397 - val_binary_crossentropy: 0.8510
Epoch 8/20
49/49 - 0s - loss: 5.2259e-04 - accuracy: 1.0000 - binary_crossentropy: 5.2259e-04 - val_loss: 0.8707 - val_accuracy: 0.8397 - val_binary_crossentropy: 0.8707
Epoch 9/20
49/49 - 0s - loss: 4.3499e-04 - accuracy: 1.0000 - binary_crossentropy: 4.3499e-04 - val_loss: 0.8885 - val_accuracy: 0.8395 - val_binary_crossentropy: 0.8885
Epoch 10/20
49/49 - 0s - loss: 3.6612e-04 - accuracy: 1.0000 - binary_crossentropy: 3.6612e-04 - val_loss: 0.9055 - val_accuracy: 0.8397 - val_binary_crossentropy: 0.9055
Epoch 11/20
49/49 - 0s - loss: 3.1179e-04 - accuracy: 1.0000 - binary_crossentropy: 3.1179e-04 - val_loss: 0.9202 - val_accuracy: 0.8396 - val_binary_crossentropy: 0.9202
Epoch 12/20
49/49 - 0s - loss: 2.6851e-04 - accuracy: 1.0000 - binary_crossentropy: 2.6851e-04 - val_loss: 0.9358 - val_accuracy: 0.8396 - val_binary_crossentropy: 0.9358
Epoch 13/20
49/49 - 0s - loss: 2.3418e-04 - accuracy: 1.0000 - binary_crossentropy: 2.3418e-04 - val_loss: 0.9482 - val_accuracy: 0.8399 - val_binary_crossentropy: 0.9482
Epoch 14/20
49/49 - 0s - loss: 2.0480e-04 - accuracy: 1.0000 - binary_crossentropy: 2.0480e-04 - val_loss: 0.9615 - val_accuracy: 0.8400 - val_binary_crossentropy: 0.9615
Epoch 15/20
49/49 - 0s - loss: 1.8099e-04 - accuracy: 1.0000 - binary_crossentropy: 1.8099e-04 - val_loss: 0.9732 - val_accuracy: 0.8396 - val_binary_crossentropy: 0.9732
Epoch 16/20
49/49 - 0s - loss: 1.6065e-04 - accuracy: 1.0000 - binary_crossentropy: 1.6065e-04 - val_loss: 0.9851 - val_accuracy: 0.8400 - val_binary_crossentropy: 0.9851
Epoch 17/20
49/49 - 0s - loss: 1.4336e-04 - accuracy: 1.0000 - binary_crossentropy: 1.4336e-04 - val_loss: 0.9966 - val_accuracy: 0.8401 - val_binary_crossentropy: 0.9966
Epoch 18/20
49/49 - 0s - loss: 1.2880e-04 - accuracy: 1.0000 - binary_crossentropy: 1.2880e-04 - val_loss: 1.0070 - val_accuracy: 0.8399 - val_binary_crossentropy: 1.0070
Epoch 19/20
49/49 - 0s - loss: 1.1636e-04 - accuracy: 1.0000 - binary_crossentropy: 1.1636e-04 - val_loss: 1.0171 - val_accuracy: 0.8398 - val_binary_crossentropy: 1.0171
Epoch 20/20
49/49 - 0s - loss: 1.0553e-04 - accuracy: 1.0000 - binary_crossentropy: 1.0553e-04 - val_loss: 1.0270 - val_accuracy: 0.8398 - val_binary_crossentropy: 1.0270</code></pre><p>training dataset의 loss(손실)값과 test dataset의 loss(손실)값 시각화</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_history</span><span class="params">(histories, key=<span class="string">'binary_crossentropy'</span>)</span>:</span></span><br><span class="line">    plt.figure(figsize=(<span class="number">16</span>,<span class="number">6</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> name, history <span class="keyword">in</span> histories:</span><br><span class="line">        val = plt.plot(history.epoch, history.history[<span class="string">'val_'</span> + key],</span><br><span class="line">                      <span class="string">'--'</span>, label=name.title()+<span class="string">' Val'</span>)</span><br><span class="line">        plt.plot(history.epoch, history.history[key], color=val[<span class="number">0</span>].get_color(),</span><br><span class="line">                label=name.title()+<span class="string">'Train'</span>)</span><br><span class="line">                       </span><br><span class="line">    plt.xlabel(<span class="string">'Epochs'</span>)</span><br><span class="line">    plt.ylabel(key.replace(<span class="string">'-'</span>, <span class="string">' '</span>).title())</span><br><span class="line">    plt.legend()</span><br><span class="line">    </span><br><span class="line">    plt.xlim([<span class="number">0</span>, max(history.epoch)])</span><br><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'smaller'</span>, small_history),</span><br><span class="line">              (<span class="string">'bigger'</span>, big_history)])</span><br></pre></td></tr></table></figure>



<img width="947" alt="output_15_0" src="https://user-images.githubusercontent.com/59719711/91168509-b6c3ce00-e710-11ea-9ccf-2e3a684d81c9.png">



<p>big model의 경우 에포크가 시작하자마자 과대적합(Overfitting)이 일어나는 것을 알 수 있고 생각보다 심하게 이뤄집니다. 모델 네트워크의 용량이 많을수록 과대적합이 될 확률이 커집니다.(훈련 loss값과 검증 loss값 사이에 큰 차이가 발생)</p>
<p>과대적합(Overfitting)을 방지하기 위한 전략</p>
<pre><code>- 가중치 규제하기
    1. 훈련 데이터와 네트워크 구조가 주어졌을 때, 데이터를 설명할 수 있는 가중치의 조합을 간단하게!
    2. 모델 파라미터의 분포를 봤을 때 엔트로피가 작은 모델(적은 파라미터를 가지는 모델), 즉 과대적합을 완화시키는 일반적인 방법은 가중치가 작은 값을 가지도록 네트워크의 복잡도에 제약을 가하는 것이라고 할 수 있습니다. &apos;가중치 규제(Weight regularization)
        * L1 규제는 가중치의 절댓값에 비례하는 비용이 추가
        * L2 규제는 가중치의 제곱에 비례하는 비용이 추가, 신경망에서는 L2규제를 가중치 감쇠(weight decay)라고도 합니다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">l2_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>),</span><br><span class="line">                       activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>),</span><br><span class="line">                       activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">l2_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">l2_history = l2_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 1s - loss: 0.6362 - accuracy: 0.6929 - binary_crossentropy: 0.5927 - val_loss: 0.4927 - val_accuracy: 0.8113 - val_binary_crossentropy: 0.4513
Epoch 2/20
49/49 - 0s - loss: 0.4164 - accuracy: 0.8462 - binary_crossentropy: 0.3749 - val_loss: 0.3873 - val_accuracy: 0.8545 - val_binary_crossentropy: 0.3460
Epoch 3/20
49/49 - 0s - loss: 0.3636 - accuracy: 0.8669 - binary_crossentropy: 0.3230 - val_loss: 0.3708 - val_accuracy: 0.8598 - val_binary_crossentropy: 0.3312
Epoch 4/20
49/49 - 0s - loss: 0.3498 - accuracy: 0.8721 - binary_crossentropy: 0.3113 - val_loss: 0.3687 - val_accuracy: 0.8596 - val_binary_crossentropy: 0.3312
Epoch 5/20
49/49 - 0s - loss: 0.3440 - accuracy: 0.8726 - binary_crossentropy: 0.3073 - val_loss: 0.3640 - val_accuracy: 0.8602 - val_binary_crossentropy: 0.3283
Epoch 6/20
49/49 - 0s - loss: 0.3393 - accuracy: 0.8760 - binary_crossentropy: 0.3044 - val_loss: 0.3622 - val_accuracy: 0.8598 - val_binary_crossentropy: 0.3281
Epoch 7/20
49/49 - 0s - loss: 0.3369 - accuracy: 0.8749 - binary_crossentropy: 0.3034 - val_loss: 0.3604 - val_accuracy: 0.8603 - val_binary_crossentropy: 0.3276
Epoch 8/20
49/49 - 0s - loss: 0.3349 - accuracy: 0.8754 - binary_crossentropy: 0.3027 - val_loss: 0.3595 - val_accuracy: 0.8595 - val_binary_crossentropy: 0.3281
Epoch 9/20
49/49 - 0s - loss: 0.3325 - accuracy: 0.8746 - binary_crossentropy: 0.3015 - val_loss: 0.3608 - val_accuracy: 0.8592 - val_binary_crossentropy: 0.3304
Epoch 10/20
49/49 - 0s - loss: 0.3332 - accuracy: 0.8744 - binary_crossentropy: 0.3031 - val_loss: 0.3599 - val_accuracy: 0.8587 - val_binary_crossentropy: 0.3304
Epoch 11/20
49/49 - 0s - loss: 0.3305 - accuracy: 0.8750 - binary_crossentropy: 0.3012 - val_loss: 0.3563 - val_accuracy: 0.8592 - val_binary_crossentropy: 0.3274
Epoch 12/20
49/49 - 0s - loss: 0.3290 - accuracy: 0.8748 - binary_crossentropy: 0.3004 - val_loss: 0.3554 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3272
Epoch 13/20
49/49 - 0s - loss: 0.3272 - accuracy: 0.8752 - binary_crossentropy: 0.2991 - val_loss: 0.3526 - val_accuracy: 0.8604 - val_binary_crossentropy: 0.3247
Epoch 14/20
49/49 - 0s - loss: 0.3251 - accuracy: 0.8760 - binary_crossentropy: 0.2972 - val_loss: 0.3522 - val_accuracy: 0.8596 - val_binary_crossentropy: 0.3243
Epoch 15/20
49/49 - 0s - loss: 0.3232 - accuracy: 0.8759 - binary_crossentropy: 0.2953 - val_loss: 0.3547 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3268
Epoch 16/20
49/49 - 0s - loss: 0.3214 - accuracy: 0.8770 - binary_crossentropy: 0.2936 - val_loss: 0.3522 - val_accuracy: 0.8601 - val_binary_crossentropy: 0.3246
Epoch 17/20
49/49 - 0s - loss: 0.3201 - accuracy: 0.8781 - binary_crossentropy: 0.2926 - val_loss: 0.3512 - val_accuracy: 0.8600 - val_binary_crossentropy: 0.3238
Epoch 18/20
49/49 - 0s - loss: 0.3194 - accuracy: 0.8766 - binary_crossentropy: 0.2921 - val_loss: 0.3544 - val_accuracy: 0.8589 - val_binary_crossentropy: 0.3271
Epoch 19/20
49/49 - 0s - loss: 0.3180 - accuracy: 0.8772 - binary_crossentropy: 0.2908 - val_loss: 0.3509 - val_accuracy: 0.8603 - val_binary_crossentropy: 0.3238
Epoch 20/20
49/49 - 0s - loss: 0.3167 - accuracy: 0.8768 - binary_crossentropy: 0.2896 - val_loss: 0.3491 - val_accuracy: 0.8608 - val_binary_crossentropy: 0.3221</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'L2'</span>, l2_history)</span><br><span class="line">             ])</span><br></pre></td></tr></table></figure>


<img width="947" alt="output_20_0" src="https://user-images.githubusercontent.com/59719711/91168556-cb07cb00-e710-11ea-88ae-600d0836acfe.png">



<p>결과에서 보듯이 모델 파라미터의 개수는 똑같지만 L2규제를 적용한 모델이 base model보다 과대적합에 훨씬 잘 견디고 있는 것을 볼 수 있습니다.</p>
<pre><code>- dropout 추가하기
    * 신경망에서 쓰이는 가장 효과적이고 널리 사용하는 규제 기법중 하나입니다.
    * dropout은 층을 이용해 네트워크에 추가할 수 있습니다.

두 개의 층에 dropout 규제를 추가하여 과대적합이 얼마나 감소하는지 알아 보겠습니다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">dpt_model = keras.Sequential([</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>, input_shape=(NUM_WORDS,)),</span><br><span class="line">    keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">16</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    keras.layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    keras.layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">dpt_model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">                   loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">                   metrics=[<span class="string">'accuracy'</span>, <span class="string">'binary_crossentropy'</span>])</span><br><span class="line"></span><br><span class="line">dpt_history = dpt_model.fit(train_data, train_labels, epochs=<span class="number">20</span>, batch_size=<span class="number">512</span>,</span><br><span class="line">                             validation_data=(test_data, test_labels), verbose=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Epoch 1/20
49/49 - 1s - loss: 0.6841 - accuracy: 0.5583 - binary_crossentropy: 0.6841 - val_loss: 0.6280 - val_accuracy: 0.7269 - val_binary_crossentropy: 0.6280
Epoch 2/20
49/49 - 0s - loss: 0.5848 - accuracy: 0.6974 - binary_crossentropy: 0.5848 - val_loss: 0.4655 - val_accuracy: 0.8180 - val_binary_crossentropy: 0.4655
Epoch 3/20
49/49 - 0s - loss: 0.4784 - accuracy: 0.7861 - binary_crossentropy: 0.4784 - val_loss: 0.3797 - val_accuracy: 0.8453 - val_binary_crossentropy: 0.3797
Epoch 4/20
49/49 - 0s - loss: 0.4250 - accuracy: 0.8195 - binary_crossentropy: 0.4250 - val_loss: 0.3453 - val_accuracy: 0.8510 - val_binary_crossentropy: 0.3453
Epoch 5/20
49/49 - 0s - loss: 0.3931 - accuracy: 0.8381 - binary_crossentropy: 0.3931 - val_loss: 0.3338 - val_accuracy: 0.8548 - val_binary_crossentropy: 0.3338
Epoch 6/20
49/49 - 0s - loss: 0.3758 - accuracy: 0.8480 - binary_crossentropy: 0.3758 - val_loss: 0.3299 - val_accuracy: 0.8587 - val_binary_crossentropy: 0.3299
Epoch 7/20
49/49 - 0s - loss: 0.3600 - accuracy: 0.8544 - binary_crossentropy: 0.3600 - val_loss: 0.3224 - val_accuracy: 0.8612 - val_binary_crossentropy: 0.3224
Epoch 8/20
49/49 - 0s - loss: 0.3493 - accuracy: 0.8607 - binary_crossentropy: 0.3493 - val_loss: 0.3227 - val_accuracy: 0.8600 - val_binary_crossentropy: 0.3227
Epoch 9/20
49/49 - 0s - loss: 0.3442 - accuracy: 0.8605 - binary_crossentropy: 0.3442 - val_loss: 0.3226 - val_accuracy: 0.8618 - val_binary_crossentropy: 0.3226
Epoch 10/20
49/49 - 0s - loss: 0.3317 - accuracy: 0.8674 - binary_crossentropy: 0.3317 - val_loss: 0.3230 - val_accuracy: 0.8597 - val_binary_crossentropy: 0.3230
Epoch 11/20
49/49 - 0s - loss: 0.3267 - accuracy: 0.8691 - binary_crossentropy: 0.3267 - val_loss: 0.3247 - val_accuracy: 0.8604 - val_binary_crossentropy: 0.3247
Epoch 12/20
49/49 - 0s - loss: 0.3242 - accuracy: 0.8695 - binary_crossentropy: 0.3242 - val_loss: 0.3261 - val_accuracy: 0.8597 - val_binary_crossentropy: 0.3261
Epoch 13/20
49/49 - 0s - loss: 0.3153 - accuracy: 0.8721 - binary_crossentropy: 0.3153 - val_loss: 0.3289 - val_accuracy: 0.8586 - val_binary_crossentropy: 0.3289
Epoch 14/20
49/49 - 0s - loss: 0.3092 - accuracy: 0.8742 - binary_crossentropy: 0.3092 - val_loss: 0.3294 - val_accuracy: 0.8573 - val_binary_crossentropy: 0.3294
Epoch 15/20
49/49 - 0s - loss: 0.3103 - accuracy: 0.8772 - binary_crossentropy: 0.3103 - val_loss: 0.3312 - val_accuracy: 0.8576 - val_binary_crossentropy: 0.3312
Epoch 16/20
49/49 - 0s - loss: 0.3010 - accuracy: 0.8815 - binary_crossentropy: 0.3010 - val_loss: 0.3363 - val_accuracy: 0.8583 - val_binary_crossentropy: 0.3363
Epoch 17/20
49/49 - 0s - loss: 0.3010 - accuracy: 0.8788 - binary_crossentropy: 0.3010 - val_loss: 0.3338 - val_accuracy: 0.8570 - val_binary_crossentropy: 0.3338
Epoch 18/20
49/49 - 0s - loss: 0.2975 - accuracy: 0.8824 - binary_crossentropy: 0.2975 - val_loss: 0.3343 - val_accuracy: 0.8564 - val_binary_crossentropy: 0.3343
Epoch 19/20
49/49 - 0s - loss: 0.2923 - accuracy: 0.8823 - binary_crossentropy: 0.2923 - val_loss: 0.3417 - val_accuracy: 0.8556 - val_binary_crossentropy: 0.3417
Epoch 20/20
49/49 - 0s - loss: 0.2910 - accuracy: 0.8830 - binary_crossentropy: 0.2910 - val_loss: 0.3452 - val_accuracy: 0.8560 - val_binary_crossentropy: 0.3452</code></pre><p>검증 고고</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'dropout'</span>, dpt_history)</span><br><span class="line">             ])</span><br></pre></td></tr></table></figure>


<img width="947" alt="output_25_0" src="https://user-images.githubusercontent.com/59719711/91168597-db1faa80-e710-11ea-832a-55d34038d224.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plot_history([(<span class="string">'base'</span>, base_history),</span><br><span class="line">              (<span class="string">'dropout'</span>, dpt_history),</span><br><span class="line">              (<span class="string">'L2'</span>, l2_history)</span><br><span class="line">             ])</span><br></pre></td></tr></table></figure>


<img width="947" alt="output_26_0" src="https://user-images.githubusercontent.com/59719711/91168603-dd820480-e710-11ea-8916-4ba873e21636.png">


<h6 id="과대적합을-방지하기-위한-결론"><a href="#과대적합을-방지하기-위한-결론" class="headerlink" title="과대적합을 방지하기 위한 결론"></a>과대적합을 방지하기 위한 결론</h6><pre><code>1. 더 많은 훈련 데이터를 학습시킨다.
2. 네트워크의 용량을 줄인다. (ex. Dense(16 ..)
3. 가중치 규제를 추가한다. (L2)
4. 드롭아웃을 추가한다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" href="/" style="background-color:rgba(255,128,62,.87);border-color:transparent;color:white;" target="_blank" rel="noopener"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button is-danger donate" href="/" target="_blank" rel="noopener"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/08/26/Model-sava-and-load-in-tensorflow/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Model sava and load in tensorflow</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/08/21/Tensorflow%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%ED%9A%8C%EA%B7%80-%EB%AA%A8%EB%8D%B8%EB%A7%81/"><span class="level-item">Tensorflow를 활용한 회귀 모델링</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="https://user-images.githubusercontent.com/59719711/85970198-ab9c3c80-ba04-11ea-8990-4bdec6914e3c.jpeg" alt="wglee87"></figure><p class="title is-size-4 is-block line-height-inherit">wglee87</p><p class="is-size-6 is-block">Data has a better idea</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hwasung, KR</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">37</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wglee87" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wglee87"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Instagram" href="https://Instagram.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-11-25T00:54:15.000Z">2020-11-25</time></p><p class="title is-6"><a class="link-muted" href="/2020/11/25/Gradient-Descent-%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95-%EC%99%80-SGD-Stochastic-Gradient-Descent-%ED%99%95%EB%A5%A0%EC%A0%81-%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95/">Gradient Descent(경사하강법) 와 SGD(Stochastic Gradient Descent) 확률적 경사하강법</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-10-13T13:12:04.000Z">2020-10-13</time></p><p class="title is-6"><a class="link-muted" href="/2020/10/13/Introduce-to-Activation-Function/">Introduce to Activation Function</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-26T10:15:22.000Z">2020-08-26</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/26/Hyper-Parameter-Tuner/">Hyper-Parameter(Tuner)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-26T10:14:02.000Z">2020-08-26</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/26/Model-sava-and-load-in-tensorflow/">Model sava and load in tensorflow</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-08-25T11:21:43.000Z">2020-08-25</time></p><p class="title is-6"><a class="link-muted" href="/2020/08/25/%EA%B3%BC%EB%8C%80%EC%A0%81%ED%95%A9-Overfitting-%EA%B3%BC-%EA%B3%BC%EC%86%8C%EC%A0%81%ED%95%A9-Underfitting/">과대적합(Overfitting)과 과소적합(Underfitting)</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/11/"><span class="level-start"><span class="level-item">November 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/08/"><span class="level-start"><span class="level-item">August 2020</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/07/"><span class="level-start"><span class="level-item">July 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/fastcampus/"><span class="tag">fastcampus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/" alt="Geony&#039;s Tech Blog" height="28"></a><p class="size-small"><span>&copy; 2020 WGLee87</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://wglee87.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>