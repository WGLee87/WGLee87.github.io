<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>leverage-outliar-cooks_distance_anova - Geony Data World</title><meta description="1import statsmodels.api as sm  레버리지 (leverage)독립변수의 전체 데이터가 아닌 개별적인 데이터 표본 하나하나가 회귀분석 결과에 미치는 영향력은 레버리지 분석이나 아웃라이어 분석을 통해 알 수 있다. 레버리지(leverage)는 실제 종속변수값  𝑦 가 예측치(predicted target)  𝑦̂  에 미치는 영향을 나"><meta property="og:type" content="blog"><meta property="og:title" content="leverage-outliar-cooks_distance_anova"><meta property="og:url" content="http://wglee87.github.io/2020/05/14/leverage-outliar-cooks-distance-anova/"><meta property="og:site_name" content="Geony Data World"><meta property="og:description" content="1import statsmodels.api as sm  레버리지 (leverage)독립변수의 전체 데이터가 아닌 개별적인 데이터 표본 하나하나가 회귀분석 결과에 미치는 영향력은 레버리지 분석이나 아웃라이어 분석을 통해 알 수 있다. 레버리지(leverage)는 실제 종속변수값  𝑦 가 예측치(predicted target)  𝑦̂  에 미치는 영향을 나"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926194-91f19200-961c-11ea-9b3f-3acaa0daccab.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926258-a6ce2580-961c-11ea-9442-38672fbc831a.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926328-bc434f80-961c-11ea-89ef-927b80f666c7.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926368-c8c7a800-961c-11ea-9826-24478a19b3b4.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926392-d41ad380-961c-11ea-852b-985bce5ea681.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926442-e563e000-961c-11ea-9511-4128f90f70c5.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926462-ed238480-961c-11ea-827c-5e2360d26f75.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926491-fb71a080-961c-11ea-815d-7cab11d016fd.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926518-04fb0880-961d-11ea-8ec0-70154b06352f.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926554-17754200-961d-11ea-9ea7-69b37349b510.png"><meta property="og:image" content="https://user-images.githubusercontent.com/59719711/81926587-222fd700-961d-11ea-88fb-a5ff2aec6b90.png"><meta property="article:published_time" content="2020-05-14T11:01:27.000Z"><meta property="article:modified_time" content="2020-05-14T11:02:11.266Z"><meta property="article:author" content="wglee87"><meta property="article:tag" content="data_analysis"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://user-images.githubusercontent.com/59719711/81926194-91f19200-961c-11ea-9b3f-3acaa0daccab.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://wglee87.github.io/2020/05/14/leverage-outliar-cooks-distance-anova/"},"headline":"Geony Data World","image":["https://user-images.githubusercontent.com/59719711/81926194-91f19200-961c-11ea-9b3f-3acaa0daccab.png","https://user-images.githubusercontent.com/59719711/81926258-a6ce2580-961c-11ea-9442-38672fbc831a.png","https://user-images.githubusercontent.com/59719711/81926328-bc434f80-961c-11ea-89ef-927b80f666c7.png","https://user-images.githubusercontent.com/59719711/81926368-c8c7a800-961c-11ea-9826-24478a19b3b4.png","https://user-images.githubusercontent.com/59719711/81926392-d41ad380-961c-11ea-852b-985bce5ea681.png","https://user-images.githubusercontent.com/59719711/81926442-e563e000-961c-11ea-9511-4128f90f70c5.png","https://user-images.githubusercontent.com/59719711/81926462-ed238480-961c-11ea-827c-5e2360d26f75.png","https://user-images.githubusercontent.com/59719711/81926491-fb71a080-961c-11ea-815d-7cab11d016fd.png","https://user-images.githubusercontent.com/59719711/81926518-04fb0880-961d-11ea-8ec0-70154b06352f.png","https://user-images.githubusercontent.com/59719711/81926554-17754200-961d-11ea-9ea7-69b37349b510.png","https://user-images.githubusercontent.com/59719711/81926587-222fd700-961d-11ea-88fb-a5ff2aec6b90.png"],"datePublished":"2020-05-14T11:01:27.000Z","dateModified":"2020-05-14T11:02:11.266Z","author":{"@type":"Person","name":"WGLee87"},"description":"1import statsmodels.api as sm  레버리지 (leverage)독립변수의 전체 데이터가 아닌 개별적인 데이터 표본 하나하나가 회귀분석 결과에 미치는 영향력은 레버리지 분석이나 아웃라이어 분석을 통해 알 수 있다. 레버리지(leverage)는 실제 종속변수값  𝑦 가 예측치(predicted target)  𝑦̂  에 미치는 영향을 나"}</script><link rel="canonical" href="http://wglee87.github.io/2020/05/14/leverage-outliar-cooks-distance-anova/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Geony Data World" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2020-05-14T11:01:27.000Z" title="2020-05-14T11:01:27.000Z">2020-05-14</time><span class="level-item">30 minutes read (About 4483 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">leverage-outliar-cooks_distance_anova</h1><div class="content"><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> statsmodels.api <span class="keyword">as</span> sm</span><br></pre></td></tr></table></figure>

<h4 id="레버리지-leverage"><a href="#레버리지-leverage" class="headerlink" title="레버리지 (leverage)"></a>레버리지 (leverage)</h4><pre><code>독립변수의 전체 데이터가 아닌 개별적인 데이터 표본 하나하나가 회귀분석 결과에 미치는 영향력은 레버리지 분석이나 아웃라이어 분석을 통해 알 수 있다.
레버리지(leverage)는 실제 종속변수값  𝑦 가 예측치(predicted target)  𝑦̂  에 미치는 영향을 나타낸 값이다. self-influence, self-sensitivity 라고도 한다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_boston</span><br><span class="line"></span><br><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 14 columns</p>
</div>




<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">df0 = pd.concat([dfX, dfy],axis=<span class="number">1</span>)</span><br><span class="line">df0</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>const</th>
      <th>CRIM</th>
      <th>ZN</th>
      <th>INDUS</th>
      <th>CHAS</th>
      <th>NOX</th>
      <th>RM</th>
      <th>AGE</th>
      <th>DIS</th>
      <th>RAD</th>
      <th>TAX</th>
      <th>PTRATIO</th>
      <th>B</th>
      <th>LSTAT</th>
      <th>MEDV</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>0.00632</td>
      <td>18.0</td>
      <td>2.31</td>
      <td>0.0</td>
      <td>0.538</td>
      <td>6.575</td>
      <td>65.2</td>
      <td>4.0900</td>
      <td>1.0</td>
      <td>296.0</td>
      <td>15.3</td>
      <td>396.90</td>
      <td>4.98</td>
      <td>24.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>0.02731</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>6.421</td>
      <td>78.9</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>396.90</td>
      <td>9.14</td>
      <td>21.6</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>0.02729</td>
      <td>0.0</td>
      <td>7.07</td>
      <td>0.0</td>
      <td>0.469</td>
      <td>7.185</td>
      <td>61.1</td>
      <td>4.9671</td>
      <td>2.0</td>
      <td>242.0</td>
      <td>17.8</td>
      <td>392.83</td>
      <td>4.03</td>
      <td>34.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>0.03237</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>6.998</td>
      <td>45.8</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>394.63</td>
      <td>2.94</td>
      <td>33.4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>0.06905</td>
      <td>0.0</td>
      <td>2.18</td>
      <td>0.0</td>
      <td>0.458</td>
      <td>7.147</td>
      <td>54.2</td>
      <td>6.0622</td>
      <td>3.0</td>
      <td>222.0</td>
      <td>18.7</td>
      <td>396.90</td>
      <td>5.33</td>
      <td>36.2</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>501</th>
      <td>1.0</td>
      <td>0.06263</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.593</td>
      <td>69.1</td>
      <td>2.4786</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>391.99</td>
      <td>9.67</td>
      <td>22.4</td>
    </tr>
    <tr>
      <th>502</th>
      <td>1.0</td>
      <td>0.04527</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.120</td>
      <td>76.7</td>
      <td>2.2875</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>9.08</td>
      <td>20.6</td>
    </tr>
    <tr>
      <th>503</th>
      <td>1.0</td>
      <td>0.06076</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.976</td>
      <td>91.0</td>
      <td>2.1675</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>5.64</td>
      <td>23.9</td>
    </tr>
    <tr>
      <th>504</th>
      <td>1.0</td>
      <td>0.10959</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.794</td>
      <td>89.3</td>
      <td>2.3889</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>393.45</td>
      <td>6.48</td>
      <td>22.0</td>
    </tr>
    <tr>
      <th>505</th>
      <td>1.0</td>
      <td>0.04741</td>
      <td>0.0</td>
      <td>11.93</td>
      <td>0.0</td>
      <td>0.573</td>
      <td>6.030</td>
      <td>80.8</td>
      <td>2.5050</td>
      <td>1.0</td>
      <td>273.0</td>
      <td>21.0</td>
      <td>396.90</td>
      <td>7.88</td>
      <td>11.9</td>
    </tr>
  </tbody>
</table>
<p>506 rows × 15 columns</p>
</div>



<h5 id="statsmodels를-이용한-레버리지-계산"><a href="#statsmodels를-이용한-레버리지-계산" class="headerlink" title="statsmodels를 이용한 레버리지 계산"></a>statsmodels를 이용한 레버리지 계산</h5><pre><code>레버리지 값은 RegressionResults 클래스의 get_influence 메서드로 다음과 같이 구할 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_regression</span><br><span class="line"></span><br><span class="line"><span class="comment"># 100개의 데이터 생성</span></span><br><span class="line">X0, y, coef = make_regression(n_samples=<span class="number">100</span>, n_features=<span class="number">1</span>, noise=<span class="number">20</span>,</span><br><span class="line">                             coef=<span class="literal">True</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 레버리지가 높은 가상의 데이터를 추가</span></span><br><span class="line">data_100 = (<span class="number">4</span>, <span class="number">300</span>)</span><br><span class="line">data_101 = (<span class="number">3</span>, <span class="number">150</span>)</span><br><span class="line">X0 = np.vstack([X0, np.array([data_100[:<span class="number">1</span>], data_101[:<span class="number">1</span>]])])</span><br><span class="line">X = sm.add_constant(X0) <span class="comment">#상수항 추가</span></span><br><span class="line">y = np.hstack([y, [data_100[<span class="number">1</span>], data_101[<span class="number">1</span>]]])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt.scatter(X0, y, s=<span class="number">30</span>)</span><br><span class="line">plt.xlabel(<span class="string">"x"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"y"</span>)</span><br><span class="line">plt.title(<span class="string">"가상의 회귀분석용 데이터"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="849" alt="output_6_0" src="https://user-images.githubusercontent.com/59719711/81926194-91f19200-961c-11ea-9b3f-3acaa0daccab.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS(pd.DataFrame(y), pd.DataFrame(X))</span><br><span class="line">result = model.fit()</span><br><span class="line">print(result.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                      0   R-squared:                       0.936
Model:                            OLS   Adj. R-squared:                  0.935
Method:                 Least Squares   F-statistic:                     1464.
Date:                Thu, 14 May 2020   Prob (F-statistic):           1.61e-61
Time:                        14:22:53   Log-Likelihood:                -452.71
No. Observations:                 102   AIC:                             909.4
Df Residuals:                     100   BIC:                             914.7
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
0              3.2565      2.065      1.577      0.118      -0.840       7.353
1             78.3379      2.048     38.260      0.000      74.276      82.400
==============================================================================
Omnibus:                       16.191   Durbin-Watson:                   1.885
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.807
Skew:                          -0.534   Prob(JB):                     1.02e-08
Kurtosis:                       5.742   Cond. No.                         1.14
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


선형회귀 결과에서 get_influence 메서드를 호출하면 영향도 정보 객체를 구할 수 있고, 이 객체는 hat_matrix_diag 속성으로 레버리지 벡터의 값을 가지고도 있어</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">influence = result.get_influence()</span><br><span class="line">hat = influence.hat_matrix_diag</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt. stem(hat)</span><br><span class="line">plt.axhline(<span class="number">0.02</span>, c = <span class="string">'g'</span>, ls = <span class="string">'--'</span>) <span class="comment"># c = color , ls = linestyle</span></span><br><span class="line">plt.title(<span class="string">'각 데이터의 레버리지 값'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.
  &quot;&quot;&quot;</code></pre><img width="831" alt="output_9_1" src="https://user-images.githubusercontent.com/59719711/81926258-a6ce2580-961c-11ea-9442-38672fbc831a.png">


<pre><code>그래프를 그리는 코드에서 0.02의 값은 레버리지 평균값을 구하는 공식 독립변수의 갯수 / 데이터의 갯수 로 구하면 된다</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">![스크린샷 <span class="number">2020</span><span class="number">-05</span><span class="number">-14</span> 오후 <span class="number">2</span> <span class="number">31</span> <span class="number">46</span>](https://user-images.githubusercontent.com/<span class="number">59719711</span>/<span class="number">81926278</span>-b2215100<span class="number">-961</span>c<span class="number">-11</span>ea<span class="number">-9613</span>-c5ba582d5de0.png)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(X0, y,s=<span class="number">30</span>)</span><br><span class="line">sm.graphics.abline_plot(model_results=result, ax=ax)</span><br><span class="line"></span><br><span class="line">idx = hat &gt; <span class="number">0.05</span></span><br><span class="line">plt.scatter(X0[idx], y[idx], s=<span class="number">300</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">plt.title(<span class="string">"회귀분석 결과와 레버리지 포인트"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="833" alt="output_12_0" src="https://user-images.githubusercontent.com/59719711/81926328-bc434f80-961c-11ea-89ef-927b80f666c7.png">


<pre><code>그래프를 토대로 해석을 하자면, 데이터가 혼자만 너무 작거나 너무 크게 단독으로 존재할수록 레버리지가 커짐을 알 수 있어. 이 말은 저런 데이터은 전체 회귀분석 결과값에 큰 영향을 미친다는 말이야</code></pre><h4 id="아웃라이어-outlier"><a href="#아웃라이어-outlier" class="headerlink" title="아웃라이어(outlier)"></a>아웃라이어(outlier)</h4><pre><code>데이터와 동떨어진 값을 가지는 데이터, 즉 잔차가 큰 데이터를 아웃라이어(outlier)라고 하는데, 잔차의 크기는 독립 변수의 영향을 받으므로 아웃라이어를 찾으려면 이 영향을 제거한 표준화된 잔차를 계산해야 한다고 해. 무슨말인지 잘 모르겠지만 그래

statsmodels를 이용한 표준화 잔차 계산

잔차는 RegressionResult 객체의 resid 속성에 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line">plt.stem(result.resid)</span><br><span class="line">plt.title(<span class="string">"각 데이터의 잔차"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.</code></pre><img width="826" alt="output_16_1" src="https://user-images.githubusercontent.com/59719711/81926368-c8c7a800-961c-11ea-9826-24478a19b3b4.png">


<pre><code>표준화 잔차는 resid_pearson 속성에 있고, 보통 표준화 잔차가 2~4보다 크면 아웃라이어로 보는게 일반적이야</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt. stem(result.resid_pearson)</span><br><span class="line">plt.axhline(<span class="number">3</span>, c=<span class="string">'g'</span>, ls=<span class="string">'--'</span>)</span><br><span class="line">plt.axhline(<span class="number">-3</span>, c=<span class="string">'g'</span>, ls=<span class="string">'--'</span>)</span><br><span class="line">plt.title(<span class="string">'각 데이터의 표준화 잔차'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: In Matplotlib 3.3 individual lines on a stem plot will be added as a LineCollection instead of individual lines. This significantly improves the performance of a stem plot. To remove this warning and switch to the new behaviour, set the &quot;use_line_collection&quot; keyword argument to True.</code></pre><img width="818" alt="output_18_1" src="https://user-images.githubusercontent.com/59719711/81926392-d41ad380-961c-11ea-852b-985bce5ea681.png">


<h4 id="Cook’s-Distance"><a href="#Cook’s-Distance" class="headerlink" title="Cook’s Distance"></a>Cook’s Distance</h4><pre><code>회귀 분석에는 레버리지 따로, 잔차의 크기가 큰 데이터가 아웃라이어가 되고 그것을 보는 따로따로의 기능도 있지만  이 두개를 동시에 보는 방법이 바로 Cook&apos;s Distance야. 아마도 Cook이라는 사람이 만들었을 가능성이..

넘어가자

동시에 보는 기준이라고 생각하면 되고, 둘중 하나만 커지더라도 이 Cook&apos;s distance 값은 커지게 돼

모든 데이터의 레버리지와 잔차를 동시에 보려면 plot_leverage_resid2 명령을 사용하는데, 이 명령은 x축으로 표준화 잔차의 제곱을 표시하고 y축으로 레버리지값을 표시한다. 

그리고 데이터 아이디가 표시된 데이터들이 레버리지가 큰 아웃라이어 야</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sm.graphics.plot_leverage_resid2(result)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">sm.graphics.influence_plot(result)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<pre><code>&lt;Figure size 1008x432 with 0 Axes&gt;</code></pre><img width="401" alt="output_21_1" src="https://user-images.githubusercontent.com/59719711/81926442-e563e000-961c-11ea-9511-4128f90f70c5.png">




<img width="392" alt="output_21_2" src="https://user-images.githubusercontent.com/59719711/81926462-ed238480-961c-11ea-827c-5e2360d26f75.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> statsmodels.graphics <span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line">cooks_d2, pvals = influence.cooks_distance</span><br><span class="line">K = influence.k_vars</span><br><span class="line">fox_cr = <span class="number">4</span> / (len(y) - K - <span class="number">1</span>)</span><br><span class="line">idx = np.where(cooks_d2 &gt; fox_cr)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(X0, y)</span><br><span class="line">plt.scatter(X0[idx], y[idx], s=<span class="number">300</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">utils.annotate_axes(range(len(idx)), idx,</span><br><span class="line">                    list(zip(X0[idx], y[idx])), [(<span class="number">-20</span>, <span class="number">15</span>)] * len(idx), size=<span class="string">"small"</span>, ax=ax)</span><br><span class="line">plt.title(<span class="string">"Fox Recommendaion으로 선택한 아웃라이어"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="387" alt="output_22_0" src="https://user-images.githubusercontent.com/59719711/81926491-fb71a080-961c-11ea-815d-7cab11d016fd.png">


<h5 id="보스턴-집값-예측-문제¶"><a href="#보스턴-집값-예측-문제¶" class="headerlink" title="보스턴 집값 예측 문제¶"></a>보스턴 집값 예측 문제¶</h5><pre><code>보스턴 집값 문제에 아웃라이어를 적용해 보자. MEDV가 50인 데이터는 상식적으로 생각해도 이상한 데이터이므로 아웃라이어라고 판단할 수 있다. 나머지 데이터 중에서 폭스 추천공식을 사용하여 아웃라이어를 제외한 결과는 다음과 같다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">boston = load_boston()</span><br><span class="line"></span><br><span class="line">dfx = pd.DataFrame(boston.data, columns=boston.feature_names)</span><br><span class="line">dfy = pd.DataFrame(boston.target, columns=[<span class="string">"MEDV"</span>])</span><br><span class="line">df = pd.concat([dfx,dfy],axis=<span class="number">1</span>)</span><br><span class="line">df</span><br><span class="line"></span><br><span class="line">dfX = sm.add_constant(dfx)</span><br><span class="line">df0 = pd.concat([dfX, dfy],axis=<span class="number">1</span>)</span><br><span class="line">df0</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">pred = result_boston.predict(dfX)</span><br><span class="line"></span><br><span class="line">influence_boston = result_boston.get_influence()</span><br><span class="line">cooks_d2, pvals = influence_boston.cooks_distance</span><br><span class="line">K = influence.k_vars</span><br><span class="line">fox_cr = <span class="number">4</span> / (len(y) - K - <span class="number">1</span>)</span><br><span class="line">idx = np.where(cooks_d2 &gt; fox_cr)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># MEDV = 50 제거</span></span><br><span class="line">idx = np.hstack([idx, np.where(boston.target == <span class="number">50</span>)[<span class="number">0</span>]])</span><br><span class="line"></span><br><span class="line">ax = plt.subplot()</span><br><span class="line">plt.scatter(dfy, pred)</span><br><span class="line">plt.scatter(dfy.MEDV[idx], pred[idx], s=<span class="number">200</span>, c=<span class="string">"r"</span>, alpha=<span class="number">0.5</span>)</span><br><span class="line">utils.annotate_axes(range(len(idx)), idx,</span><br><span class="line">                    list(zip(dfy.MEDV[idx], pred[idx])), [(<span class="number">-20</span>, <span class="number">15</span>)] * len(idx), size=<span class="string">"small"</span>, ax=ax)</span><br><span class="line">plt.title(<span class="string">"보스턴 집값 데이터에서 아웃라이어"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="374" alt="output_25_0" src="https://user-images.githubusercontent.com/59719711/81926518-04fb0880-961d-11ea-8ec0-70154b06352f.png">


<pre><code>다음은 이렇게 아웃라이어를 제외한 후에 다시 회귀분석을 한 결과이다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">idx2 = list(set(range(len(dfX))).difference(idx))</span><br><span class="line">dfX = dfX.iloc[idx2, :].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">dfy = dfy.iloc[idx2, :].reset_index(drop=<span class="literal">True</span>)</span><br><span class="line">model_boston2 = sm.OLS(dfy, dfX)</span><br><span class="line">result_boston2 = model_boston2.fit()</span><br><span class="line">print(result_boston2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.812
Model:                            OLS   Adj. R-squared:                  0.806
Method:                 Least Squares   F-statistic:                     156.1
Date:                Thu, 14 May 2020   Prob (F-statistic):          2.41e-161
Time:                        15:14:52   Log-Likelihood:                -1285.2
No. Observations:                 485   AIC:                             2598.
Df Residuals:                     471   BIC:                             2657.
Df Model:                          13                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
const         18.8999      4.107      4.602      0.000      10.830      26.969
CRIM          -0.0973      0.024     -4.025      0.000      -0.145      -0.050
ZN             0.0278      0.010      2.651      0.008       0.007       0.048
INDUS         -0.0274      0.046     -0.595      0.552      -0.118       0.063
CHAS           0.9228      0.697      1.324      0.186      -0.447       2.292
NOX           -9.4922      2.856     -3.323      0.001     -15.105      -3.879
RM             5.0921      0.371     13.735      0.000       4.364       5.821
AGE           -0.0305      0.010     -2.986      0.003      -0.051      -0.010
DIS           -1.0562      0.150     -7.057      0.000      -1.350      -0.762
RAD            0.1990      0.049      4.022      0.000       0.102       0.296
TAX           -0.0125      0.003     -4.511      0.000      -0.018      -0.007
PTRATIO       -0.7777      0.098     -7.955      0.000      -0.970      -0.586
B              0.0107      0.002      5.348      0.000       0.007       0.015
LSTAT         -0.2846      0.043     -6.639      0.000      -0.369      -0.200
==============================================================================
Omnibus:                       45.944   Durbin-Watson:                   1.184
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               65.791
Skew:                           0.679   Prob(JB):                     5.17e-15
Kurtosis:                       4.188   Cond. No.                     1.59e+04
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 1.59e+04. This might indicate that there are
strong multicollinearity or other numerical problems.


R-squared 의 성능점수가 올라간 것을 볼 수 있어.

이렇게 어떤 특정 데이터를 가지고 회귀분석 모델링을 할 때에는 하기 전에 레버리지가 큰 데이터와 아웃라이어의 값을 이러한 절차에 의해 뽑아서 제거하고 모델링을 한다면 더욱 성능이 좋은 회귀분석 모델링을 할 수 있는거야</code></pre><h4 id="분산-분석"><a href="#분산-분석" class="headerlink" title="분산 분석"></a>분산 분석</h4><pre><code>선형회귀분석의 결과가 얼마나 좋은지는 단순히 잔차제곱합(RSS: Residula Sum of Square)으로 평가할 수 없다. 변수의 단위 즉, 스케일이 달라지면 회귀분석과 상관없이 잔차제곱합도 달라지기 때문이야 ( ex.1km와 1000m)

분산 분석(ANOVA: Analysis of Variance)은 종속변수의 분산과 독립변수의 분산간의 관계를 사용하여 선형회귀분석의 성능을 평가하고자 하는 방법이다. 분산 분석은 서로 다른 두 개의 선형회귀분석의 성능 비교에 응용할 수 있으며 독립변수가 카테고리 변수인 경우 각 카테고리 값에 따른 영향을 정량적으로 분석하는데도 사용할 수 있게 돼

여러 수식들이 존재하지만 내가 이해를 못하겠고 결론은 다음과 같아.

모형 예측치의 움직임의 크기(분산,ESS)은 종속변수의 움직임의 크기(분산,TSS)보다 클 수 없어 그리고 모형의 성능이 좋을수록 모형 예측치의 움직임의 크기는 종속변수의 움직임의 크기와 비슷해진다는 점이야</code></pre><h5 id="F-검정을-사용한-변수-중요도-비교"><a href="#F-검정을-사용한-변수-중요도-비교" class="headerlink" title="F 검정을 사용한 변수 중요도 비교"></a>F 검정을 사용한 변수 중요도 비교</h5><pre><code>F검정은 각 독립변수의 중요도를 비교하기 위해 사용할 수 있다. 방법은 전체 모형과 각 변수 하나만을 뺀 모형들의 성능을 비교하는 것인데, 이는 간접적으로 각 독립 변수의 영향력을 측정하는 것이라고 할 수 있다. 예를 들어 보스턴 집값 데이터에서 CRIM이란 변수를 뺀 모델과 전체 모델의 비교하는 검정을 하면 이 검정 결과는 CRIM변수의 중요도를 나타낸다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">model_full = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ CRIM + ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line">model_reduced = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line"></span><br><span class="line">sm.stats.anova_lm(model_reduced.fit(), model_full.fit())</span><br></pre></td></tr></table></figure>

<pre><code>/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater
  return (a &lt; x) &amp; (x &lt; b)
/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less
  return (a &lt; x) &amp; (x &lt; b)
/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal
  cond2 = cond0 &amp; (x &lt;= _a)</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>df_resid</th>
      <th>ssr</th>
      <th>df_diff</th>
      <th>ss_diff</th>
      <th>F</th>
      <th>Pr(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>493.0</td>
      <td>11322.004277</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>492.0</td>
      <td>11078.784578</td>
      <td>1.0</td>
      <td>243.219699</td>
      <td>10.801193</td>
      <td>0.001087</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>anova_lm 명령에서는 typ 인수를 2로 지정하면 하나 하나의 변수를 뺀 축소 모형에서의 F 검정값을 한꺼번에 계산할 수 있다.</code></pre><h5 id="아노바-분석-F검정"><a href="#아노바-분석-F검정" class="headerlink" title="아노바 분석 - F검정"></a>아노바 분석 - F검정</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model = sm.OLS.from_formula(</span><br><span class="line">    <span class="string">"MEDV ~ CRIM + ZN + INDUS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT + CHAS"</span>, data=df0)</span><br><span class="line">result = model.fit()</span><br><span class="line">sm.stats.anova_lm(result, typ=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sum_sq</th>
      <th>df</th>
      <th>F</th>
      <th>PR(&gt;F)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>CRIM</th>
      <td>243.219699</td>
      <td>1.0</td>
      <td>10.801193</td>
      <td>1.086810e-03</td>
    </tr>
    <tr>
      <th>ZN</th>
      <td>257.492979</td>
      <td>1.0</td>
      <td>11.435058</td>
      <td>7.781097e-04</td>
    </tr>
    <tr>
      <th>INDUS</th>
      <td>2.516668</td>
      <td>1.0</td>
      <td>0.111763</td>
      <td>7.382881e-01</td>
    </tr>
    <tr>
      <th>NOX</th>
      <td>487.155674</td>
      <td>1.0</td>
      <td>21.634196</td>
      <td>4.245644e-06</td>
    </tr>
    <tr>
      <th>RM</th>
      <td>1871.324082</td>
      <td>1.0</td>
      <td>83.104012</td>
      <td>1.979441e-18</td>
    </tr>
    <tr>
      <th>AGE</th>
      <td>0.061834</td>
      <td>1.0</td>
      <td>0.002746</td>
      <td>9.582293e-01</td>
    </tr>
    <tr>
      <th>DIS</th>
      <td>1232.412493</td>
      <td>1.0</td>
      <td>54.730457</td>
      <td>6.013491e-13</td>
    </tr>
    <tr>
      <th>RAD</th>
      <td>479.153926</td>
      <td>1.0</td>
      <td>21.278844</td>
      <td>5.070529e-06</td>
    </tr>
    <tr>
      <th>TAX</th>
      <td>242.257440</td>
      <td>1.0</td>
      <td>10.758460</td>
      <td>1.111637e-03</td>
    </tr>
    <tr>
      <th>PTRATIO</th>
      <td>1194.233533</td>
      <td>1.0</td>
      <td>53.034960</td>
      <td>1.308835e-12</td>
    </tr>
    <tr>
      <th>B</th>
      <td>270.634230</td>
      <td>1.0</td>
      <td>12.018651</td>
      <td>5.728592e-04</td>
    </tr>
    <tr>
      <th>LSTAT</th>
      <td>2410.838689</td>
      <td>1.0</td>
      <td>107.063426</td>
      <td>7.776912e-23</td>
    </tr>
    <tr>
      <th>CHAS</th>
      <td>218.970357</td>
      <td>1.0</td>
      <td>9.724299</td>
      <td>1.925030e-03</td>
    </tr>
    <tr>
      <th>Residual</th>
      <td>11078.784578</td>
      <td>492.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>각각의 독립변수들의 전체와 비교했을 때 얼마만큼 중요도를 가지는데 정량적으로 나온 결과값이야. 여기서 주목해야할 부분은 PR&gt;(&gt;F)부분으로 summary에서도 나오는 p-value값을 디테일하게 풀어놓은 값이고 예를 들어 LSTAT, RM의 경우 10의 -23승, 10의 -18승으로 수치가 제일 낮은걸 알 수 있어. 그러면 이 2가지의 독립변수가 종속변수에 가장 큰 영향을 미쳤다고 해석하면 되는거야
표의 F값을 보고도 알 수 있지만 F값은 확률의 의미는 없기 때문에 단순 순위를 매기는거 라면 결정할 수 있지만 만약 귀무가설/대립가설을 accept 하냐 reject 하냐의 확률적 의미를 판단한다면 F값만으로는 불가능해</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="범주형을-사용한-비선형성"><a href="#범주형을-사용한-비선형성" class="headerlink" title="범주형을 사용한 비선형성"></a>범주형을 사용한 비선형성</h5><pre><code>독립변수의 비선형성을 포착하는 또 다른 방법 중 하나는 강제로 범주형 값으로 만드는 것이다. 범주형 값이 되면서 독립변수의 오차가 생기지만 이로 인한 오차보다 비선형성으로 얻을 수 있는 이익이 클 수도 있다.

보스턴 집값 데이터에서 종속변수와 RM 변수의 관계는 선형에 가깝지만 방의 갯수가 아주 작아지거나 아주 커지면 선형모형에서 벗어난다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sns.scatterplot(x=<span class="string">"RM"</span>, y=<span class="string">"MEDV"</span>, data=df0, s=<span class="number">60</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="836" alt="output_39_0" src="https://user-images.githubusercontent.com/59719711/81926554-17754200-961d-11ea-9ea7-69b37349b510.png">



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_rm = sm.OLS.from_formula(<span class="string">'MEDV ~ RM'</span>, data=df0)</span><br><span class="line">result_rm = model_rm.fit()</span><br><span class="line">print(result_rm.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.484
Model:                            OLS   Adj. R-squared:                  0.483
Method:                 Least Squares   F-statistic:                     471.8
Date:                Thu, 14 May 2020   Prob (F-statistic):           2.49e-74
Time:                        19:28:18   Log-Likelihood:                -1673.1
No. Observations:                 506   AIC:                             3350.
Df Residuals:                     504   BIC:                             3359.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==============================================================================
                 coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------
Intercept    -34.6706      2.650    -13.084      0.000     -39.877     -29.465
RM             9.1021      0.419     21.722      0.000       8.279       9.925
==============================================================================
Omnibus:                      102.585   Durbin-Watson:                   0.684
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              612.449
Skew:                           0.726   Prob(JB):                    1.02e-133
Kurtosis:                       8.190   Cond. No.                         58.4
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


이렇게 RM 데이터 전체를 놓고 보면 종속변수 y와 아주 큰 상관관계가 있는것으로 보이지만 위에 그래프에서 봤듯이, 방의 갯수가 아주 적거나, 많으면 선형성을 보이지 않는 구간에 대해 조금 더 디테일하게 상관관게를 보고 싶다면 RM 데이터를 강제로 범주화 시켜 RM 데이터가 가지는 비선형성을 잡을 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rooms = np.arange(<span class="number">3</span>,<span class="number">10</span>)</span><br><span class="line">labels = [str(r) <span class="keyword">for</span> r <span class="keyword">in</span> rooms[:<span class="number">-1</span>]]</span><br><span class="line">df0[<span class="string">'CAT_RM'</span>] = np.round(df[<span class="string">'RM'</span>])</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">sns.barplot(<span class="string">'CAT_RM'</span>, <span class="string">'MEDV'</span>, data=df0)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<img width="836" alt="output_42_0" src="https://user-images.githubusercontent.com/59719711/81926587-222fd700-961d-11ea-88fb-a5ff2aec6b90.png">


<pre><code>이렇게 하면 RM 변수으로 인한 종속변수의 변화를 비선형 상수항으로 모형화 할 수 있다. 선형모형보다 성능이 향상된 것을 볼 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model_rm2 = sm.OLS.from_formula(<span class="string">"MEDV ~ C(np.round(RM))"</span>, data=df0)</span><br><span class="line">result_rm2 = model_rm2.fit()</span><br><span class="line">print(result_rm2.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                   MEDV   R-squared:                       0.537
Model:                            OLS   Adj. R-squared:                  0.532
Method:                 Least Squares   F-statistic:                     115.8
Date:                Thu, 14 May 2020   Prob (F-statistic):           3.57e-81
Time:                        19:33:48   Log-Likelihood:                -1645.6
No. Observations:                 506   AIC:                             3303.
Df Residuals:                     500   BIC:                             3329.
Df Model:                           5                                         
Covariance Type:            nonrobust                                         
==========================================================================================
                             coef    std err          t      P&gt;|t|      [0.025      0.975]
------------------------------------------------------------------------------------------
Intercept                 17.0200      2.814      6.049      0.000      11.492      22.548
C(np.round(RM))[T.5.0]    -2.0741      2.998     -0.692      0.489      -7.964       3.816
C(np.round(RM))[T.6.0]     2.3460      2.836      0.827      0.409      -3.226       7.918
C(np.round(RM))[T.7.0]    11.0272      2.869      3.843      0.000       5.389      16.665
C(np.round(RM))[T.8.0]    28.5425      3.093      9.228      0.000      22.466      34.619
C(np.round(RM))[T.9.0]    23.6133      4.595      5.139      0.000      14.586      32.641
==============================================================================
Omnibus:                       81.744   Durbin-Watson:                   0.799
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              467.887
Skew:                           0.542   Prob(JB):                    2.51e-102
Kurtosis:                       7.584   Cond. No.                         31.1
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</code></pre><h5 id="시간-독립변수의-변형"><a href="#시간-독립변수의-변형" class="headerlink" title="시간 독립변수의 변형"></a>시간 독립변수의 변형</h5><pre><code>독립변수가 시간인 경우에는 특정 시점에서 경과된 시간값으로 변형해야 한다. 일간 전기 사용량 데이터를 예로 들어 설명한다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = sm.datasets.get_rdataset(<span class="string">"elecdaily"</span>, package=<span class="string">"fpp2"</span>)</span><br><span class="line"></span><br><span class="line">df_elec = data.data.drop(columns=[<span class="string">"WorkDay"</span>, <span class="string">"Temperature"</span>])</span><br><span class="line">df_elec[<span class="string">"Date"</span>] = pd.date_range(<span class="string">"2014-1-1"</span>, <span class="string">"2014-12-31"</span>)</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>파이썬 datetime 자료형은 toordinal 명령으로 특정 시점으로부터 경과한 시간의 일단위 값을 구하거나 timestamp 메서드로 초단위 값을 구할 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime <span class="keyword">as</span> dt</span><br><span class="line"></span><br><span class="line">df_elec[<span class="string">"Ordinal"</span>] = df_elec.Date.map(dt.datetime.toordinal)</span><br><span class="line">df_elec[<span class="string">"Timestamp"</span>] = df_elec.Date.map(dt.datetime.timestamp)</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
      <th>Ordinal</th>
      <th>Timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
      <td>735594</td>
      <td>1.419606e+09</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
      <td>735595</td>
      <td>1.419692e+09</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
      <td>735596</td>
      <td>1.419779e+09</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
      <td>735597</td>
      <td>1.419865e+09</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
      <td>735598</td>
      <td>1.419952e+09</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>여기에서는 일단위 시간 값을 사용하여 회귀분석을 한다. 시간 값의 경우 크기가 크므로 반드시 스케일링을 해 주어야 한다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model5 = sm.OLS.from_formula(<span class="string">"Demand ~ scale(Ordinal)"</span>, data=df_elec)</span><br><span class="line">result5 = model5.fit()</span><br><span class="line">print(result5.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Demand   R-squared:                       0.031
Model:                            OLS   Adj. R-squared:                  0.028
Method:                 Least Squares   F-statistic:                     11.58
Date:                Thu, 14 May 2020   Prob (F-statistic):           0.000739
Time:                        19:35:40   Log-Likelihood:                -1709.7
No. Observations:                 365   AIC:                             3423.
Df Residuals:                     363   BIC:                             3431.
Df Model:                           1                                         
Covariance Type:            nonrobust                                         
==================================================================================
                     coef    std err          t      P&gt;|t|      [0.025      0.975]
----------------------------------------------------------------------------------
Intercept        221.2775      1.374    160.997      0.000     218.575     223.980
scale(Ordinal)    -4.6779      1.374     -3.404      0.001      -7.381      -1.975
==============================================================================
Omnibus:                       43.105   Durbin-Watson:                   0.677
Prob(Omnibus):                  0.000   Jarque-Bera (JB):               96.485
Skew:                           0.614   Prob(JB):                     1.12e-21
Kurtosis:                       5.199   Cond. No.                         1.00
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.


하지만 시간 독립변수는 이 외에더 다양한 특징들을 숨기고 있다. 예들 들어 연도, 월, 일, 요일 데이터를 별도의 독립변수로 분리하거나 한 달 내에서 몇번째 날짜인지 월의 시작 또는 끝인지를 나타내는 값은 모두 특징값이 될 수 있다. 판다스에서는 dt 특수 연산자를 사용하여 이러한 값을 구할 수 있다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df_elec[<span class="string">"Year"</span>] = df_elec[<span class="string">'Date'</span>].dt.year</span><br><span class="line">df_elec[<span class="string">"Month"</span>] = df_elec.Date.dt.month</span><br><span class="line">df_elec[<span class="string">"DayOfYear"</span>] = df_elec.Date.dt.dayofyear</span><br><span class="line">df_elec[<span class="string">"DayOfMonth"</span>] = df_elec.Date.dt.daysinmonth</span><br><span class="line">df_elec[<span class="string">"DayOfWeek"</span>] = df_elec.Date.dt.dayofweek</span><br><span class="line">df_elec[<span class="string">"WeekOfYear"</span>] = df_elec.Date.dt.weekofyear</span><br><span class="line">df_elec[<span class="string">"Weekday"</span>] = df_elec.Date.dt.weekday</span><br><span class="line">df_elec[<span class="string">"IsMonthStart"</span>] = df_elec.Date.dt.is_month_start</span><br><span class="line">df_elec[<span class="string">"IsMonthEnd"</span>] = df_elec.Date.dt.is_month_end</span><br><span class="line">df_elec.tail()</span><br></pre></td></tr></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}</code></pre><p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Demand</th>
      <th>Date</th>
      <th>Ordinal</th>
      <th>Timestamp</th>
      <th>Year</th>
      <th>Month</th>
      <th>DayOfYear</th>
      <th>DayOfMonth</th>
      <th>DayOfWeek</th>
      <th>WeekOfYear</th>
      <th>Weekday</th>
      <th>IsMonthStart</th>
      <th>IsMonthEnd</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>360</th>
      <td>173.727990</td>
      <td>2014-12-27</td>
      <td>735594</td>
      <td>1.419606e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>361</td>
      <td>31</td>
      <td>5</td>
      <td>52</td>
      <td>5</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>361</th>
      <td>188.512817</td>
      <td>2014-12-28</td>
      <td>735595</td>
      <td>1.419692e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>362</td>
      <td>31</td>
      <td>6</td>
      <td>52</td>
      <td>6</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>362</th>
      <td>191.273009</td>
      <td>2014-12-29</td>
      <td>735596</td>
      <td>1.419779e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>363</td>
      <td>31</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>363</th>
      <td>186.240144</td>
      <td>2014-12-30</td>
      <td>735597</td>
      <td>1.419865e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>364</td>
      <td>31</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>False</td>
      <td>False</td>
    </tr>
    <tr>
      <th>364</th>
      <td>186.370181</td>
      <td>2014-12-31</td>
      <td>735598</td>
      <td>1.419952e+09</td>
      <td>2014</td>
      <td>12</td>
      <td>365</td>
      <td>31</td>
      <td>2</td>
      <td>1</td>
      <td>2</td>
      <td>False</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>



<pre><code>이렇게 추가적인 특징값을 이용하여 구한 모형은 성능이 향상된다.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">feature_names = df_elec.columns.tolist()</span><br><span class="line">feature_names.remove(<span class="string">"Demand"</span>)</span><br><span class="line">feature_names.remove(<span class="string">"Date"</span>)</span><br><span class="line"></span><br><span class="line">formula = <span class="string">"""</span></span><br><span class="line"><span class="string">Demand ~ scale(Ordinal) + C(Month) + DayOfYear + </span></span><br><span class="line"><span class="string">         C(DayOfMonth) + C(DayOfWeek) + C(Weekday) + C(IsMonthStart) + C(IsMonthEnd)</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">model6 = sm.OLS.from_formula(formula, data=df_elec)</span><br><span class="line">result6 = model6.fit()</span><br><span class="line">print(result6.summary())</span><br></pre></td></tr></table></figure>

<pre><code>                            OLS Regression Results                            
==============================================================================
Dep. Variable:                 Demand   R-squared:                       0.537
Model:                            OLS   Adj. R-squared:                  0.511
Method:                 Least Squares   F-statistic:                     19.98
Date:                Thu, 14 May 2020   Prob (F-statistic):           4.74e-46
Time:                        19:37:49   Log-Likelihood:                -1574.8
No. Observations:                 365   AIC:                             3192.
Df Residuals:                     344   BIC:                             3273.
Df Model:                          20                                         
Covariance Type:            nonrobust                                         
===========================================================================================
                              coef    std err          t      P&gt;|t|      [0.025      0.975]
-------------------------------------------------------------------------------------------
Intercept                  58.6105      2.423     24.188      0.000      53.844      63.377
C(Month)[T.2]              14.5730      4.587      3.177      0.002       5.551      23.595
C(Month)[T.3]              -1.2369      8.663     -0.143      0.887     -18.276      15.802
C(Month)[T.4]             -29.1875     10.239     -2.851      0.005     -49.326      -9.049
C(Month)[T.5]              23.4037     15.493      1.511      0.132      -7.069      53.876
C(Month)[T.6]              11.3667      3.758      3.024      0.003       3.974      18.759
C(Month)[T.7]              64.8095     22.750      2.849      0.005      20.063     109.556
C(Month)[T.8]              66.5692     26.490      2.513      0.012      14.467     118.671
C(Month)[T.9]              22.7687      9.491      2.399      0.017       4.100      41.437
C(Month)[T.10]             59.0491     33.895      1.742      0.082      -7.619     125.717
C(Month)[T.11]             33.4276     16.778      1.992      0.047       0.427      66.429
C(Month)[T.12]             72.2523     41.334      1.748      0.081      -9.047     153.552
C(DayOfMonth)[T.30]        38.3755     13.530      2.836      0.005      11.763      64.988
C(DayOfMonth)[T.31]         5.6620      7.806      0.725      0.469      -9.691      21.015
C(DayOfWeek)[T.1]           3.4766      1.829      1.900      0.058      -0.121       7.075
C(DayOfWeek)[T.2]           1.5756      1.821      0.865      0.387      -2.006       5.157
C(DayOfWeek)[T.3]           2.8568      1.831      1.560      0.120      -0.745       6.459
C(DayOfWeek)[T.4]           0.8832      1.831      0.482      0.630      -2.719       4.485
C(DayOfWeek)[T.5]         -12.8982      1.831     -7.045      0.000     -16.499      -9.297
C(DayOfWeek)[T.6]         -16.4623      1.829     -8.999      0.000     -20.060     -12.864
C(Weekday)[T.1]             3.4766      1.829      1.900      0.058      -0.121       7.075
C(Weekday)[T.2]             1.5756      1.821      0.865      0.387      -2.006       5.157
C(Weekday)[T.3]             2.8568      1.831      1.560      0.120      -0.745       6.459
C(Weekday)[T.4]             0.8832      1.831      0.482      0.630      -2.719       4.485
C(Weekday)[T.5]           -12.8982      1.831     -7.045      0.000     -16.499      -9.297
C(Weekday)[T.6]           -16.4623      1.829     -8.999      0.000     -20.060     -12.864
C(IsMonthStart)[T.True]     1.2012      5.781      0.208      0.836     -10.169      12.571
C(IsMonthEnd)[T.True]       4.7608      5.781      0.824      0.411      -6.609      16.131
scale(Ordinal)           -101.7884      4.209    -24.182      0.000    -110.068     -93.509
DayOfYear                   0.6769      0.085      7.926      0.000       0.509       0.845
==============================================================================
Omnibus:                      150.460   Durbin-Watson:                   0.577
Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1586.415
Skew:                           1.422   Prob(JB):                         0.00
Kurtosis:                      12.809   Cond. No.                     1.05e+18
==============================================================================

Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The smallest eigenvalue is 1.49e-29. This might indicate that there are
strong multicollinearity problems or that the design matrix is singular.</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</div><div class="notification is-danger">You need to set <code>install_url</code> to use ShareThis. Please set it in <code>_config.yml</code>.</div></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button is-info donate"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" href="/" style="background-color:rgba(255,128,62,.87);border-color:transparent;color:white;" target="_blank" rel="noopener"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a><a class="button is-danger donate" href="/" target="_blank" rel="noopener"><span class="icon is-small"><i class="fab fa-patreon"></i></span><span>Patreon</span></a><div class="notification is-danger">You forgot to set the <code>business</code> or <code>currency_code</code> for Paypal. Please set it in <code>_config.yml</code>.</div><a class="button is-success donate"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/05/15/Data-Analytics-on-Football/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Data Analytic on Football</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2020/05/13/Linear-Regression-with-scale-categorical-regression-and-partial-regression/"><span class="level-item">Linear Regression with scale, categorical regression, and partial regression</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div class="notification is-danger">You forgot to set the <code>shortname</code> for Disqus. Please set it in <code>_config.yml</code>.</div></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="wglee87"></figure><p class="title is-size-4 is-block line-height-inherit">wglee87</p><p class="is-size-6 is-block">Data has a better idea</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>S.Korea</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">23</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">3</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/wglee87" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/wglee87"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><!--!--><div class="card widget"><div class="card-content"><h3 class="menu-label">Recent</h3><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-23T10:40:19.000Z">2020-06-23</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/23/%EB%B9%84%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5-PCA-%EC%A3%BC%EC%84%B1%EB%B6%84-%EB%B6%84%EC%84%9D/">비지도학습 : PCA 주성분 분석</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-17T11:38:49.000Z">2020-06-17</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/17/mglearn%EC%97%90-%EB%8C%80%ED%95%B4/">mglearn에 대해</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-13T08:39:13.000Z">2020-06-13</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/13/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-Data-Scaling-with-sklearn/">데이터 전처리(Data Scaling with sklearn)</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-09T10:02:14.000Z">2020-06-09</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/09/Mysql-Database-%EC%9A%A9%EB%9F%89-%ED%99%95%EC%9D%B8/">[Mysql]Database 용량 확인</a></p><p class="is-uppercase"></p></div></article><article class="media"><div class="media-content size-small"><p><time dateTime="2020-06-04T11:22:46.000Z">2020-06-04</time></p><p class="title is-6"><a class="link-muted" href="/2020/06/04/DataFrame-Functions/">DataFrame Functions</a></p><p class="is-uppercase"></p></div></article></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/06/"><span class="level-start"><span class="level-item">June 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/05/"><span class="level-start"><span class="level-item">May 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/archives/2020/04/"><span class="level-start"><span class="level-item">April 2020</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/fastcampus/"><span class="tag">fastcampus</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/git/"><span class="tag">git</span><span class="tag is-grey-lightest">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag is-grey-lightest">1</span></a></div></div></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe to Updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button is-primary" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="card widget"><div class="card-content"><div class="notification is-danger">You need to set <code>client_id</code> and <code>slot_id</code> to show this AD unit. Please set it in <code>_config.yml</code>.</div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Geony Data World" height="28"></a><p class="size-small"><span>&copy; 2020 WGLee87</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'http://wglee87.github.io',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to Top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>